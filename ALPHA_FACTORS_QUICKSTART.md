# Alpha Factors ä¼˜åŒ–ç‰ˆæœ¬ - å¿«é€Ÿå¼€å§‹

## ğŸ“¦ å®‰è£…å’Œè¿ç§»

### ä»æ—§ç‰ˆæœ¬è¿ç§»

**å¥½æ¶ˆæ¯ï¼šæ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç ï¼** ä¼˜åŒ–ç‰ˆæœ¬ 100% å‘åå…¼å®¹ã€‚

```python
# æ—§ä»£ç ç»§ç»­å·¥ä½œ
from features.alpha_factors import AlphaFactors

af = AlphaFactors(df)
result = af.add_all_alpha_factors()
```

### å¯ç”¨æ–°åŠŸèƒ½

```python
# æ¨èé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
af = AlphaFactors(
    df,
    inplace=False,                # å®‰å…¨æ¨¡å¼
    enable_leak_detection=False,  # å…³é—­æ£€æµ‹ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰
    enable_copy_on_write=True     # å¼€å¯CoWï¼ˆèŠ‚çœå†…å­˜ï¼‰
)

result = af.add_all_alpha_factors(show_cache_stats=False)
```

---

## ğŸš€ æ€§èƒ½æå‡

### å…³é”®æ”¹è¿›

| ä¼˜åŒ–é¡¹ | æå‡æ•ˆæœ | é€‚ç”¨åœºæ™¯ |
|--------|---------|---------|
| **å‘é‡åŒ–çº¿æ€§å›å½’** | 35å€ âš¡ | è¶‹åŠ¿å› å­è®¡ç®— |
| **å…±äº«ç¼“å­˜** | 2-3å€ âš¡ | é‡å¤è®¡ç®—åœºæ™¯ |
| **Copy-on-Write** | -50% å†…å­˜ ğŸ’¾ | å¤§æ•°æ®é›† |

### å®é™…æµ‹è¯•ç»“æœ

```
æ•°æ®è§„æ¨¡: 2000è¡Œ Ã— 5åˆ—
ä¼˜åŒ–å‰æ€»è€—æ—¶: 12.3ç§’
ä¼˜åŒ–åæ€»è€—æ—¶: 4.1ç§’
åŠ é€Ÿæ¯”: 3å€
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®

```python
import pandas as pd
from features.alpha_factors import AlphaFactors

# åŠ è½½æ•°æ®
df = pd.read_csv('stock_data.csv', index_col='date', parse_dates=True)

# åˆ›å»ºå› å­è®¡ç®—å™¨ï¼ˆæ¨èé…ç½®ï¼‰
af = AlphaFactors(
    df,
    inplace=False,                # ä¸ä¿®æ”¹åŸæ•°æ®
    enable_copy_on_write=True     # èŠ‚çœå†…å­˜
)

# è®¡ç®—æ‰€æœ‰å› å­
result = af.add_all_alpha_factors()

# è·å–å› å­åˆ—è¡¨
factor_names = af.get_factor_names()
print(f"ç”Ÿæˆäº† {len(factor_names)} ä¸ªå› å­")

# ä¿å­˜ç»“æœ
result.to_parquet('stock_features.parquet')
```

### 2. å¼€å‘/è°ƒè¯•é…ç½®

```python
# å¯ç”¨æ•°æ®æ³„æ¼æ£€æµ‹
af = AlphaFactors(
    df,
    enable_leak_detection=True,   # æ£€æµ‹æ•°æ®æ³„æ¼
    enable_copy_on_write=True
)

# æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
result = af.add_all_alpha_factors(show_cache_stats=True)

# è¾“å‡ºç¤ºä¾‹:
# ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡=56.3%, å‘½ä¸­=125, æœªå‘½ä¸­=97, å¤§å°=45/200
# âœ“ æ•°æ®æ³„æ¼æ£€æµ‹é€šè¿‡
```

### 3. æ‰¹é‡å¤„ç†å¤šä¸ªè‚¡ç¥¨

```python
stock_list = ['000001', '000002', '600000', '600036']

for stock_code in stock_list:
    df = load_stock_data(stock_code)

    af = AlphaFactors(df, enable_copy_on_write=True)
    result = af.add_all_alpha_factors()

    # ç¼“å­˜ä¼šè‡ªåŠ¨åœ¨ç›¸åŒå‘¨æœŸçš„è®¡ç®—ä¸­å¤ç”¨
    # æ— éœ€æ‰‹åŠ¨æ¸…ç†ï¼ˆé™¤éå†…å­˜ç´§å¼ ï¼‰

    save_result(stock_code, result)

# å¤„ç†å®Œæˆåæ¸…ç©ºç¼“å­˜ï¼ˆå¯é€‰ï¼‰
af.clear_cache()
```

### 4. å†…å­˜ä¼˜åŒ–ç­–ç•¥

```python
# æ–¹æ¡ˆA: æœ€çœå†…å­˜ï¼ˆç›´æ¥ä¿®æ”¹åŸæ•°æ®ï¼‰
af = AlphaFactors(df, inplace=True)
result = af.add_all_alpha_factors()
# æ³¨æ„ï¼šdf å·²è¢«ä¿®æ”¹

# æ–¹æ¡ˆB: å®‰å…¨ä¸”çœå†…å­˜ï¼ˆæ¨èï¼‰
af = AlphaFactors(df, inplace=False, enable_copy_on_write=True)
result = af.add_all_alpha_factors()
# df ä¸å˜ï¼Œresult åŒ…å«æ‰€æœ‰å› å­

# æ–¹æ¡ˆC: åˆ†æ®µè®¡ç®—ï¼ˆè¶…å¤§æ•°æ®é›†ï¼‰
af = AlphaFactors(df, enable_copy_on_write=True)

# åˆ†æ‰¹è®¡ç®—ï¼Œæ¯æ¬¡æ¸…ç©ºç¼“å­˜
af.momentum.calculate_all()
af.clear_cache()

af.trend.calculate_all()
af.clear_cache()

# ...
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•éªŒè¯æ€§èƒ½æå‡ï¼Ÿ

```python
import time

# æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
start = time.perf_counter()
af = AlphaFactors(df, enable_copy_on_write=True)
result = af.add_all_alpha_factors(show_cache_stats=True)
elapsed = time.perf_counter() - start

print(f"è®¡ç®—è€—æ—¶: {elapsed:.2f} ç§’")
print(f"ç”Ÿæˆå› å­: {len(af.get_factor_names())} ä¸ª")

# æŸ¥çœ‹ç¼“å­˜æ•ˆæœ
cache_stats = af.get_cache_stats()
print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
```

### Q2: æ•°æ®æ³„æ¼æ£€æµ‹å¦‚ä½•ä½¿ç”¨ï¼Ÿ

```python
# å¼€å‘é˜¶æ®µå»ºè®®å¯ç”¨
af = AlphaFactors(df, enable_leak_detection=True)
result = af.add_all_alpha_factors()

# å¦‚æœæ£€æµ‹åˆ°æ³„æ¼ï¼Œä¼šåœ¨æ—¥å¿—ä¸­è¾“å‡ºï¼š
# âš ï¸  æ£€æµ‹åˆ°æ•°æ®æ³„æ¼! å› å­ XXX ä¸æœªæ¥æ”¶ç›Šç›¸å…³æ€§: 0.97

# ç”Ÿäº§ç¯å¢ƒå»ºè®®å…³é—­ï¼ˆæå‡æ€§èƒ½ï¼‰
af = AlphaFactors(df, enable_leak_detection=False)
```

### Q3: Copy-on-Write æœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ

```python
# éœ€è¦ Pandas 2.0+
import pandas as pd
print(pd.__version__)  # åº”è¯¥ >= 2.0.0

# å¦‚æœæ˜¯æ—§ç‰ˆæœ¬ï¼Œä¼šè‡ªåŠ¨é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼
# ä»ç„¶å¯ä»¥æ­£å¸¸å·¥ä½œï¼Œåªæ˜¯å†…å­˜ä¼˜åŒ–æ•ˆæœé™ä½
```

### Q4: å¦‚ä½•æ¸…ç©ºç¼“å­˜ï¼Ÿ

```python
# æ–¹æ³•1: å®ä¾‹æ–¹æ³•
af.clear_cache()

# æ–¹æ³•2: ç±»æ–¹æ³•ï¼ˆæ¸…ç©ºæ‰€æœ‰å®ä¾‹çš„å…±äº«ç¼“å­˜ï¼‰
from features.alpha_factors import BaseFactorCalculator
BaseFactorCalculator._shared_cache.clear()
```

### Q5: å‘é‡åŒ–ç‰ˆæœ¬çš„ç»“æœä¸æ—§ç‰ˆæœ¬ä¸€è‡´å—ï¼Ÿ

**æ˜¯çš„ï¼Œå®Œå…¨ä¸€è‡´ã€‚** æˆ‘ä»¬ä½¿ç”¨äº†ç›¸åŒçš„æ•°å­¦å…¬å¼ï¼Œåªæ˜¯æ”¹å˜äº†è®¡ç®—æ–¹å¼ã€‚

```python
# éªŒè¯ç»“æœä¸€è‡´æ€§
import numpy as np

# æ—§ç‰ˆæœ¬ç»“æœï¼ˆä»å¤‡ä»½åŠ è½½ï¼‰
old_result = pd.read_parquet('old_factors.parquet')

# æ–°ç‰ˆæœ¬ç»“æœ
new_result = af.add_all_alpha_factors()

# å¯¹æ¯”ï¼ˆå…è®¸æµ®ç‚¹è¯¯å·®ï¼‰
for col in old_result.columns:
    if col in new_result.columns:
        diff = np.abs(new_result[col] - old_result[col])
        max_diff = diff.max()
        assert max_diff < 1e-10, f"{col} ç»“æœä¸ä¸€è‡´: {max_diff}"

print("âœ“ æ‰€æœ‰å› å­ç»“æœä¸€è‡´")
```

---

## ğŸ“Š ç¼“å­˜ç»Ÿè®¡è¯´æ˜

```python
cache_stats = af.get_cache_stats()

# è¿”å›å­—å…¸:
{
    'size': 45,           # å½“å‰ç¼“å­˜æ¡ç›®æ•°
    'max_size': 200,      # æœ€å¤§ç¼“å­˜å®¹é‡
    'hits': 125,          # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    'misses': 97,         # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    'hit_rate': 0.563     # å‘½ä¸­ç‡ (56.3%)
}

# å‘½ä¸­ç‡è¯´æ˜:
# - 0-30%: ä½æ•ˆï¼ˆè€ƒè™‘è°ƒæ•´è®¡ç®—é¡ºåºï¼‰
# - 30-60%: æ­£å¸¸ï¼ˆå¤šæ•°åœºæ™¯ï¼‰
# - 60%+: é«˜æ•ˆï¼ˆå¤§é‡é‡å¤è®¡ç®—è¢«ä¼˜åŒ–ï¼‰
```

---

## ğŸ¯ é€‰æ‹©åˆé€‚çš„é…ç½®

### åœºæ™¯ 1: å•æ¬¡è®¡ç®—ï¼ˆå°æ•°æ®é›† <1000è¡Œï¼‰

```python
# ä½¿ç”¨é»˜è®¤é…ç½®å³å¯
af = AlphaFactors(df)
result = af.add_all_alpha_factors()
```

### åœºæ™¯ 2: æ‰¹é‡è®¡ç®—ï¼ˆå¤šä¸ªè‚¡ç¥¨ï¼‰

```python
# å¯ç”¨ Copy-on-Write
af = AlphaFactors(df, enable_copy_on_write=True)
result = af.add_all_alpha_factors()
```

### åœºæ™¯ 3: å¤§æ•°æ®é›†ï¼ˆ>5000è¡Œï¼‰

```python
# å¯ç”¨ CoW + å®šæœŸæ¸…ç¼“å­˜
for chunk in data_chunks:
    af = AlphaFactors(chunk, enable_copy_on_write=True)
    result = af.add_all_alpha_factors()
    save(result)
    af.clear_cache()  # é‡Šæ”¾å†…å­˜
```

### åœºæ™¯ 4: å¼€å‘æ–°å› å­

```python
# å¯ç”¨æ³„æ¼æ£€æµ‹ + ç¼“å­˜ç»Ÿè®¡
af = AlphaFactors(
    df,
    enable_leak_detection=True,
    enable_copy_on_write=True
)
result = af.add_all_alpha_factors(show_cache_stats=True)
```

---

## ğŸ”— ç›¸å…³èµ„æº

- **è¯¦ç»†æŠ¥å‘Š**: [ALPHA_FACTORS_OPTIMIZATION_REPORT.md](ALPHA_FACTORS_OPTIMIZATION_REPORT.md)
- **æºä»£ç **: [core/src/features/alpha_factors.py](core/src/features/alpha_factors.py)
- **æµ‹è¯•æ–‡ä»¶**: [core/tests/test_alpha_factors_optimization.py](core/tests/test_alpha_factors_optimization.py)

---

## ğŸ†˜ é‡åˆ°é—®é¢˜ï¼Ÿ

### å¸¸è§é”™è¯¯æ’æŸ¥

**é”™è¯¯1: ModuleNotFoundError: No module named 'pandas'**
```bash
# å®‰è£…ä¾èµ–
pip install pandas numpy loguru
```

**é”™è¯¯2: å†…å­˜å ç”¨ä»ç„¶å¾ˆé«˜**
```python
# æ£€æŸ¥ Pandas ç‰ˆæœ¬
import pandas as pd
print(pd.__version__)

# å¦‚æœ < 2.0ï¼Œå‡çº§æˆ–ä½¿ç”¨ inplace=True
pip install --upgrade pandas

# æˆ–è€…
af = AlphaFactors(df, inplace=True)  # ç›´æ¥ä¿®æ”¹åŸæ•°æ®
```

**é”™è¯¯3: ç¼“å­˜å‘½ä¸­ç‡å¾ˆä½**
```python
# å¯èƒ½åŸå› ï¼šæ•°æ®é›†æ¯æ¬¡éƒ½ä¸åŒ
# è§£å†³æ–¹æ¡ˆï¼šæ‰¹é‡è®¡ç®—æ—¶å¤ç”¨ç›¸åŒçš„å‘¨æœŸå‚æ•°

# ä¸æ¨èï¼ˆå‘½ä¸­ç‡ä½ï¼‰
af1.add_momentum_factors(periods=[5, 10])
af2.add_momentum_factors(periods=[10, 20])

# æ¨èï¼ˆå‘½ä¸­ç‡é«˜ï¼‰
af1.add_momentum_factors(periods=[5, 10, 20])
af2.add_momentum_factors(periods=[5, 10, 20])
```

---

## âœ… å¿«é€ŸéªŒè¯

è¿è¡Œè¿™ä¸ªè„šæœ¬ç¡®è®¤ä¼˜åŒ–ç‰ˆæœ¬å·¥ä½œæ­£å¸¸ï¼š

```python
import pandas as pd
import numpy as np
from features.alpha_factors import AlphaFactors

# åˆ›å»ºæµ‹è¯•æ•°æ®
df = pd.DataFrame({
    'close': np.random.randn(500).cumsum() + 100,
    'volume': np.random.uniform(1e6, 1e7, 500)
})

# è®¡ç®—å› å­
af = AlphaFactors(df, enable_copy_on_write=True)
result = af.add_all_alpha_factors(show_cache_stats=True)

# éªŒè¯ç»“æœ
factor_names = af.get_factor_names()
print(f"âœ“ ç”Ÿæˆå› å­: {len(factor_names)} ä¸ª")
print(f"âœ“ æ•°æ®å½¢çŠ¶: {result.shape}")
print(f"âœ“ ç¼“å­˜ç»Ÿè®¡: {af.get_cache_stats()}")
print("\nä¼˜åŒ–ç‰ˆæœ¬å·¥ä½œæ­£å¸¸ï¼")
```

---

**æœ€åæ›´æ–°**: 2026-01-27
**ç‰ˆæœ¬**: 2.0-optimized
