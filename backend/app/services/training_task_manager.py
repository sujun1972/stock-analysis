"""
è®­ç»ƒä»»åŠ¡ç®¡ç†å™¨
è´Ÿè´£è®­ç»ƒä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import uuid
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from loguru import logger

from src.database.db_manager import DatabaseManager
from app.services.core_training import CoreTrainingService
from app.core.exceptions import BackendError, DatabaseError


class TrainingTaskManager:
    """
    è®­ç»ƒä»»åŠ¡ç®¡ç†å™¨

    èŒè´£ï¼š
    - åˆ›å»ºå’Œç®¡ç†è®­ç»ƒä»»åŠ¡
    - è·Ÿè¸ªä»»åŠ¡çŠ¶æ€
    - å­˜å‚¨ä»»åŠ¡å…ƒæ•°æ®
    - æ‰§è¡Œè®­ç»ƒæµç¨‹
    """

    def __init__(self, models_dir: Optional[Path] = None, db: Optional[DatabaseManager] = None):
        """
        åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨

            db: DatabaseManager å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºä¾èµ–æ³¨å…¥ï¼‰
        Args:
            models_dir: æ¨¡å‹å­˜å‚¨ç›®å½•
        """
        self.tasks: Dict[str, Dict[str, Any]] = {}  # å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€
        self.models_dir = models_dir or Path('/data/models/ml_models')
        self.models_dir.mkdir(parents=True, exist_ok=True)

        # ä»»åŠ¡å…ƒæ•°æ®å­˜å‚¨
        self.metadata_file = self.models_dir / 'tasks_metadata.json'
        self._load_metadata()

        # æ•°æ®åº“è¿æ¥
        self.db = db or DatabaseManager()

    def _load_metadata(self):
        """åŠ è½½ä»»åŠ¡å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r') as f:
                    self.tasks = json.load(f)
                logger.info(f"âœ“ åŠ è½½äº† {len(self.tasks)} ä¸ªå†å²ä»»åŠ¡")
            except (json.JSONDecodeError, IOError) as e:
                # æ–‡ä»¶æŸåæˆ–ä¸å­˜åœ¨
                logger.warning(f"å…ƒæ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸: {e}")
                self.tasks = {}
            except Exception as e:
                # å…¶ä»–æœªé¢„æœŸé”™è¯¯
                logger.error(f"åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
                self.tasks = {}

    def _save_metadata(self):
        """ä¿å­˜ä»»åŠ¡å…ƒæ•°æ®"""
        try:
            with open(self.metadata_file, 'w') as f:
                json.dump(self.tasks, f, indent=2, default=str)
        except (IOError, OSError) as e:
            # æ–‡ä»¶å†™å…¥å¤±è´¥
            logger.error(f"ä¿å­˜å…ƒæ•°æ®å¤±è´¥ (æ–‡ä»¶å†™å…¥é”™è¯¯): {e}")
        except Exception as e:
            # å…¶ä»–æœªé¢„æœŸé”™è¯¯
            logger.error(f"ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")

    async def create_task(self, config: Dict[str, Any]) -> str:
        """
        åˆ›å»ºè®­ç»ƒä»»åŠ¡

        Args:
            config: è®­ç»ƒé…ç½®

        Returns:
            task_id: ä»»åŠ¡ID
        """
        task_id = str(uuid.uuid4())

        task = {
            'task_id': task_id,
            'status': 'pending',
            'created_at': datetime.now().isoformat(),
            'config': config,
            'progress': 0,
            'current_step': 'å‡†å¤‡è®­ç»ƒ...',
            'metrics': {},
            'error': None,
            'error_message': None,
            'has_baseline': False,
            'baseline_metrics': None,
            'comparison_result': None,
            'recommendation': None,
            'total_samples': None,
            'successful_symbols': None
        }

        self.tasks[task_id] = task
        self._save_metadata()

        logger.info(f"âœ“ åˆ›å»ºè®­ç»ƒä»»åŠ¡: {task_id}")
        return task_id

    async def run_training(self, task_id: str):
        """
        æ‰§è¡Œè®­ç»ƒä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        task = self.tasks[task_id]

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'running'
        task['started_at'] = datetime.now().isoformat()
        self._save_metadata()

        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task_id}")

        try:
            await self._run_training(task_id)

            # è®­ç»ƒæˆåŠŸ
            task['status'] = 'completed'
            task['completed_at'] = datetime.now().isoformat()
            task['progress'] = 100

            logger.info(f"âœ“ è®­ç»ƒä»»åŠ¡å®Œæˆ: {task_id}")

        except BackendError as e:
            # å·²çŸ¥ä¸šåŠ¡å¼‚å¸¸
            task['status'] = 'failed'
            task['error'] = str(e)
            task['error_message'] = str(e)
            task['failed_at'] = datetime.now().isoformat()

            logger.error(f"âœ— è®­ç»ƒä»»åŠ¡å¤±è´¥ (ä¸šåŠ¡å¼‚å¸¸): {task_id} - {e}")
            raise
        except Exception as e:
            # æœªé¢„æœŸé”™è¯¯
            task['status'] = 'failed'
            task['error'] = str(e)
            task['error_message'] = str(e)
            task['failed_at'] = datetime.now().isoformat()

            logger.error(f"âœ— è®­ç»ƒä»»åŠ¡å¤±è´¥ (æœªé¢„æœŸé”™è¯¯): {task_id} - {e}")
            raise BackendError(
                f"è®­ç»ƒä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task_id}",
                error_code="TRAINING_TASK_FAILED",
                task_id=task_id,
                reason=str(e)
            )
        finally:
            self._save_metadata()

    async def _run_training(self, task_id: str):
        """
        æ‰§è¡Œå®é™…çš„è®­ç»ƒè¿‡ç¨‹

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        # æ£€æµ‹æ˜¯å¦å¯ç”¨æ± åŒ–è®­ç»ƒ
        enable_pooled = config.get('enable_pooled_training', False)
        symbols = config.get('symbols', [])

        if enable_pooled and len(symbols) > 1:
            # ä½¿ç”¨æ± åŒ–è®­ç»ƒPipeline
            await self._run_pooled_training(task_id)
        else:
            # ä½¿ç”¨å•è‚¡ç¥¨è®­ç»ƒ
            await self._run_single_stock_training(task_id)

    async def _run_single_stock_training(self, task_id: str):
        """
        æ‰§è¡Œå•è‚¡ç¥¨è®­ç»ƒï¼ˆåŸæœ‰é€»è¾‘ï¼‰

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        # ä½¿ç”¨ CoreTrainingService ç»Ÿä¸€è®­ç»ƒæµç¨‹
        core_service = CoreTrainingService()

        # å‡†å¤‡è®­ç»ƒé…ç½®
        training_config = {
            'symbol': config.get('symbol') or (config.get('symbols', [None])[0]),
            'start_date': config.get('start_date'),
            'end_date': config.get('end_date'),
            'model_type': config.get('model_type', 'lightgbm'),
            'target_period': config.get('target_period', 5),
            'scaler_type': config.get('scaler_type', 'robust'),
            'balance_samples': config.get('balance_samples', False),
            'model_params': config.get('model_params', {}),
            'use_async': True  # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if 'seq_length' in config:
            training_config['seq_length'] = config['seq_length']
        if 'epochs' in config:
            training_config['epochs'] = config['epochs']

        logger.info(f"[å•è‚¡ç¥¨è®­ç»ƒ] é…ç½®: {training_config}")

        # æ‰§è¡Œè®­ç»ƒ
        result = await asyncio.to_thread(
            core_service.train_model,
            **training_config
        )

        # ä¿å­˜è®­ç»ƒç»“æœ
        task['metrics'] = result.get('metrics', {})
        task['model_path'] = str(result.get('model_path', ''))
        task['feature_importance'] = result.get('feature_importance', {})
        task['has_baseline'] = False

        # æ›´æ–°è¿›åº¦
        task['progress'] = 100

        logger.info(f"âœ“ å•è‚¡ç¥¨è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹è·¯å¾„: {task['model_path']}")

        self._save_metadata()

    async def _run_pooled_training(self, task_id: str):
        """
        æ‰§è¡Œæ± åŒ–è®­ç»ƒï¼ˆå¤šè‚¡ç¥¨ + RidgeåŸºå‡†å¯¹æ¯”ï¼‰

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        logger.info(f"[æ± åŒ–è®­ç»ƒ] å¼€å§‹å¤šè‚¡ç¥¨æ± åŒ–è®­ç»ƒ")

        # å¯¼å…¥æ± åŒ–è®­ç»ƒPipeline
        from src.data_pipeline.pooled_training_pipeline import PooledTrainingPipeline

        # å‡†å¤‡å‚æ•°
        symbol_list = config.get('symbols', [])
        start_date = config.get('start_date')
        end_date = config.get('end_date')
        target_period = config.get('target_period', 10)
        model_type = config.get('model_type', 'lightgbm')
        enable_ridge_baseline = config.get('enable_ridge_baseline', True)

        # æ¨¡å‹å‚æ•°
        lightgbm_params = config.get('model_params', {
            'max_depth': 3,
            'num_leaves': 7,
            'n_estimators': 200,
            'learning_rate': 0.03,
            'min_child_samples': 100,
            'reg_alpha': 2.0,
            'reg_lambda': 2.0
        })

        ridge_params = config.get('ridge_params', {'alpha': 1.0})

        logger.info(f"[æ± åŒ–è®­ç»ƒ] è‚¡ç¥¨æ•°: {len(symbol_list)}, RidgeåŸºå‡†: {enable_ridge_baseline}")

        # æ›´æ–°è¿›åº¦
        task['progress'] = 10
        task['current_step'] = f"åŠ è½½ {len(symbol_list)} åªè‚¡ç¥¨æ•°æ®..."
        self._save_metadata()

        # åˆ›å»ºPipeline
        pipeline = PooledTrainingPipeline(
            scaler_type=config.get('scaler_type', 'robust'),
            verbose=True
        )

        # æ‰§è¡Œå®Œæ•´Pipeline
        result = await asyncio.to_thread(
            pipeline.run_full_pipeline,
            symbol_list=symbol_list,
            start_date=start_date,
            end_date=end_date,
            target_period=target_period,
            lightgbm_params=lightgbm_params,
            ridge_params=ridge_params,
            enable_ridge_baseline=enable_ridge_baseline
        )

        # ä¿å­˜ç»“æœ
        task['metrics'] = {
            'ic': result['lgb_metrics']['test_ic'],
            'rank_ic': result['lgb_metrics']['test_rank_ic'],
            'mae': result['lgb_metrics']['test_mae'],
            'r2': result['lgb_metrics']['test_r2'],
            'train_ic': result['lgb_metrics']['train_ic'],
            'valid_ic': result['lgb_metrics']['valid_ic']
        }

        task['has_baseline'] = result.get('has_baseline', False)
        task['baseline_metrics'] = result.get('ridge_metrics', {})
        task['comparison_result'] = result.get('comparison_result', {})
        task['recommendation'] = result.get('recommendation', '')
        task['total_samples'] = result.get('total_samples', 0)
        task['successful_symbols'] = result.get('successful_symbols', [])
        task['feature_importance'] = result.get('feature_importance', {})

        # æ¨¡å‹è·¯å¾„ï¼ˆå–LightGBMçš„è·¯å¾„ï¼‰
        task['model_path'] = str(result.get('lgb_model_path', ''))

        # æ›´æ–°è¿›åº¦
        task['progress'] = 100
        task['current_step'] = "è®­ç»ƒå®Œæˆ"

        logger.info(f"âœ“ æ± åŒ–è®­ç»ƒå®Œæˆï¼Œæ¨è: {task['recommendation']}")

        self._save_metadata()

        # ä¿å­˜åˆ°æ•°æ®åº“çš„ experiments è¡¨ï¼ˆå…ˆä¿å­˜è®­ç»ƒç»“æœï¼Œå†æ›´æ–°å›æµ‹ç»“æœï¼‰
        experiment_id = await self._save_pooled_experiment_to_db(task_id, result, config)

        # æ‰§è¡Œå›æµ‹ï¼ˆä¸å•è‚¡ç¥¨è®­ç»ƒä¸€è‡´ï¼‰
        if experiment_id:
            logger.info(f"[æ± åŒ–è®­ç»ƒ] å¼€å§‹å›æµ‹...")
            task['current_step'] = "å›æµ‹ä¸­..."
            task['progress'] = 95
            self._save_metadata()

            try:
                from app.services.backtest_service import BacktestService
                backtest_service = BacktestService(self.db)

                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„è‚¡ç¥¨ä»£ç è¿›è¡Œå›æµ‹ï¼ˆæ± åŒ–æ¨¡å‹å¯ä»¥ç”¨äºä»»æ„è‚¡ç¥¨ï¼‰
                symbol_for_backtest = task['successful_symbols'][0] if task['successful_symbols'] else config.get('symbols', [])[0]

                # æ‰§è¡Œå›æµ‹ï¼ˆæ³¨æ„ï¼šBacktestService.run_backtestæ˜¯asyncæ–¹æ³•ï¼‰
                # ä½¿ç”¨MLæ¨¡å‹ç­–ç•¥è¿›è¡Œå›æµ‹ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„æŠ€æœ¯æŒ‡æ ‡ç­–ç•¥
                backtest_result_full = await backtest_service.run_backtest(
                    symbols=symbol_for_backtest,  # å‚æ•°åæ˜¯ symbols
                    start_date=config.get('start_date'),
                    end_date=config.get('end_date'),
                    strategy_id='ml_model',  # âœ… ä½¿ç”¨MLæ¨¡å‹ç­–ç•¥
                    strategy_params={
                        'model_id': task_id,  # ä¼ å…¥è®­ç»ƒç”Ÿæˆçš„model_id
                        'buy_threshold': 0.15,  # é¢„æµ‹æ”¶ç›Šç‡è¶…è¿‡0.15%æ—¶ä¹°å…¥
                        'sell_threshold': -0.3,  # é¢„æµ‹æ”¶ç›Šç‡ä½äº-0.3%æ—¶å–å‡º
                    }
                )

                # æå– metrics éƒ¨åˆ†ä½œä¸ºå›æµ‹æŒ‡æ ‡
                backtest_result = backtest_result_full.get('metrics', {})

                # æ›´æ–°æ•°æ®åº“ä¸­çš„å›æµ‹ç»“æœ
                await self._update_pooled_backtest_result(experiment_id, backtest_result)

                # è®¡ç®—å¹¶æ›´æ–°ç»¼åˆè¯„åˆ†
                from app.services.model_ranker import ModelRanker
                ranker = ModelRanker(self.db)
                rank_score = ranker.calculate_rank_score(
                    train_metrics=task.get('metrics', {}),
                    backtest_metrics=backtest_result
                )
                await self._update_rank_score(experiment_id, rank_score)

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task['backtest_metrics'] = backtest_result
                task['rank_score'] = rank_score
                task['current_step'] = "å›æµ‹å®Œæˆ"
                task['progress'] = 100

                logger.info(f"âœ“ æ± åŒ–è®­ç»ƒå›æµ‹å®Œæˆï¼Œå¹´åŒ–æ”¶ç›Š: {backtest_result.get('annualized_return', 0):.2%}, è¯„åˆ†: {rank_score:.2f}")

            except Exception as e:
                logger.error(f"âœ— æ± åŒ–è®­ç»ƒå›æµ‹å¤±è´¥: {e}")
                # å›æµ‹å¤±è´¥ä¸å½±å“è®­ç»ƒç»“æœ
                task['backtest_error'] = str(e)
                task['current_step'] = "è®­ç»ƒå®Œæˆï¼ˆå›æµ‹å¤±è´¥ï¼‰"
                task['progress'] = 100

        self._save_metadata()

    def get_task(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.tasks.get(task_id)

    def list_tasks(
        self,
        status: Optional[str] = None,
        limit: int = 100,
        offset: int = 0
    ) -> Dict[str, Any]:
        """
        åˆ—å‡ºä»»åŠ¡

        Args:
            status: çŠ¶æ€è¿‡æ»¤
            limit: é™åˆ¶æ•°é‡
            offset: åç§»é‡

        Returns:
            ä»»åŠ¡åˆ—è¡¨å’Œæ€»æ•°
        """
        # è¿‡æ»¤ä»»åŠ¡
        filtered_tasks = []
        for task in self.tasks.values():
            if status is None or task.get('status') == status:
                filtered_tasks.append(task)

        # æ’åºï¼ˆæŒ‰åˆ›å»ºæ—¶é—´å€’åºï¼‰
        filtered_tasks.sort(
            key=lambda x: x.get('created_at', ''),
            reverse=True
        )

        # åˆ†é¡µ
        total = len(filtered_tasks)
        paginated_tasks = filtered_tasks[offset:offset + limit]

        return {
            'tasks': paginated_tasks,
            'total': total,
            'limit': limit,
            'offset': offset
        }

    def cancel_task(self, task_id: str):
        """
        å–æ¶ˆä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        task = self.tasks[task_id]

        if task['status'] not in ['pending', 'running']:
            raise ValueError(f"ä»»åŠ¡æ— æ³•å–æ¶ˆï¼Œå½“å‰çŠ¶æ€: {task['status']}")

        task['status'] = 'cancelled'
        task['cancelled_at'] = datetime.now().isoformat()
        self._save_metadata()

        logger.info(f"âœ“ ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")

    def delete_task(self, task_id: str):
        """
        åˆ é™¤ä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        del self.tasks[task_id]
        self._save_metadata()

        logger.info(f"âœ“ ä»»åŠ¡å·²åˆ é™¤: {task_id}")

    async def _save_pooled_experiment_to_db(
        self,
        task_id: str,
        result: Dict[str, Any],
        config: Dict[str, Any]
    ) -> Optional[int]:
        """
        ä¿å­˜æ± åŒ–è®­ç»ƒç»“æœåˆ°æ•°æ®åº“çš„ experiments è¡¨

        Args:
            task_id: ä»»åŠ¡ID
            result: è®­ç»ƒç»“æœ
            config: è®­ç»ƒé…ç½®

        Returns:
            å®éªŒID (experiment.id)ï¼Œå¦‚æœä¿å­˜å¤±è´¥åˆ™è¿”å›None
        """
        from psycopg2.extras import Json

        try:
            # ç”Ÿæˆæ¨¡å‹åç§°ï¼šPOOLED_symbols_modeltype_period
            symbols = config.get('symbols', [])
            symbols_str = '_'.join(symbols[:3]) + (f'_plus{len(symbols)-3}' if len(symbols) > 3 else '')
            model_type = config.get('model_type', 'lightgbm')
            target_period = config.get('target_period', 10)
            experiment_name = f"POOLED_{symbols_str}_{model_type}_{target_period}d"

            # å‡†å¤‡æ’å…¥æ•°æ®
            # æ‰©å±•configï¼Œæ·»åŠ è®­ç»ƒç»“æœä¸­çš„å…³é”®ä¿¡æ¯
            extended_config = config.copy()
            extended_config['feature_cols'] = result.get('feature_cols', [])
            extended_config['scaler_path'] = result.get('scaler_path', '')
            extended_config['feature_count'] = result.get('feature_count', 0)

            insert_data = {
                'batch_id': None,  # æ‰‹åŠ¨è®­ç»ƒä¸å±äºæ‰¹æ¬¡
                'experiment_name': experiment_name,
                'model_id': task_id,  # ä½¿ç”¨task_idä½œä¸ºmodel_id
                'model_path': result.get('lgb_model_path', ''),
                'config': Json(extended_config),
                'train_metrics': Json({
                    'ic': result['lgb_metrics']['test_ic'],
                    'rank_ic': result['lgb_metrics']['test_rank_ic'],
                    'mae': result['lgb_metrics']['test_mae'],
                    'r2': result['lgb_metrics']['test_r2'],
                    'rmse': result['lgb_metrics'].get('test_rmse', 0),
                    'train_ic': result['lgb_metrics']['train_ic'],
                    'valid_ic': result['lgb_metrics']['valid_ic'],
                    'test_ic': result['lgb_metrics']['test_ic']
                }),
                'status': 'completed',
                'has_baseline': result.get('has_baseline', False),
                'baseline_metrics': Json(result.get('ridge_metrics', {})),
                'comparison_result': Json(result.get('comparison_result', {})),
                'recommendation': result.get('recommendation', ''),
                'total_samples': result.get('total_samples', 0),
                'successful_symbols': result.get('successful_symbols', [])
            }

            # æ‰§è¡Œæ’å…¥
            query = """
                INSERT INTO experiments (
                    batch_id, experiment_name, model_id, model_path,
                    config, train_metrics, status,
                    has_baseline, baseline_metrics, comparison_result,
                    recommendation, total_samples, successful_symbols,
                    created_at, train_completed_at
                )
                VALUES (
                    %(batch_id)s, %(experiment_name)s, %(model_id)s, %(model_path)s,
                    %(config)s, %(train_metrics)s, %(status)s,
                    %(has_baseline)s, %(baseline_metrics)s, %(comparison_result)s,
                    %(recommendation)s, %(total_samples)s, %(successful_symbols)s,
                    NOW(), NOW()
                )
                RETURNING id
            """

            # ä½¿ç”¨è¿æ¥æ± ç›´æ¥æ‰§è¡ŒSQL
            conn = self.db.get_connection()
            try:
                with conn.cursor() as cur:
                    cur.execute(query, insert_data)
                    result = cur.fetchone()
                    conn.commit()

                    if result:
                        exp_id = result[0]
                        logger.info(f"âœ“ æ± åŒ–è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå®éªŒID: {exp_id}")
                        return exp_id
                    else:
                        logger.warning(f"âš ï¸  æ± åŒ–è®­ç»ƒç»“æœä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
                        return None
            finally:
                self.db.release_connection(conn)

        except DatabaseError as e:
            logger.error(f"âœ— ä¿å­˜æ± åŒ–è®­ç»ƒç»“æœåˆ°æ•°æ®åº“æ—¶å‡ºé”™ (æ•°æ®åº“é”™è¯¯): {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹
            return None
        except Exception as e:
            logger.error(f"âœ— ä¿å­˜æ± åŒ–è®­ç»ƒç»“æœåˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹
            return None

    async def _update_pooled_backtest_result(
        self,
        exp_id: int,
        backtest_metrics: Dict[str, Any]
    ):
        """
        æ›´æ–°æ± åŒ–è®­ç»ƒå®éªŒçš„å›æµ‹ç»“æœ

        Args:
            exp_id: å®éªŒID
            backtest_metrics: å›æµ‹æŒ‡æ ‡
        """
        from psycopg2.extras import Json
        from datetime import datetime

        try:
            query = """
                UPDATE experiments
                SET backtest_status = 'completed',
                    backtest_metrics = %s,
                    backtest_completed_at = %s
                WHERE id = %s
            """

            params = (
                Json(backtest_metrics) if backtest_metrics else None,
                datetime.now(),
                exp_id
            )

            # ä½¿ç”¨è¿æ¥æ± æ‰§è¡Œæ›´æ–°
            conn = self.db.get_connection()
            try:
                with conn.cursor() as cur:
                    cur.execute(query, params)
                    conn.commit()
                    logger.info(f"âœ“ æ± åŒ–è®­ç»ƒå›æµ‹ç»“æœå·²æ›´æ–°åˆ°æ•°æ®åº“ï¼Œå®éªŒID: {exp_id}")
            finally:
                self.db.release_connection(conn)

        except DatabaseError as e:
            logger.error(f"âœ— æ›´æ–°æ± åŒ–è®­ç»ƒå›æµ‹ç»“æœæ—¶å‡ºé”™ (æ•°æ®åº“é”™è¯¯): {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹
        except Exception as e:
            logger.error(f"âœ— æ›´æ–°æ± åŒ–è®­ç»ƒå›æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹

    async def _update_rank_score(
        self,
        exp_id: int,
        rank_score: float
    ):
        """
        æ›´æ–°å®éªŒçš„ç»¼åˆè¯„åˆ†

        Args:
            exp_id: å®éªŒID
            rank_score: ç»¼åˆè¯„åˆ†
        """
        try:
            query = """
                UPDATE experiments
                SET rank_score = %s
                WHERE id = %s
            """

            params = (rank_score, exp_id)

            # ä½¿ç”¨è¿æ¥æ± æ‰§è¡Œæ›´æ–°
            conn = self.db.get_connection()
            try:
                with conn.cursor() as cur:
                    cur.execute(query, params)
                    conn.commit()
                    logger.info(f"âœ“ ç»¼åˆè¯„åˆ†å·²æ›´æ–°åˆ°æ•°æ®åº“ï¼Œå®éªŒID: {exp_id}, è¯„åˆ†: {rank_score:.2f}")
            finally:
                self.db.release_connection(conn)

        except DatabaseError as e:
            logger.error(f"âœ— æ›´æ–°ç»¼åˆè¯„åˆ†æ—¶å‡ºé”™ (æ•°æ®åº“é”™è¯¯): {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹
        except Exception as e:
            logger.error(f"âœ— æ›´æ–°ç»¼åˆè¯„åˆ†æ—¶å‡ºé”™: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹
