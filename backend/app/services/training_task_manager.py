"""
è®­ç»ƒä»»åŠ¡ç®¡ç†å™¨
è´Ÿè´£è®­ç»ƒä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import uuid
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from loguru import logger

from src.database.db_manager import DatabaseManager
from app.services.core_training import CoreTrainingService


class TrainingTaskManager:
    """
    è®­ç»ƒä»»åŠ¡ç®¡ç†å™¨

    èŒè´£ï¼š
    - åˆ›å»ºå’Œç®¡ç†è®­ç»ƒä»»åŠ¡
    - è·Ÿè¸ªä»»åŠ¡çŠ¶æ€
    - å­˜å‚¨ä»»åŠ¡å…ƒæ•°æ®
    - æ‰§è¡Œè®­ç»ƒæµç¨‹
    """

    def __init__(self, models_dir: Optional[Path] = None, db: Optional[DatabaseManager] = None):
        """
        åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨

            db: DatabaseManager å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºä¾èµ–æ³¨å…¥ï¼‰
        Args:
            models_dir: æ¨¡å‹å­˜å‚¨ç›®å½•
        """
        self.tasks: Dict[str, Dict[str, Any]] = {}  # å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€
        self.models_dir = models_dir or Path('/data/models/ml_models')
        self.models_dir.mkdir(parents=True, exist_ok=True)

        # ä»»åŠ¡å…ƒæ•°æ®å­˜å‚¨
        self.metadata_file = self.models_dir / 'tasks_metadata.json'
        self._load_metadata()

        # æ•°æ®åº“è¿æ¥
        self.db = db or DatabaseManager()

    def _load_metadata(self):
        """åŠ è½½ä»»åŠ¡å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r') as f:
                    self.tasks = json.load(f)
                logger.info(f"âœ“ åŠ è½½äº† {len(self.tasks)} ä¸ªå†å²ä»»åŠ¡")
            except Exception as e:
                logger.error(f"åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
                self.tasks = {}

    def _save_metadata(self):
        """ä¿å­˜ä»»åŠ¡å…ƒæ•°æ®"""
        try:
            with open(self.metadata_file, 'w') as f:
                json.dump(self.tasks, f, indent=2, default=str)
        except Exception as e:
            logger.error(f"ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")

    async def create_task(self, config: Dict[str, Any]) -> str:
        """
        åˆ›å»ºè®­ç»ƒä»»åŠ¡

        Args:
            config: è®­ç»ƒé…ç½®

        Returns:
            task_id: ä»»åŠ¡ID
        """
        task_id = str(uuid.uuid4())

        task = {
            'task_id': task_id,
            'status': 'pending',
            'created_at': datetime.now().isoformat(),
            'config': config,
            'progress': 0,
            'current_step': 'å‡†å¤‡è®­ç»ƒ...',
            'metrics': {},
            'error': None,
            'error_message': None,
            'has_baseline': False,
            'baseline_metrics': None,
            'comparison_result': None,
            'recommendation': None,
            'total_samples': None,
            'successful_symbols': None
        }

        self.tasks[task_id] = task
        self._save_metadata()

        logger.info(f"âœ“ åˆ›å»ºè®­ç»ƒä»»åŠ¡: {task_id}")
        return task_id

    async def run_training(self, task_id: str):
        """
        æ‰§è¡Œè®­ç»ƒä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        task = self.tasks[task_id]

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'running'
        task['started_at'] = datetime.now().isoformat()
        self._save_metadata()

        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task_id}")

        try:
            await self._run_training(task_id)

            # è®­ç»ƒæˆåŠŸ
            task['status'] = 'completed'
            task['completed_at'] = datetime.now().isoformat()
            task['progress'] = 100

            logger.info(f"âœ“ è®­ç»ƒä»»åŠ¡å®Œæˆ: {task_id}")

        except Exception as e:
            # è®­ç»ƒå¤±è´¥
            task['status'] = 'failed'
            task['error'] = str(e)
            task['error_message'] = str(e)
            task['failed_at'] = datetime.now().isoformat()

            logger.error(f"âœ— è®­ç»ƒä»»åŠ¡å¤±è´¥: {task_id} - {e}")
            raise

        finally:
            self._save_metadata()

    async def _run_training(self, task_id: str):
        """
        æ‰§è¡Œå®é™…çš„è®­ç»ƒè¿‡ç¨‹

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        # æ£€æµ‹æ˜¯å¦å¯ç”¨æ± åŒ–è®­ç»ƒ
        enable_pooled = config.get('enable_pooled_training', False)
        symbols = config.get('symbols', [])

        if enable_pooled and len(symbols) > 1:
            # ä½¿ç”¨æ± åŒ–è®­ç»ƒPipeline
            await self._run_pooled_training(task_id)
        else:
            # ä½¿ç”¨å•è‚¡ç¥¨è®­ç»ƒ
            await self._run_single_stock_training(task_id)

    async def _run_single_stock_training(self, task_id: str):
        """
        æ‰§è¡Œå•è‚¡ç¥¨è®­ç»ƒï¼ˆåŸæœ‰é€»è¾‘ï¼‰

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        # ä½¿ç”¨ CoreTrainingService ç»Ÿä¸€è®­ç»ƒæµç¨‹
        core_service = CoreTrainingService()

        # å‡†å¤‡è®­ç»ƒé…ç½®
        training_config = {
            'symbol': config.get('symbol') or (config.get('symbols', [None])[0]),
            'start_date': config.get('start_date'),
            'end_date': config.get('end_date'),
            'model_type': config.get('model_type', 'lightgbm'),
            'target_period': config.get('target_period', 5),
            'scaler_type': config.get('scaler_type', 'robust'),
            'balance_samples': config.get('balance_samples', False),
            'model_params': config.get('model_params', {}),
            'use_async': True  # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if 'seq_length' in config:
            training_config['seq_length'] = config['seq_length']
        if 'epochs' in config:
            training_config['epochs'] = config['epochs']

        logger.info(f"[å•è‚¡ç¥¨è®­ç»ƒ] é…ç½®: {training_config}")

        # æ‰§è¡Œè®­ç»ƒ
        result = await asyncio.to_thread(
            core_service.train_model,
            **training_config
        )

        # ä¿å­˜è®­ç»ƒç»“æœ
        task['metrics'] = result.get('metrics', {})
        task['model_path'] = str(result.get('model_path', ''))
        task['feature_importance'] = result.get('feature_importance', {})
        task['has_baseline'] = False

        # æ›´æ–°è¿›åº¦
        task['progress'] = 100

        logger.info(f"âœ“ å•è‚¡ç¥¨è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹è·¯å¾„: {task['model_path']}")

        self._save_metadata()

    async def _run_pooled_training(self, task_id: str):
        """
        æ‰§è¡Œæ± åŒ–è®­ç»ƒï¼ˆå¤šè‚¡ç¥¨ + RidgeåŸºå‡†å¯¹æ¯”ï¼‰

        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.tasks[task_id]
        config = task['config']

        logger.info(f"[æ± åŒ–è®­ç»ƒ] å¼€å§‹å¤šè‚¡ç¥¨æ± åŒ–è®­ç»ƒ")

        # å¯¼å…¥æ± åŒ–è®­ç»ƒPipeline
        from src.data_pipeline.pooled_training_pipeline import PooledTrainingPipeline

        # å‡†å¤‡å‚æ•°
        symbol_list = config.get('symbols', [])
        start_date = config.get('start_date')
        end_date = config.get('end_date')
        target_period = config.get('target_period', 10)
        model_type = config.get('model_type', 'lightgbm')
        enable_ridge_baseline = config.get('enable_ridge_baseline', True)

        # æ¨¡å‹å‚æ•°
        lightgbm_params = config.get('model_params', {
            'max_depth': 3,
            'num_leaves': 7,
            'n_estimators': 200,
            'learning_rate': 0.03,
            'min_child_samples': 100,
            'reg_alpha': 2.0,
            'reg_lambda': 2.0
        })

        ridge_params = config.get('ridge_params', {'alpha': 1.0})

        logger.info(f"[æ± åŒ–è®­ç»ƒ] è‚¡ç¥¨æ•°: {len(symbol_list)}, RidgeåŸºå‡†: {enable_ridge_baseline}")

        # æ›´æ–°è¿›åº¦
        task['progress'] = 10
        task['current_step'] = f"åŠ è½½ {len(symbol_list)} åªè‚¡ç¥¨æ•°æ®..."
        self._save_metadata()

        # åˆ›å»ºPipeline
        pipeline = PooledTrainingPipeline(
            scaler_type=config.get('scaler_type', 'robust'),
            verbose=True
        )

        # æ‰§è¡Œå®Œæ•´Pipeline
        result = await asyncio.to_thread(
            pipeline.run_full_pipeline,
            symbol_list=symbol_list,
            start_date=start_date,
            end_date=end_date,
            target_period=target_period,
            lightgbm_params=lightgbm_params,
            ridge_params=ridge_params,
            enable_ridge_baseline=enable_ridge_baseline
        )

        # ä¿å­˜ç»“æœ
        task['metrics'] = {
            'ic': result['lgb_metrics']['test_ic'],
            'rank_ic': result['lgb_metrics']['test_rank_ic'],
            'mae': result['lgb_metrics']['test_mae'],
            'r2': result['lgb_metrics']['test_r2'],
            'train_ic': result['lgb_metrics']['train_ic'],
            'valid_ic': result['lgb_metrics']['valid_ic']
        }

        task['has_baseline'] = result.get('has_baseline', False)
        task['baseline_metrics'] = result.get('ridge_metrics', {})
        task['comparison_result'] = result.get('comparison_result', {})
        task['recommendation'] = result.get('recommendation', '')
        task['total_samples'] = result.get('total_samples', 0)
        task['successful_symbols'] = result.get('successful_symbols', [])
        task['feature_importance'] = result.get('feature_importance', {})

        # æ¨¡å‹è·¯å¾„ï¼ˆå–LightGBMçš„è·¯å¾„ï¼‰
        task['model_path'] = str(result.get('lgb_model_path', ''))

        # æ›´æ–°è¿›åº¦
        task['progress'] = 100
        task['current_step'] = "è®­ç»ƒå®Œæˆ"

        logger.info(f"âœ“ æ± åŒ–è®­ç»ƒå®Œæˆï¼Œæ¨è: {task['recommendation']}")

        self._save_metadata()

    def get_task(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.tasks.get(task_id)

    def list_tasks(
        self,
        status: Optional[str] = None,
        limit: int = 100,
        offset: int = 0
    ) -> Dict[str, Any]:
        """
        åˆ—å‡ºä»»åŠ¡

        Args:
            status: çŠ¶æ€è¿‡æ»¤
            limit: é™åˆ¶æ•°é‡
            offset: åç§»é‡

        Returns:
            ä»»åŠ¡åˆ—è¡¨å’Œæ€»æ•°
        """
        # è¿‡æ»¤ä»»åŠ¡
        filtered_tasks = []
        for task in self.tasks.values():
            if status is None or task.get('status') == status:
                filtered_tasks.append(task)

        # æ’åºï¼ˆæŒ‰åˆ›å»ºæ—¶é—´å€’åºï¼‰
        filtered_tasks.sort(
            key=lambda x: x.get('created_at', ''),
            reverse=True
        )

        # åˆ†é¡µ
        total = len(filtered_tasks)
        paginated_tasks = filtered_tasks[offset:offset + limit]

        return {
            'tasks': paginated_tasks,
            'total': total,
            'limit': limit,
            'offset': offset
        }

    def cancel_task(self, task_id: str):
        """
        å–æ¶ˆä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        task = self.tasks[task_id]

        if task['status'] not in ['pending', 'running']:
            raise ValueError(f"ä»»åŠ¡æ— æ³•å–æ¶ˆï¼Œå½“å‰çŠ¶æ€: {task['status']}")

        task['status'] = 'cancelled'
        task['cancelled_at'] = datetime.now().isoformat()
        self._save_metadata()

        logger.info(f"âœ“ ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")

    def delete_task(self, task_id: str):
        """
        åˆ é™¤ä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id not in self.tasks:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        del self.tasks[task_id]
        self._save_metadata()

        logger.info(f"âœ“ ä»»åŠ¡å·²åˆ é™¤: {task_id}")
