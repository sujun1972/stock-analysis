"""
å®éªŒç®¡ç†æœåŠ¡
ç®¡ç†æ‰¹é‡è®­ç»ƒå’Œå›æµ‹å®éªŒçš„ç”Ÿå‘½å‘¨æœŸ
"""

import asyncio
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

from loguru import logger

# å¯¼å…¥coreæ¨¡å—
import sys
sys.path.insert(0, '/app/src')

from src.data_pipeline import DataPipeline
from src.models.model_trainer import ModelTrainer
from src.database.db_manager import DatabaseManager

from app.services.parameter_grid import ParameterGrid
from app.services.ml_training_service import MLTrainingService
from app.services.backtest_service import BacktestService


class ExperimentService:
    """å®éªŒç®¡ç†æœåŠ¡"""

    def __init__(self):
        self.db = DatabaseManager()
        self.ml_service = MLTrainingService()
        self.backtest_service = BacktestService()

        # ä»»åŠ¡é˜Ÿåˆ—
        self.running_batches: Dict[int, asyncio.Task] = {}

    # ==================== æ‰¹æ¬¡ç®¡ç† ====================

    async def create_batch(
        self,
        batch_name: str,
        param_space: Dict[str, Any],
        strategy: str = 'grid',
        max_experiments: Optional[int] = None,
        description: Optional[str] = None,
        config: Optional[Dict] = None,
        tags: Optional[List[str]] = None
    ) -> int:
        """
        åˆ›å»ºå®éªŒæ‰¹æ¬¡

        Args:
            batch_name: æ‰¹æ¬¡åç§°ï¼ˆå”¯ä¸€ï¼‰
            param_space: å‚æ•°ç©ºé—´å®šä¹‰
            strategy: å‚æ•°ç”Ÿæˆç­–ç•¥ ('grid', 'random', 'bayesian')
            max_experiments: æœ€å¤§å®éªŒæ•°ï¼ˆä»…å¯¹random/bayesianæœ‰æ•ˆï¼‰
            description: æ‰¹æ¬¡æè¿°
            config: æ‰¹æ¬¡çº§åˆ«é…ç½®ï¼ˆå¹¶è¡Œåº¦ã€å›æµ‹è®¾ç½®ç­‰ï¼‰
            tags: æ ‡ç­¾åˆ—è¡¨

        Returns:
            batch_id
        """
        logger.info(f"ğŸ“¦ åˆ›å»ºå®éªŒæ‰¹æ¬¡: {batch_name}")

        try:
            # 1. ç”Ÿæˆå‚æ•°ç»„åˆ
            param_grid = ParameterGrid(param_space)
            experiment_configs = param_grid.generate(
                strategy=strategy,
                max_experiments=max_experiments
            )

            total_experiments = len(experiment_configs)
            logger.info(f"âœ… ç”Ÿæˆäº† {total_experiments} ä¸ªå®éªŒé…ç½®")

            # 2. åˆ›å»ºæ‰¹æ¬¡è®°å½•
            batch_config = config or {}
            batch_config.setdefault('auto_backtest', True)
            batch_config.setdefault('max_workers', 3)
            batch_config.setdefault('save_models', True)

            insert_query = """
                INSERT INTO experiment_batches (
                    batch_name, description, strategy, param_space,
                    total_experiments, config, tags
                )
                VALUES (%s, %s, %s, %s::jsonb, %s, %s::jsonb, %s)
                RETURNING id
            """

            # ä½¿ç”¨æ‰‹åŠ¨äº‹åŠ¡ç®¡ç†
            conn = self.db.get_connection()
            cursor = conn.cursor()

            try:
                cursor.execute(
                    insert_query,
                    (
                        batch_name,
                        description,
                        strategy,
                        json.dumps(param_space),
                        total_experiments,
                        json.dumps(batch_config),
                        tags or []
                    )
                )
                result = cursor.fetchone()
                batch_id = result[0]
                conn.commit()
                logger.info(f"âœ… æ‰¹æ¬¡ID: {batch_id}")
            except Exception as e:
                conn.rollback()
                error_msg = str(e)
                logger.error(f"âŒ åˆ›å»ºæ‰¹æ¬¡è®°å½•å¤±è´¥: {error_msg}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯å”¯ä¸€æ€§çº¦æŸå†²çª
                if 'experiment_batches_batch_name_key' in error_msg or 'duplicate key value' in error_msg:
                    raise ValueError(f"æ‰¹æ¬¡åç§° '{batch_name}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°")
                raise
            finally:
                cursor.close()
                self.db.release_connection(conn)

            # 3. åˆ›å»ºå®éªŒè®°å½•
            await self._create_experiments(batch_id, experiment_configs)

            return batch_id

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ‰¹æ¬¡å¤±è´¥: {e}")
            raise

    async def _create_experiments(self, batch_id: int, configs: List[Dict]):
        """æ‰¹é‡åˆ›å»ºå®éªŒè®°å½•"""

        logger.info(f"ğŸ“ åˆ›å»º {len(configs)} ä¸ªå®éªŒè®°å½•...")

        insert_query = """
            INSERT INTO experiments (
                batch_id, experiment_name, experiment_hash, config, status
            )
            VALUES (%s, %s, %s, %s::jsonb, 'pending')
        """

        values = []
        for config in configs:
            exp_name = self._generate_experiment_name(config)
            exp_hash = config.pop('experiment_hash', None)  # ç§»é™¤å“ˆå¸Œå­—æ®µ

            values.append((
                batch_id,
                exp_name,
                exp_hash,
                json.dumps(config)
            ))

        # æ‰¹é‡æ’å…¥
        conn = self.db.get_connection()
        cursor = conn.cursor()

        try:
            cursor.executemany(insert_query, values)
            conn.commit()
            logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(values)} ä¸ªå®éªŒè®°å½•")
        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
            raise
        finally:
            cursor.close()
            self.db.release_connection(conn)

    def _generate_experiment_name(self, config: Dict) -> str:
        """ç”Ÿæˆå®éªŒåç§°"""
        symbol = config.get('symbol', 'unknown')
        model_type = config.get('model_type', 'unknown')
        target_period = config.get('target_period', 0)
        scaler = config.get('scaler_type', 'unknown')

        return f"{symbol}_{model_type}_T{target_period}_{scaler}"

    # ==================== æ‰¹æ¬¡æ‰§è¡Œ ====================

    async def run_batch(
        self,
        batch_id: int,
        max_workers: Optional[int] = None
    ):
        """
        è¿è¡Œå®éªŒæ‰¹æ¬¡

        Args:
            batch_id: æ‰¹æ¬¡ID
            max_workers: æœ€å¤§å¹¶è¡ŒWorkeræ•°ï¼ˆè¦†ç›–æ‰¹æ¬¡é…ç½®ï¼‰
        """
        logger.info(f"ğŸš€ å¯åŠ¨æ‰¹æ¬¡ {batch_id}")

        try:
            # 1. æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
            await self._update_batch_status(batch_id, 'running', started_at=datetime.now())

            # 2. è·å–æ‰¹æ¬¡é…ç½®
            batch_config = await self._get_batch_config(batch_id)
            workers = max_workers or batch_config.get('max_workers', 3)
            auto_backtest = batch_config.get('auto_backtest', True)

            logger.info(f"âš™ï¸  é…ç½®: {workers} ä¸ªWorker, è‡ªåŠ¨å›æµ‹={auto_backtest}")

            # 3. è·å–å¾…æ‰§è¡Œå®éªŒ
            experiments = await self._get_pending_experiments(batch_id)
            logger.info(f"ğŸ“‹ å¾…æ‰§è¡Œå®éªŒ: {len(experiments)} ä¸ª")

            if not experiments:
                logger.warning("âš ï¸  æ²¡æœ‰å¾…æ‰§è¡Œçš„å®éªŒ")
                await self._update_batch_status(batch_id, 'completed', completed_at=datetime.now())
                return

            # 4. åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
            queue = asyncio.Queue()
            for exp in experiments:
                await queue.put(exp)

            # 5. å¯åŠ¨Workeræ± 
            tasks = []
            for i in range(workers):
                task = asyncio.create_task(
                    self._experiment_worker(
                        worker_id=i,
                        batch_id=batch_id,
                        queue=queue,
                        auto_backtest=auto_backtest
                    )
                )
                tasks.append(task)

            # 6. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            await queue.join()

            # 7. åœæ­¢Workers
            for task in tasks:
                task.cancel()

            await asyncio.gather(*tasks, return_exceptions=True)

            # 8. è®¡ç®—æ’å
            await self._calculate_rankings(batch_id)

            # 9. æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
            await self._update_batch_status(batch_id, 'completed', completed_at=datetime.now())

            logger.info(f"ğŸ‰ æ‰¹æ¬¡ {batch_id} æ‰§è¡Œå®Œæˆï¼")

        except Exception as e:
            logger.error(f"âŒ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
            await self._update_batch_status(batch_id, 'failed')
            raise

    async def _experiment_worker(
        self,
        worker_id: int,
        batch_id: int,
        queue: asyncio.Queue,
        auto_backtest: bool
    ):
        """å®éªŒæ‰§è¡ŒWorker"""

        logger.info(f"ğŸ”§ Worker-{worker_id} å¯åŠ¨")

        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–å®éªŒ
                experiment = await queue.get()

                exp_id = experiment[0]
                # configå­—æ®µæ˜¯JSONBç±»å‹ï¼Œæ•°æ®åº“å·²è‡ªåŠ¨è½¬æ¢ä¸ºdictï¼Œæ— éœ€json.loads
                exp_config = experiment[3] if isinstance(experiment[3], dict) else json.loads(experiment[3])

                logger.info(f"[Worker-{worker_id}] ğŸ”¬ å¼€å§‹å®éªŒ {exp_id}: {experiment[2]}")

                # æ‰§è¡Œå®éªŒ
                await self._run_single_experiment(
                    exp_id=exp_id,
                    config=exp_config,
                    auto_backtest=auto_backtest,
                    worker_id=worker_id
                )

                # æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
                await self._increment_batch_counter(batch_id, 'completed')

            except asyncio.CancelledError:
                logger.info(f"ğŸ›‘ Worker-{worker_id} åœæ­¢")
                break
            except Exception as e:
                logger.error(f"[Worker-{worker_id}] âŒ å®éªŒå¤±è´¥: {e}")
                await self._mark_experiment_failed(exp_id, str(e))
                await self._increment_batch_counter(batch_id, 'failed')
            finally:
                queue.task_done()

    async def _run_single_experiment(
        self,
        exp_id: int,
        config: Dict,
        auto_backtest: bool,
        worker_id: int
    ):
        """æ‰§è¡Œå•ä¸ªå®éªŒ"""

        start_time = datetime.now()

        try:
            # 1. æ›´æ–°çŠ¶æ€ä¸ºè®­ç»ƒä¸­
            await self._update_experiment_status(exp_id, 'training', train_started_at=start_time)

            # 2. è®­ç»ƒæ¨¡å‹
            logger.info(f"[Worker-{worker_id}] ğŸ‹ï¸  è®­ç»ƒæ¨¡å‹...")
            model_id, train_metrics, feature_importance, model_path = await self._train_model_async(config)

            train_end_time = datetime.now()
            train_duration = (train_end_time - start_time).total_seconds()

            # 3. ä¿å­˜è®­ç»ƒç»“æœ
            await self._update_experiment_train_result(
                exp_id=exp_id,
                model_id=model_id,
                train_metrics=train_metrics,
                feature_importance=feature_importance,
                model_path=model_path,
                train_completed_at=train_end_time,
                train_duration=int(train_duration)
            )

            logger.info(f"[Worker-{worker_id}] âœ… è®­ç»ƒå®Œæˆ: {model_id}")

            # 4. è‡ªåŠ¨å›æµ‹ï¼ˆå¯é€‰ï¼‰
            if auto_backtest:
                await self._update_experiment_status(exp_id, 'backtesting', backtest_started_at=datetime.now())

                logger.info(f"[Worker-{worker_id}] ğŸ“Š å›æµ‹ä¸­...")
                backtest_result = await self._run_backtest_async(model_id, config)

                backtest_end_time = datetime.now()
                backtest_duration = (backtest_end_time - train_end_time).total_seconds()

                # 5. ä¿å­˜å›æµ‹ç»“æœ
                await self._update_experiment_backtest_result(
                    exp_id=exp_id,
                    backtest_metrics=backtest_result,
                    backtest_completed_at=backtest_end_time,
                    backtest_duration=int(backtest_duration)
                )

                logger.info(f"[Worker-{worker_id}] âœ… å›æµ‹å®Œæˆ")

            # 6. æ ‡è®°å®éªŒå®Œæˆ
            total_duration = (datetime.now() - start_time).total_seconds()
            await self._update_experiment_status(
                exp_id,
                'completed',
                total_duration=int(total_duration)
            )

            logger.info(f"[Worker-{worker_id}] ğŸ‰ å®éªŒ {exp_id} å®Œæˆï¼")

        except Exception as e:
            logger.error(f"[Worker-{worker_id}] âŒ å®éªŒ {exp_id} å¤±è´¥: {e}")
            await self._mark_experiment_failed(exp_id, str(e))
            raise

    async def _train_model_async(self, config: Dict) -> tuple:
        """å¼‚æ­¥è®­ç»ƒæ¨¡å‹ï¼ˆåŒ…è£…åŒæ­¥ä»£ç ï¼‰"""

        def _train():
            # ä½¿ç”¨ç°æœ‰çš„è®­ç»ƒæœåŠ¡
            pipeline = DataPipeline()

            # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆä¸MLTrainingServiceä¸€è‡´ï¼‰
            models_dir = Path('/data/models/ml_models')
            models_dir.mkdir(parents=True, exist_ok=True)

            # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆmodel_typeåœ¨æ„é€ å‡½æ•°ä¸­ä¼ é€’ï¼‰
            trainer = ModelTrainer(
                model_type=config['model_type'],
                model_params=config.get('model_params', {}),
                output_dir=str(models_dir)
            )

            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X, y = pipeline.get_training_data(
                symbol=config['symbol'],
                start_date=config['start_date'],
                end_date=config['end_date'],
                target_period=config['target_period']
            )

            # å‡†å¤‡æ¨¡å‹è®­ç»ƒæ•°æ®ï¼ˆåˆ†å‰²è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†ï¼Œå¹¶ç¼©æ”¾ç‰¹å¾ï¼‰
            # è¿™ä¸€æ­¥ä¼šfit scaler
            X_train, y_train, X_valid, y_valid, X_test, y_test = pipeline.prepare_for_model(
                X, y,
                train_ratio=config.get('train_ratio', 0.7),
                valid_ratio=config.get('valid_ratio', 0.15),
                scale_features=True,
                balance_samples=config.get('balance_samples', False)
            )

            # è®­ç»ƒæ¨¡å‹ï¼ˆç›´æ¥è°ƒç”¨å¯¹åº”çš„è®­ç»ƒæ–¹æ³•ï¼‰
            if config['model_type'] == 'lightgbm':
                trainer.train_lightgbm(
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_valid,
                    y_valid=y_valid
                )
            elif config['model_type'] == 'gru':
                trainer.train_gru(
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_valid,
                    y_valid=y_valid
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {config['model_type']}")

            # è®­ç»ƒåï¼Œæ¨¡å‹ä¿å­˜åœ¨trainer.modelä¸­
            # è¯„ä¼°è®­ç»ƒé›†æ€§èƒ½
            metrics = trainer.evaluate(X_train, y_train, dataset_name='train', verbose=False)

            # ç”Ÿæˆæ¨¡å‹IDå¹¶ä¿å­˜æ¨¡å‹
            model_id = f"{config['symbol']}_{config['model_type']}_T{config['target_period']}_{config.get('scaler_type', 'robust')}"
            trainer.save_model(model_name=model_id, save_metrics=True)

            # è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»åœ¨save_modelä¹‹åï¼Œç¡®ä¿æ–‡ä»¶å·²ä¿å­˜ï¼‰
            model_path = models_dir / f"{model_id}.txt" if config['model_type'] == 'lightgbm' else models_dir / f"{model_id}.pth"

            # ä¿å­˜scalerï¼ˆä¸æ‰‹åŠ¨è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
            import pickle
            scaler_path = models_dir / f"{model_id}_scaler.pkl"
            with open(scaler_path, 'wb') as f:
                pickle.dump(pipeline.get_scaler(), f)
            logger.info(f"âœ… Scalerå·²ä¿å­˜: {scaler_path}")

            # è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆLightGBMæ¨¡å‹æœ‰è¿™ä¸ªæ–¹æ³•ï¼‰
            # ä½¿ç”¨å­—å…¸æ ¼å¼ {feature: gain}ï¼Œä¸æ‰‹åŠ¨è®­ç»ƒä¿æŒä¸€è‡´
            feature_importance = {}
            if hasattr(trainer.model, 'get_feature_importance'):
                try:
                    fi_df = trainer.model.get_feature_importance(top_n=20)
                    if fi_df is not None and not fi_df.empty:
                        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼š{feature: gain}
                        feature_importance = dict(zip(
                            fi_df['feature'].tolist(),
                            fi_df['gain'].tolist()
                        ))
                except Exception as e:
                    logger.warning(f"è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")

            # æ³¨å†Œæ¨¡å‹åˆ°MLTrainingServiceï¼Œä½¿å›æµ‹èƒ½æ‰¾åˆ°æ¨¡å‹
            from app.services.ml_training_service import MLTrainingService
            ml_service = MLTrainingService()

            # åˆ›å»ºä»»åŠ¡å…ƒæ•°æ®
            ml_service.tasks[model_id] = {
                'task_id': model_id,
                'status': 'completed',
                'model_path': str(model_path),
                'config': {
                    'model_type': config['model_type'],
                    'target_period': config['target_period'],
                    'symbol': config['symbol'],
                    'scaler_type': config.get('scaler_type', 'robust'),
                },
                'metrics': metrics,  # è®­ç»ƒæŒ‡æ ‡
                'feature_importance': feature_importance,  # ç‰¹å¾é‡è¦æ€§
                'created_at': datetime.now().isoformat(),
                'completed_at': datetime.now().isoformat(),
            }
            ml_service._save_metadata()
            logger.info(f"âœ… æ¨¡å‹å·²æ³¨å†Œåˆ°MLTrainingService: {model_id}")

            return model_id, metrics, feature_importance, str(model_path)

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        return await asyncio.to_thread(_train)

    async def _run_backtest_async(self, model_id: str, config: Dict) -> Dict:
        """å¼‚æ­¥å›æµ‹"""

        # è°ƒç”¨å›æµ‹æœåŠ¡ï¼ˆä½¿ç”¨MLç­–ç•¥ï¼‰
        result = await self.backtest_service.run_backtest(
            symbols=config['symbol'],
            start_date=config['start_date'],
            end_date=config['end_date'],
            strategy_id='ml_model',
            strategy_params={'model_id': model_id}
        )

        return result.get('metrics', {})

    # ==================== æ•°æ®åº“æ“ä½œ ====================

    async def _update_batch_status(
        self,
        batch_id: int,
        status: str,
        started_at: Optional[datetime] = None,
        completed_at: Optional[datetime] = None
    ):
        """æ›´æ–°æ‰¹æ¬¡çŠ¶æ€"""

        updates = ["status = %s"]
        params = [status]

        if started_at:
            updates.append("started_at = %s")
            params.append(started_at)

        if completed_at:
            updates.append("completed_at = %s")
            params.append(completed_at)

        query = f"UPDATE experiment_batches SET {', '.join(updates)} WHERE id = %s"
        params.append(batch_id)

        await asyncio.to_thread(self.db._execute_update, query, tuple(params))

    async def _get_batch_config(self, batch_id: int) -> Dict:
        """è·å–æ‰¹æ¬¡é…ç½®"""

        query = "SELECT config FROM experiment_batches WHERE id = %s"
        result = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        if result:
            return result[0][0] or {}
        return {}

    async def _get_pending_experiments(self, batch_id: int) -> List:
        """è·å–å¾…æ‰§è¡Œçš„å®éªŒ"""

        query = """
            SELECT id, batch_id, experiment_name, config
            FROM experiments
            WHERE batch_id = %s AND status = 'pending'
            ORDER BY id
        """

        return await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

    async def _update_experiment_status(
        self,
        exp_id: int,
        status: str,
        train_started_at: Optional[datetime] = None,
        backtest_started_at: Optional[datetime] = None,
        total_duration: Optional[int] = None
    ):
        """æ›´æ–°å®éªŒçŠ¶æ€"""

        updates = ["status = %s"]
        params = [status]

        if train_started_at:
            updates.append("train_started_at = %s")
            params.append(train_started_at)

        if backtest_started_at:
            updates.append("backtest_started_at = %s")
            params.append(backtest_started_at)

        if total_duration is not None:
            updates.append("total_duration_seconds = %s")
            params.append(total_duration)

        query = f"UPDATE experiments SET {', '.join(updates)} WHERE id = %s"
        params.append(exp_id)

        await asyncio.to_thread(self.db._execute_update, query, tuple(params))

    async def _update_experiment_train_result(
        self,
        exp_id: int,
        model_id: str,
        train_metrics: Dict,
        feature_importance: Dict,
        model_path: str,
        train_completed_at: datetime,
        train_duration: int
    ):
        """æ›´æ–°è®­ç»ƒç»“æœ"""

        query = """
            UPDATE experiments
            SET model_id = %s,
                train_metrics = %s::jsonb,
                feature_importance = %s::jsonb,
                model_path = %s,
                train_completed_at = %s,
                train_duration_seconds = %s
            WHERE id = %s
        """

        await asyncio.to_thread(
            self.db._execute_update,
            query,
            (
                model_id,
                json.dumps(train_metrics),
                json.dumps(feature_importance),
                model_path,
                train_completed_at,
                train_duration,
                exp_id
            )
        )

    async def _update_experiment_backtest_result(
        self,
        exp_id: int,
        backtest_metrics: Dict,
        backtest_completed_at: datetime,
        backtest_duration: int
    ):
        """æ›´æ–°å›æµ‹ç»“æœ"""

        query = """
            UPDATE experiments
            SET backtest_status = 'completed',
                backtest_metrics = %s::jsonb,
                backtest_completed_at = %s,
                backtest_duration_seconds = %s
            WHERE id = %s
        """

        await asyncio.to_thread(
            self.db._execute_update,
            query,
            (
                json.dumps(backtest_metrics),
                backtest_completed_at,
                backtest_duration,
                exp_id
            )
        )

    async def _mark_experiment_failed(self, exp_id: int, error_message: str):
        """æ ‡è®°å®éªŒå¤±è´¥"""

        query = """
            UPDATE experiments
            SET status = 'failed',
                error_message = %s,
                retry_count = retry_count + 1
            WHERE id = %s
        """

        await asyncio.to_thread(self.db._execute_update, query, (error_message, exp_id))

    async def _increment_batch_counter(self, batch_id: int, counter_type: str):
        """å¢åŠ æ‰¹æ¬¡è®¡æ•°å™¨"""

        if counter_type == 'completed':
            field = 'completed_experiments'
        elif counter_type == 'failed':
            field = 'failed_experiments'
        else:
            return

        query = f"UPDATE experiment_batches SET {field} = {field} + 1 WHERE id = %s"
        await asyncio.to_thread(self.db._execute_update, query, (batch_id,))

    async def _calculate_rankings(self, batch_id: int):
        """è®¡ç®—å®éªŒæ’å"""

        logger.info(f"ğŸ“Š è®¡ç®—æ‰¹æ¬¡ {batch_id} çš„æ’å...")

        # å¯¼å…¥æ’åå™¨
        from app.services.model_ranker import ModelRanker
        ranker = ModelRanker(self.db)

        # è·å–æ‰€æœ‰å®Œæˆçš„å®éªŒ
        query = """
            SELECT id, train_metrics, backtest_metrics
            FROM experiments
            WHERE batch_id = %s AND status = 'completed' AND backtest_status = 'completed'
        """

        experiments = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        # è®¡ç®—è¯„åˆ†
        for exp in experiments:
            exp_id = exp[0]
            train_metrics = exp[1] or {}
            backtest_metrics = exp[2] or {}

            rank_score = ranker.calculate_rank_score(train_metrics, backtest_metrics)

            # æ›´æ–°è¯„åˆ†
            update_query = "UPDATE experiments SET rank_score = %s WHERE id = %s"
            await asyncio.to_thread(self.db._execute_update, update_query, (rank_score, exp_id))

        # æ›´æ–°æ’åä½ç½®
        rank_query = """
            WITH ranked AS (
                SELECT id, ROW_NUMBER() OVER (ORDER BY rank_score DESC NULLS LAST) as position
                FROM experiments
                WHERE batch_id = %s AND status = 'completed'
            )
            UPDATE experiments e
            SET rank_position = r.position
            FROM ranked r
            WHERE e.id = r.id
        """

        await asyncio.to_thread(self.db._execute_update, rank_query, (batch_id,))

        logger.info("âœ… æ’åè®¡ç®—å®Œæˆ")

    # ==================== æŸ¥è¯¢æ¥å£ ====================

    async def get_batch_info(self, batch_id: int) -> Optional[Dict]:
        """è·å–æ‰¹æ¬¡ä¿¡æ¯"""

        query = "SELECT * FROM batch_statistics WHERE batch_id = %s"
        result = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        if result:
            row = result[0]
            return {
                'batch_id': row[0],
                'batch_name': row[1],
                'strategy': row[2],
                'status': row[3],
                'total_experiments': row[4],
                'completed_experiments': row[5],
                'failed_experiments': row[6],
                'running_experiments': row[7],
                'success_rate_pct': float(row[8]) if row[8] else 0,
                'created_at': row[9].isoformat() if row[9] else None,
                'started_at': row[10].isoformat() if row[10] else None,
                'completed_at': row[11].isoformat() if row[11] else None,
                'duration_hours': float(row[12]) if row[12] else None,
                'avg_rank_score': float(row[13]) if row[13] else None,
                'max_rank_score': float(row[14]) if row[14] else None,
                'top_model_id': row[15]
            }

        return None

    async def get_top_models(
        self,
        batch_id: int,
        top_n: int = 10,
        min_sharpe: Optional[float] = None,
        max_drawdown: Optional[float] = None,
        min_annual_return: Optional[float] = None
    ) -> List[Dict]:
        """è·å–Topæ¨¡å‹"""

        query = "SELECT * FROM get_top_models(%s, %s, %s, %s, %s)"

        result = await asyncio.to_thread(
            self.db._execute_query,
            query,
            (batch_id, top_n, min_sharpe, max_drawdown, min_annual_return)
        )

        models = []
        for row in result:
            models.append({
                'experiment_id': row[0],
                'model_id': row[1],
                'rank_score': float(row[2]) if row[2] else None,
                'annual_return': float(row[3]) if row[3] else None,
                'sharpe_ratio': float(row[4]) if row[4] else None,
                'max_drawdown': float(row[5]) if row[5] else None,
                'config': row[6]
            })

        return models

    async def list_batches(self, limit: int = 100, status: Optional[str] = None) -> List[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰æ‰¹æ¬¡

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            status: çŠ¶æ€è¿‡æ»¤ (pending/running/completed/failed)

        Returns:
            æ‰¹æ¬¡åˆ—è¡¨
        """
        # æ„å»ºæŸ¥è¯¢
        conditions = []
        params = []

        if status:
            conditions.append("status = %s")
            params.append(status)

        where_clause = f"WHERE {' AND '.join(conditions)}" if conditions else ""

        query = f"""
            SELECT * FROM batch_statistics
            {where_clause}
            ORDER BY created_at DESC
            LIMIT %s
        """
        params.append(limit)

        # æ‰§è¡ŒæŸ¥è¯¢
        results = await asyncio.to_thread(self.db._execute_query, query, tuple(params))

        batches = []
        for row in results:
            batches.append({
                'batch_id': row[0],
                'batch_name': row[1],
                'strategy': row[2],
                'status': row[3],
                'total_experiments': row[4],
                'completed_experiments': row[5],
                'failed_experiments': row[6],
                'running_experiments': row[7],
                'success_rate_pct': float(row[8]) if row[8] else 0,
                'created_at': row[9].isoformat() if row[9] else None,
                'started_at': row[10].isoformat() if row[10] else None,
                'completed_at': row[11].isoformat() if row[11] else None,
                'duration_hours': float(row[12]) if row[12] else None,
                'avg_rank_score': float(row[13]) if row[13] else None,
                'max_rank_score': float(row[14]) if row[14] else None,
                'top_model_id': row[15]
            })

        return batches

    async def get_batch_experiments(self, batch_id: int, status: Optional[str] = None, limit: int = 500) -> List[Dict]:
        """
        è·å–æ‰¹æ¬¡ä¸‹çš„æ‰€æœ‰å®éªŒ

        Args:
            batch_id: æ‰¹æ¬¡ID
            status: çŠ¶æ€è¿‡æ»¤ (completed/failed/running/pending)
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            å®éªŒåˆ—è¡¨
        """
        conditions = ["batch_id = %s"]
        params = [batch_id]

        if status:
            conditions.append("status = %s")
            params.append(status)

        query = f"""
            SELECT id, experiment_name, model_id, config, train_metrics, backtest_metrics,
                   rank_score, rank_position, status, error_message
            FROM experiments
            WHERE {' AND '.join(conditions)}
            ORDER BY rank_score DESC NULLS LAST
            LIMIT %s
        """
        params.append(limit)

        results = await asyncio.to_thread(self.db._execute_query, query, tuple(params))

        experiments = []
        for row in results:
            experiments.append({
                'id': row[0],
                'experiment_name': row[1],
                'model_id': row[2],
                'config': row[3],
                'train_metrics': row[4],
                'backtest_metrics': row[5],
                'rank_score': float(row[6]) if row[6] else None,
                'rank_position': row[7],
                'status': row[8],
                'error_message': row[9]
            })

        return experiments
