"""
ÂÆûÈ™åÁÆ°ÁêÜÊúçÂä°
ÁÆ°ÁêÜÊâπÈáèËÆ≠ÁªÉÂíåÂõûÊµãÂÆûÈ™åÁöÑÁîüÂëΩÂë®Êúü
"""

import asyncio
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

from loguru import logger

# ÂØºÂÖ•coreÊ®°Âùó
import sys
sys.path.insert(0, '/app/src')

from src.data_pipeline import DataPipeline
from src.models.model_trainer import ModelTrainer
from src.database.db_manager import DatabaseManager

from app.services.parameter_grid import ParameterGrid
from app.services.ml_training_service import MLTrainingService
from app.services.backtest_service import BacktestService


class ExperimentService:
    """ÂÆûÈ™åÁÆ°ÁêÜÊúçÂä°"""

    def __init__(self):
        self.db = DatabaseManager()
        self.ml_service = MLTrainingService()
        self.backtest_service = BacktestService()

        # ‰ªªÂä°ÈòüÂàó
        self.running_batches: Dict[int, asyncio.Task] = {}

    # ==================== ÊâπÊ¨°ÁÆ°ÁêÜ ====================

    async def create_batch(
        self,
        batch_name: str,
        param_space: Dict[str, Any],
        strategy: str = 'grid',
        max_experiments: Optional[int] = None,
        description: Optional[str] = None,
        config: Optional[Dict] = None,
        tags: Optional[List[str]] = None
    ) -> int:
        """
        ÂàõÂª∫ÂÆûÈ™åÊâπÊ¨°

        Args:
            batch_name: ÊâπÊ¨°ÂêçÁß∞ÔºàÂîØ‰∏ÄÔºâ
            param_space: ÂèÇÊï∞Á©∫Èó¥ÂÆö‰πâ
            strategy: ÂèÇÊï∞ÁîüÊàêÁ≠ñÁï• ('grid', 'random', 'bayesian')
            max_experiments: ÊúÄÂ§ßÂÆûÈ™åÊï∞Ôºà‰ªÖÂØπrandom/bayesianÊúâÊïàÔºâ
            description: ÊâπÊ¨°ÊèèËø∞
            config: ÊâπÊ¨°Á∫ßÂà´ÈÖçÁΩÆÔºàÂπ∂Ë°åÂ∫¶„ÄÅÂõûÊµãËÆæÁΩÆÁ≠âÔºâ
            tags: Ê†áÁ≠æÂàóË°®

        Returns:
            batch_id
        """
        logger.info(f"üì¶ ÂàõÂª∫ÂÆûÈ™åÊâπÊ¨°: {batch_name}")

        try:
            # 1. ÁîüÊàêÂèÇÊï∞ÁªÑÂêà
            param_grid = ParameterGrid(param_space)
            experiment_configs = param_grid.generate(
                strategy=strategy,
                max_experiments=max_experiments
            )

            total_experiments = len(experiment_configs)
            logger.info(f"‚úÖ ÁîüÊàê‰∫Ü {total_experiments} ‰∏™ÂÆûÈ™åÈÖçÁΩÆ")

            # 2. ÂàõÂª∫ÊâπÊ¨°ËÆ∞ÂΩï
            batch_config = config or {}
            batch_config.setdefault('auto_backtest', True)
            batch_config.setdefault('max_workers', 3)
            batch_config.setdefault('save_models', True)

            insert_query = """
                INSERT INTO experiment_batches (
                    batch_name, description, strategy, param_space,
                    total_experiments, config, tags
                )
                VALUES (%s, %s, %s, %s::jsonb, %s, %s::jsonb, %s)
                RETURNING id
            """

            # ‰ΩøÁî®ÊâãÂä®‰∫ãÂä°ÁÆ°ÁêÜ
            conn = self.db.get_connection()
            cursor = conn.cursor()

            try:
                cursor.execute(
                    insert_query,
                    (
                        batch_name,
                        description,
                        strategy,
                        json.dumps(param_space),
                        total_experiments,
                        json.dumps(batch_config),
                        tags or []
                    )
                )
                result = cursor.fetchone()
                batch_id = result[0]
                conn.commit()
                logger.info(f"‚úÖ ÊâπÊ¨°ID: {batch_id}")
            except Exception as e:
                conn.rollback()
                logger.error(f"‚ùå ÂàõÂª∫ÊâπÊ¨°ËÆ∞ÂΩïÂ§±Ë¥•: {e}")
                raise
            finally:
                cursor.close()
                self.db.release_connection(conn)

            # 3. ÂàõÂª∫ÂÆûÈ™åËÆ∞ÂΩï
            await self._create_experiments(batch_id, experiment_configs)

            return batch_id

        except Exception as e:
            logger.error(f"‚ùå ÂàõÂª∫ÊâπÊ¨°Â§±Ë¥•: {e}")
            raise

    async def _create_experiments(self, batch_id: int, configs: List[Dict]):
        """ÊâπÈáèÂàõÂª∫ÂÆûÈ™åËÆ∞ÂΩï"""

        logger.info(f"üìù ÂàõÂª∫ {len(configs)} ‰∏™ÂÆûÈ™åËÆ∞ÂΩï...")

        insert_query = """
            INSERT INTO experiments (
                batch_id, experiment_name, experiment_hash, config, status
            )
            VALUES (%s, %s, %s, %s::jsonb, 'pending')
        """

        values = []
        for config in configs:
            exp_name = self._generate_experiment_name(config)
            exp_hash = config.pop('experiment_hash', None)  # ÁßªÈô§ÂìàÂ∏åÂ≠óÊÆµ

            values.append((
                batch_id,
                exp_name,
                exp_hash,
                json.dumps(config)
            ))

        # ÊâπÈáèÊèíÂÖ•
        conn = self.db.get_connection()
        cursor = conn.cursor()

        try:
            cursor.executemany(insert_query, values)
            conn.commit()
            logger.info(f"‚úÖ ÊàêÂäüÂàõÂª∫ {len(values)} ‰∏™ÂÆûÈ™åËÆ∞ÂΩï")
        except Exception as e:
            conn.rollback()
            logger.error(f"‚ùå ÊâπÈáèÊèíÂÖ•Â§±Ë¥•: {e}")
            raise
        finally:
            cursor.close()
            self.db.release_connection(conn)

    def _generate_experiment_name(self, config: Dict) -> str:
        """ÁîüÊàêÂÆûÈ™åÂêçÁß∞"""
        symbol = config.get('symbol', 'unknown')
        model_type = config.get('model_type', 'unknown')
        target_period = config.get('target_period', 0)
        scaler = config.get('scaler_type', 'unknown')

        return f"{symbol}_{model_type}_T{target_period}_{scaler}"

    # ==================== ÊâπÊ¨°ÊâßË°å ====================

    async def run_batch(
        self,
        batch_id: int,
        max_workers: Optional[int] = None
    ):
        """
        ËøêË°åÂÆûÈ™åÊâπÊ¨°

        Args:
            batch_id: ÊâπÊ¨°ID
            max_workers: ÊúÄÂ§ßÂπ∂Ë°åWorkerÊï∞ÔºàË¶ÜÁõñÊâπÊ¨°ÈÖçÁΩÆÔºâ
        """
        logger.info(f"üöÄ ÂêØÂä®ÊâπÊ¨° {batch_id}")

        try:
            # 1. Êõ¥Êñ∞ÊâπÊ¨°Áä∂ÊÄÅ
            await self._update_batch_status(batch_id, 'running', started_at=datetime.now())

            # 2. Ëé∑ÂèñÊâπÊ¨°ÈÖçÁΩÆ
            batch_config = await self._get_batch_config(batch_id)
            workers = max_workers or batch_config.get('max_workers', 3)
            auto_backtest = batch_config.get('auto_backtest', True)

            logger.info(f"‚öôÔ∏è  ÈÖçÁΩÆ: {workers} ‰∏™Worker, Ëá™Âä®ÂõûÊµã={auto_backtest}")

            # 3. Ëé∑ÂèñÂæÖÊâßË°åÂÆûÈ™å
            experiments = await self._get_pending_experiments(batch_id)
            logger.info(f"üìã ÂæÖÊâßË°åÂÆûÈ™å: {len(experiments)} ‰∏™")

            if not experiments:
                logger.warning("‚ö†Ô∏è  Ê≤°ÊúâÂæÖÊâßË°åÁöÑÂÆûÈ™å")
                await self._update_batch_status(batch_id, 'completed', completed_at=datetime.now())
                return

            # 4. ÂàõÂª∫‰ªªÂä°ÈòüÂàó
            queue = asyncio.Queue()
            for exp in experiments:
                await queue.put(exp)

            # 5. ÂêØÂä®WorkerÊ±†
            tasks = []
            for i in range(workers):
                task = asyncio.create_task(
                    self._experiment_worker(
                        worker_id=i,
                        batch_id=batch_id,
                        queue=queue,
                        auto_backtest=auto_backtest
                    )
                )
                tasks.append(task)

            # 6. Á≠âÂæÖÊâÄÊúâ‰ªªÂä°ÂÆåÊàê
            await queue.join()

            # 7. ÂÅúÊ≠¢Workers
            for task in tasks:
                task.cancel()

            await asyncio.gather(*tasks, return_exceptions=True)

            # 8. ËÆ°ÁÆóÊéíÂêç
            await self._calculate_rankings(batch_id)

            # 9. Êõ¥Êñ∞ÊâπÊ¨°Áä∂ÊÄÅ
            await self._update_batch_status(batch_id, 'completed', completed_at=datetime.now())

            logger.info(f"üéâ ÊâπÊ¨° {batch_id} ÊâßË°åÂÆåÊàêÔºÅ")

        except Exception as e:
            logger.error(f"‚ùå ÊâπÊ¨°ÊâßË°åÂ§±Ë¥•: {e}")
            await self._update_batch_status(batch_id, 'failed')
            raise

    async def _experiment_worker(
        self,
        worker_id: int,
        batch_id: int,
        queue: asyncio.Queue,
        auto_backtest: bool
    ):
        """ÂÆûÈ™åÊâßË°åWorker"""

        logger.info(f"üîß Worker-{worker_id} ÂêØÂä®")

        while True:
            try:
                # ‰ªéÈòüÂàóËé∑ÂèñÂÆûÈ™å
                experiment = await queue.get()

                exp_id = experiment[0]
                # configÂ≠óÊÆµÊòØJSONBÁ±ªÂûãÔºåÊï∞ÊçÆÂ∫ìÂ∑≤Ëá™Âä®ËΩ¨Êç¢‰∏∫dictÔºåÊó†ÈúÄjson.loads
                exp_config = experiment[3] if isinstance(experiment[3], dict) else json.loads(experiment[3])

                logger.info(f"[Worker-{worker_id}] üî¨ ÂºÄÂßãÂÆûÈ™å {exp_id}: {experiment[2]}")

                # ÊâßË°åÂÆûÈ™å
                await self._run_single_experiment(
                    exp_id=exp_id,
                    config=exp_config,
                    auto_backtest=auto_backtest,
                    worker_id=worker_id
                )

                # Êõ¥Êñ∞ÊâπÊ¨°ÁªüËÆ°
                await self._increment_batch_counter(batch_id, 'completed')

            except asyncio.CancelledError:
                logger.info(f"üõë Worker-{worker_id} ÂÅúÊ≠¢")
                break
            except Exception as e:
                logger.error(f"[Worker-{worker_id}] ‚ùå ÂÆûÈ™åÂ§±Ë¥•: {e}")
                await self._mark_experiment_failed(exp_id, str(e))
                await self._increment_batch_counter(batch_id, 'failed')
            finally:
                queue.task_done()

    async def _run_single_experiment(
        self,
        exp_id: int,
        config: Dict,
        auto_backtest: bool,
        worker_id: int
    ):
        """ÊâßË°åÂçï‰∏™ÂÆûÈ™å"""

        start_time = datetime.now()

        try:
            # 1. Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ËÆ≠ÁªÉ‰∏≠
            await self._update_experiment_status(exp_id, 'training', train_started_at=start_time)

            # 2. ËÆ≠ÁªÉÊ®°Âûã
            logger.info(f"[Worker-{worker_id}] üèãÔ∏è  ËÆ≠ÁªÉÊ®°Âûã...")
            model_id, train_metrics, feature_importance = await self._train_model_async(config)

            train_end_time = datetime.now()
            train_duration = (train_end_time - start_time).total_seconds()

            # 3. ‰øùÂ≠òËÆ≠ÁªÉÁªìÊûú
            await self._update_experiment_train_result(
                exp_id=exp_id,
                model_id=model_id,
                train_metrics=train_metrics,
                feature_importance=feature_importance,
                train_completed_at=train_end_time,
                train_duration=int(train_duration)
            )

            logger.info(f"[Worker-{worker_id}] ‚úÖ ËÆ≠ÁªÉÂÆåÊàê: {model_id}")

            # 4. Ëá™Âä®ÂõûÊµãÔºàÂèØÈÄâÔºâ
            if auto_backtest:
                await self._update_experiment_status(exp_id, 'backtesting', backtest_started_at=datetime.now())

                logger.info(f"[Worker-{worker_id}] üìä ÂõûÊµã‰∏≠...")
                backtest_result = await self._run_backtest_async(model_id, config)

                backtest_end_time = datetime.now()
                backtest_duration = (backtest_end_time - train_end_time).total_seconds()

                # 5. ‰øùÂ≠òÂõûÊµãÁªìÊûú
                await self._update_experiment_backtest_result(
                    exp_id=exp_id,
                    backtest_metrics=backtest_result,
                    backtest_completed_at=backtest_end_time,
                    backtest_duration=int(backtest_duration)
                )

                logger.info(f"[Worker-{worker_id}] ‚úÖ ÂõûÊµãÂÆåÊàê")

            # 6. Ê†áËÆ∞ÂÆûÈ™åÂÆåÊàê
            total_duration = (datetime.now() - start_time).total_seconds()
            await self._update_experiment_status(
                exp_id,
                'completed',
                total_duration=int(total_duration)
            )

            logger.info(f"[Worker-{worker_id}] üéâ ÂÆûÈ™å {exp_id} ÂÆåÊàêÔºÅ")

        except Exception as e:
            logger.error(f"[Worker-{worker_id}] ‚ùå ÂÆûÈ™å {exp_id} Â§±Ë¥•: {e}")
            await self._mark_experiment_failed(exp_id, str(e))
            raise

    async def _train_model_async(self, config: Dict) -> tuple:
        """ÂºÇÊ≠•ËÆ≠ÁªÉÊ®°ÂûãÔºàÂåÖË£ÖÂêåÊ≠•‰ª£Á†ÅÔºâ"""

        def _train():
            # ‰ΩøÁî®Áé∞ÊúâÁöÑËÆ≠ÁªÉÊúçÂä°
            pipeline = DataPipeline()

            # ÂàõÂª∫ËÆ≠ÁªÉÂô®Ôºàmodel_typeÂú®ÊûÑÈÄ†ÂáΩÊï∞‰∏≠‰º†ÈÄíÔºâ
            trainer = ModelTrainer(
                model_type=config['model_type'],
                model_params=config.get('model_params', {})
            )

            # ÂáÜÂ§áËÆ≠ÁªÉÊï∞ÊçÆ
            X_train, y_train = pipeline.get_training_data(
                symbol=config['symbol'],
                start_date=config['start_date'],
                end_date=config['end_date'],
                target_period=config['target_period']
            )

            # ËÆ≠ÁªÉÊ®°ÂûãÔºàÁõ¥Êé•Ë∞ÉÁî®ÂØπÂ∫îÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºâ
            if config['model_type'] == 'lightgbm':
                trainer.train_lightgbm(
                    X_train=X_train,
                    y_train=y_train
                )
            elif config['model_type'] == 'gru':
                trainer.train_gru(
                    X_train=X_train,
                    y_train=y_train
                )
            else:
                raise ValueError(f"‰∏çÊîØÊåÅÁöÑÊ®°ÂûãÁ±ªÂûã: {config['model_type']}")

            # ËÆ≠ÁªÉÂêéÔºåÊ®°Âûã‰øùÂ≠òÂú®trainer.model‰∏≠
            # ËØÑ‰º∞ËÆ≠ÁªÉÈõÜÊÄßËÉΩ
            metrics = trainer.evaluate(X_train, y_train, dataset_name='train', verbose=False)

            # ÁîüÊàêÊ®°ÂûãIDÂπ∂‰øùÂ≠òÊ®°Âûã
            model_id = f"{config['symbol']}_{config['model_type']}_T{config['target_period']}_{config.get('scaler_type', 'robust')}"
            trainer.save_model(model_name=model_id, save_metrics=True)

            # Ëé∑ÂèñÁâπÂæÅÈáçË¶ÅÊÄßÔºàLightGBMÊ®°ÂûãÊúâËøô‰∏™ÊñπÊ≥ïÔºâ
            feature_importance = {}
            if hasattr(trainer.model, 'get_feature_importance'):
                try:
                    fi_df = trainer.model.get_feature_importance(top_n=20)
                    if fi_df is not None and not fi_df.empty:
                        feature_importance = fi_df.to_dict('records')
                except Exception as e:
                    logger.warning(f"Ëé∑ÂèñÁâπÂæÅÈáçË¶ÅÊÄßÂ§±Ë¥•: {e}")

            # Ê≥®ÂÜåÊ®°ÂûãÂà∞MLTrainingServiceÔºå‰ΩøÂõûÊµãËÉΩÊâæÂà∞Ê®°Âûã
            from app.services.ml_training_service import MLTrainingService
            ml_service = MLTrainingService()

            # Ëé∑ÂèñÊ®°ÂûãÊñá‰ª∂Ë∑ØÂæÑ
            from pathlib import Path
            model_path = Path('data/models/saved') / f"{model_id}.txt" if config['model_type'] == 'lightgbm' else Path('data/models/saved') / f"{model_id}.pth"

            # ÂàõÂª∫‰ªªÂä°ÂÖÉÊï∞ÊçÆ
            ml_service.tasks[model_id] = {
                'task_id': model_id,
                'status': 'completed',
                'model_path': str(model_path),
                'config': {
                    'model_type': config['model_type'],
                    'target_period': config['target_period'],
                    'symbol': config['symbol'],
                    'scaler_type': config.get('scaler_type', 'robust'),
                },
                'metrics': metrics,  # ËÆ≠ÁªÉÊåáÊ†á
                'feature_importance': feature_importance,  # ÁâπÂæÅÈáçË¶ÅÊÄß
                'created_at': datetime.now().isoformat(),
                'completed_at': datetime.now().isoformat(),
            }
            ml_service._save_metadata()
            logger.info(f"‚úÖ Ê®°ÂûãÂ∑≤Ê≥®ÂÜåÂà∞MLTrainingService: {model_id}")

            return model_id, metrics, feature_importance

        # Âú®Á∫øÁ®ãÊ±†‰∏≠ÊâßË°åÔºàÈÅøÂÖçÈòªÂ°û‰∫ã‰ª∂Âæ™ÁéØÔºâ
        return await asyncio.to_thread(_train)

    async def _run_backtest_async(self, model_id: str, config: Dict) -> Dict:
        """ÂºÇÊ≠•ÂõûÊµã"""

        # Ë∞ÉÁî®ÂõûÊµãÊúçÂä°Ôºà‰ΩøÁî®MLÁ≠ñÁï•Ôºâ
        result = await self.backtest_service.run_backtest(
            symbols=config['symbol'],
            start_date=config['start_date'],
            end_date=config['end_date'],
            strategy_id='ml_model',
            strategy_params={'model_id': model_id}
        )

        return result.get('metrics', {})

    # ==================== Êï∞ÊçÆÂ∫ìÊìç‰Ωú ====================

    async def _update_batch_status(
        self,
        batch_id: int,
        status: str,
        started_at: Optional[datetime] = None,
        completed_at: Optional[datetime] = None
    ):
        """Êõ¥Êñ∞ÊâπÊ¨°Áä∂ÊÄÅ"""

        updates = ["status = %s"]
        params = [status]

        if started_at:
            updates.append("started_at = %s")
            params.append(started_at)

        if completed_at:
            updates.append("completed_at = %s")
            params.append(completed_at)

        query = f"UPDATE experiment_batches SET {', '.join(updates)} WHERE id = %s"
        params.append(batch_id)

        await asyncio.to_thread(self.db._execute_update, query, tuple(params))

    async def _get_batch_config(self, batch_id: int) -> Dict:
        """Ëé∑ÂèñÊâπÊ¨°ÈÖçÁΩÆ"""

        query = "SELECT config FROM experiment_batches WHERE id = %s"
        result = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        if result:
            return result[0][0] or {}
        return {}

    async def _get_pending_experiments(self, batch_id: int) -> List:
        """Ëé∑ÂèñÂæÖÊâßË°åÁöÑÂÆûÈ™å"""

        query = """
            SELECT id, batch_id, experiment_name, config
            FROM experiments
            WHERE batch_id = %s AND status = 'pending'
            ORDER BY id
        """

        return await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

    async def _update_experiment_status(
        self,
        exp_id: int,
        status: str,
        train_started_at: Optional[datetime] = None,
        backtest_started_at: Optional[datetime] = None,
        total_duration: Optional[int] = None
    ):
        """Êõ¥Êñ∞ÂÆûÈ™åÁä∂ÊÄÅ"""

        updates = ["status = %s"]
        params = [status]

        if train_started_at:
            updates.append("train_started_at = %s")
            params.append(train_started_at)

        if backtest_started_at:
            updates.append("backtest_started_at = %s")
            params.append(backtest_started_at)

        if total_duration is not None:
            updates.append("total_duration_seconds = %s")
            params.append(total_duration)

        query = f"UPDATE experiments SET {', '.join(updates)} WHERE id = %s"
        params.append(exp_id)

        await asyncio.to_thread(self.db._execute_update, query, tuple(params))

    async def _update_experiment_train_result(
        self,
        exp_id: int,
        model_id: str,
        train_metrics: Dict,
        feature_importance: Dict,
        train_completed_at: datetime,
        train_duration: int
    ):
        """Êõ¥Êñ∞ËÆ≠ÁªÉÁªìÊûú"""

        query = """
            UPDATE experiments
            SET model_id = %s,
                train_metrics = %s::jsonb,
                feature_importance = %s::jsonb,
                train_completed_at = %s,
                train_duration_seconds = %s
            WHERE id = %s
        """

        await asyncio.to_thread(
            self.db._execute_update,
            query,
            (
                model_id,
                json.dumps(train_metrics),
                json.dumps(feature_importance),
                train_completed_at,
                train_duration,
                exp_id
            )
        )

    async def _update_experiment_backtest_result(
        self,
        exp_id: int,
        backtest_metrics: Dict,
        backtest_completed_at: datetime,
        backtest_duration: int
    ):
        """Êõ¥Êñ∞ÂõûÊµãÁªìÊûú"""

        query = """
            UPDATE experiments
            SET backtest_status = 'completed',
                backtest_metrics = %s::jsonb,
                backtest_completed_at = %s,
                backtest_duration_seconds = %s
            WHERE id = %s
        """

        await asyncio.to_thread(
            self.db._execute_update,
            query,
            (
                json.dumps(backtest_metrics),
                backtest_completed_at,
                backtest_duration,
                exp_id
            )
        )

    async def _mark_experiment_failed(self, exp_id: int, error_message: str):
        """Ê†áËÆ∞ÂÆûÈ™åÂ§±Ë¥•"""

        query = """
            UPDATE experiments
            SET status = 'failed',
                error_message = %s,
                retry_count = retry_count + 1
            WHERE id = %s
        """

        await asyncio.to_thread(self.db._execute_update, query, (error_message, exp_id))

    async def _increment_batch_counter(self, batch_id: int, counter_type: str):
        """Â¢ûÂä†ÊâπÊ¨°ËÆ°Êï∞Âô®"""

        if counter_type == 'completed':
            field = 'completed_experiments'
        elif counter_type == 'failed':
            field = 'failed_experiments'
        else:
            return

        query = f"UPDATE experiment_batches SET {field} = {field} + 1 WHERE id = %s"
        await asyncio.to_thread(self.db._execute_update, query, (batch_id,))

    async def _calculate_rankings(self, batch_id: int):
        """ËÆ°ÁÆóÂÆûÈ™åÊéíÂêç"""

        logger.info(f"üìä ËÆ°ÁÆóÊâπÊ¨° {batch_id} ÁöÑÊéíÂêç...")

        # ÂØºÂÖ•ÊéíÂêçÂô®
        from app.services.model_ranker import ModelRanker
        ranker = ModelRanker(self.db)

        # Ëé∑ÂèñÊâÄÊúâÂÆåÊàêÁöÑÂÆûÈ™å
        query = """
            SELECT id, train_metrics, backtest_metrics
            FROM experiments
            WHERE batch_id = %s AND status = 'completed' AND backtest_status = 'completed'
        """

        experiments = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        # ËÆ°ÁÆóËØÑÂàÜ
        for exp in experiments:
            exp_id = exp[0]
            train_metrics = exp[1] or {}
            backtest_metrics = exp[2] or {}

            rank_score = ranker.calculate_rank_score(train_metrics, backtest_metrics)

            # Êõ¥Êñ∞ËØÑÂàÜ
            update_query = "UPDATE experiments SET rank_score = %s WHERE id = %s"
            await asyncio.to_thread(self.db._execute_update, update_query, (rank_score, exp_id))

        # Êõ¥Êñ∞ÊéíÂêç‰ΩçÁΩÆ
        rank_query = """
            WITH ranked AS (
                SELECT id, ROW_NUMBER() OVER (ORDER BY rank_score DESC NULLS LAST) as position
                FROM experiments
                WHERE batch_id = %s AND status = 'completed'
            )
            UPDATE experiments e
            SET rank_position = r.position
            FROM ranked r
            WHERE e.id = r.id
        """

        await asyncio.to_thread(self.db._execute_update, rank_query, (batch_id,))

        logger.info("‚úÖ ÊéíÂêçËÆ°ÁÆóÂÆåÊàê")

    # ==================== Êü•ËØ¢Êé•Âè£ ====================

    async def get_batch_info(self, batch_id: int) -> Optional[Dict]:
        """Ëé∑ÂèñÊâπÊ¨°‰ø°ÊÅØ"""

        query = "SELECT * FROM batch_statistics WHERE batch_id = %s"
        result = await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

        if result:
            row = result[0]
            return {
                'batch_id': row[0],
                'batch_name': row[1],
                'strategy': row[2],
                'status': row[3],
                'total_experiments': row[4],
                'completed_experiments': row[5],
                'failed_experiments': row[6],
                'running_experiments': row[7],
                'success_rate_pct': float(row[8]) if row[8] else 0,
                'created_at': row[9].isoformat() if row[9] else None,
                'started_at': row[10].isoformat() if row[10] else None,
                'completed_at': row[11].isoformat() if row[11] else None,
                'duration_hours': float(row[12]) if row[12] else None,
                'avg_rank_score': float(row[13]) if row[13] else None,
                'max_rank_score': float(row[14]) if row[14] else None,
                'top_model_id': row[15]
            }

        return None

    async def get_top_models(
        self,
        batch_id: int,
        top_n: int = 10,
        min_sharpe: Optional[float] = None,
        max_drawdown: Optional[float] = None,
        min_annual_return: Optional[float] = None
    ) -> List[Dict]:
        """Ëé∑ÂèñTopÊ®°Âûã"""

        query = "SELECT * FROM get_top_models(%s, %s, %s, %s, %s)"

        result = await asyncio.to_thread(
            self.db._execute_query,
            query,
            (batch_id, top_n, min_sharpe, max_drawdown, min_annual_return)
        )

        models = []
        for row in result:
            models.append({
                'experiment_id': row[0],
                'model_id': row[1],
                'rank_score': float(row[2]) if row[2] else None,
                'annual_return': float(row[3]) if row[3] else None,
                'sharpe_ratio': float(row[4]) if row[4] else None,
                'max_drawdown': float(row[5]) if row[5] else None,
                'config': row[6]
            })

        return models
