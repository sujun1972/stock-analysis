"""
å®éªŒè¿è¡Œå™¨
è´Ÿè´£æ‰§è¡Œå®éªŒçš„è®­ç»ƒå’Œå›æµ‹
"""

import asyncio
import json
from datetime import datetime
from typing import Dict, List, Optional
from loguru import logger

from database.db_manager import DatabaseManager
from app.services.core_training import CoreTrainingService
from app.services.backtest_service import BacktestService
from app.services.training_task_manager import TrainingTaskManager
from app.repositories.experiment_repository import ExperimentRepository


class ExperimentRunner:
    """
    å®éªŒè¿è¡Œå™¨

    èŒè´£ï¼š
    - æ‰§è¡Œæ‰¹æ¬¡å®éªŒ
    - Worker ç®¡ç†å’Œè°ƒåº¦
    - å•ä¸ªå®éªŒçš„è®­ç»ƒå’Œå›æµ‹
    - å®éªŒçŠ¶æ€æ›´æ–°
    """

    def __init__(self, db: Optional[DatabaseManager] = None):
        """
        åˆå§‹åŒ–å®éªŒè¿è¡Œå™¨

        Args:
            db: DatabaseManager å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºä¾èµ–æ³¨å…¥ï¼‰
        """
        self.db = db or DatabaseManager()
        self.backtest_service = BacktestService(self.db)
        self.experiment_repo = ExperimentRepository(self.db)

        # è¿è¡Œä¸­çš„æ‰¹æ¬¡
        self.running_batches: Dict[int, asyncio.Task] = {}

    async def run_batch(
        self,
        batch_id: int,
        max_workers: Optional[int] = None,
        auto_backtest: bool = True
    ):
        """
        è¿è¡Œæ‰¹æ¬¡å®éªŒ

        Args:
            batch_id: æ‰¹æ¬¡ID
            max_workers: æœ€å¤§å¹¶è¡ŒWorkeræ•°
            auto_backtest: æ˜¯å¦è‡ªåŠ¨å›æµ‹
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹æ¬¡ {batch_id}ï¼ŒWorkeræ•°: {max_workers or 4}")

        # æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
        await self._update_batch_status(batch_id, 'running', started_at=datetime.now())

        try:
            # è·å–å¾…æ‰§è¡Œçš„å®éªŒ
            experiments = await self._get_pending_experiments(batch_id)

            if not experiments:
                logger.warning(f"æ‰¹æ¬¡ {batch_id} æ²¡æœ‰å¾…æ‰§è¡Œçš„å®éªŒ")
                await self._update_batch_status(batch_id, 'completed')
                return

            # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
            queue = asyncio.Queue()
            for exp in experiments:
                await queue.put(exp)

            # åˆ›å»ºWorkeræ± 
            workers = []
            num_workers = min(max_workers or 4, len(experiments))

            for worker_id in range(num_workers):
                task = asyncio.create_task(
                    self._experiment_worker(
                        worker_id=worker_id,
                        batch_id=batch_id,
                        queue=queue,
                        auto_backtest=auto_backtest
                    )
                )
                workers.append(task)

            # ç­‰å¾…æ‰€æœ‰å®éªŒå®Œæˆ
            await queue.join()

            # åœæ­¢æ‰€æœ‰Worker
            for task in workers:
                task.cancel()

            await asyncio.gather(*workers, return_exceptions=True)

            # è®¡ç®—æ’å
            from app.services.batch_manager import BatchManager
            batch_manager = BatchManager()
            await batch_manager.calculate_rankings(batch_id)

            # æ›´æ–°æ‰¹æ¬¡çŠ¶æ€ä¸ºå®Œæˆ
            await self._update_batch_status(batch_id, 'completed', completed_at=datetime.now())

            logger.info(f"âœ… æ‰¹æ¬¡ {batch_id} å®Œæˆ")

        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ {batch_id} æ‰§è¡Œå¤±è´¥: {e}")
            await self._update_batch_status(batch_id, 'failed')
            raise

    async def _experiment_worker(
        self,
        worker_id: int,
        batch_id: int,
        queue: asyncio.Queue,
        auto_backtest: bool
    ):
        """
        å®éªŒæ‰§è¡ŒWorker

        Args:
            worker_id: Worker ID
            batch_id: æ‰¹æ¬¡ID
            queue: ä»»åŠ¡é˜Ÿåˆ—
            auto_backtest: æ˜¯å¦è‡ªåŠ¨å›æµ‹
        """
        logger.info(f"ğŸ”§ Worker-{worker_id} å¯åŠ¨")

        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–å®éªŒ
                experiment = await queue.get()

                exp_id = experiment[0]
                exp_config = experiment[3] if isinstance(experiment[3], dict) else json.loads(experiment[3])

                logger.info(f"[Worker-{worker_id}] ğŸ”¬ å¼€å§‹å®éªŒ {exp_id}")

                # æ‰§è¡Œå®éªŒ
                await self._run_single_experiment(
                    exp_id=exp_id,
                    config=exp_config,
                    auto_backtest=auto_backtest,
                    worker_id=worker_id
                )

                # æ›´æ–°æ‰¹æ¬¡è®¡æ•°å™¨
                await self._increment_batch_counter(batch_id, 'completed')

            except asyncio.CancelledError:
                logger.info(f"ğŸ›‘ Worker-{worker_id} åœæ­¢")
                break
            except Exception as e:
                logger.error(f"[Worker-{worker_id}] âŒ å®éªŒå¤±è´¥: {e}")
                await self._mark_experiment_failed(exp_id, str(e))
                await self._increment_batch_counter(batch_id, 'failed')
            finally:
                queue.task_done()

    async def _run_single_experiment(
        self,
        exp_id: int,
        config: Dict,
        auto_backtest: bool,
        worker_id: int
    ):
        """
        æ‰§è¡Œå•ä¸ªå®éªŒ

        Args:
            exp_id: å®éªŒID
            config: å®éªŒé…ç½®
            auto_backtest: æ˜¯å¦è‡ªåŠ¨å›æµ‹
            worker_id: Worker ID
        """
        start_time = datetime.now()

        try:
            # 1. æ›´æ–°çŠ¶æ€ä¸ºè®­ç»ƒä¸­
            await self._update_experiment_status(exp_id, 'training', train_started_at=start_time)

            # 2. è®­ç»ƒæ¨¡å‹
            logger.info(f"[Worker-{worker_id}] ğŸ‹ï¸  è®­ç»ƒæ¨¡å‹...")
            model_id, train_metrics, feature_importance, model_path = await self._train_model_async(config)

            train_end_time = datetime.now()
            train_duration = (train_end_time - start_time).total_seconds()

            # 3. ä¿å­˜è®­ç»ƒç»“æœ
            await self._update_experiment_train_result(
                exp_id=exp_id,
                model_id=model_id,
                train_metrics=train_metrics,
                feature_importance=feature_importance,
                model_path=model_path,
                train_completed_at=train_end_time,
                train_duration=int(train_duration)
            )

            logger.info(f"[Worker-{worker_id}] âœ… è®­ç»ƒå®Œæˆ: {model_id}")

            # 4. è‡ªåŠ¨å›æµ‹ï¼ˆå¯é€‰ï¼‰
            if auto_backtest:
                await self._update_experiment_status(exp_id, 'backtesting', backtest_started_at=datetime.now())

                logger.info(f"[Worker-{worker_id}] ğŸ“Š å›æµ‹ä¸­...")
                backtest_result = await self._run_backtest_async(model_id, config)

                backtest_end_time = datetime.now()
                backtest_duration = (backtest_end_time - train_end_time).total_seconds()

                # 5. ä¿å­˜å›æµ‹ç»“æœ
                await self._update_experiment_backtest_result(
                    exp_id=exp_id,
                    backtest_metrics=backtest_result,
                    backtest_completed_at=backtest_end_time,
                    backtest_duration=int(backtest_duration)
                )

                logger.info(f"[Worker-{worker_id}] âœ… å›æµ‹å®Œæˆ")

            # 6. æ ‡è®°å®éªŒå®Œæˆ
            total_duration = (datetime.now() - start_time).total_seconds()
            await self._update_experiment_status(
                exp_id,
                'completed',
                completed_at=datetime.now(),
                total_duration_seconds=int(total_duration)
            )

        except Exception as e:
            logger.error(f"[Worker-{worker_id}] å®éªŒ {exp_id} å¤±è´¥: {e}")
            await self._mark_experiment_failed(exp_id, str(e))
            raise

    async def _train_model_async(self, config: Dict) -> tuple:
        """
        å¼‚æ­¥è®­ç»ƒæ¨¡å‹

        Args:
            config: è®­ç»ƒé…ç½®

        Returns:
            (model_id, metrics, feature_importance, model_path)
        """
        def _train():
            # ä½¿ç”¨ CoreTrainingService ç»Ÿä¸€è®­ç»ƒæµç¨‹
            core_service = CoreTrainingService()

            result = core_service.train_model(
                symbol=config['symbol'],
                start_date=config['start_date'],
                end_date=config['end_date'],
                model_type=config.get('model_type', 'lightgbm'),
                target_period=config.get('target_period', 5),
                scaler_type=config.get('scaler_type', 'robust'),
                balance_samples=config.get('balance_samples', False),
                model_params=config.get('model_params', {}),
                seq_length=config.get('seq_length'),
                epochs=config.get('epochs'),
                use_async=False
            )

            model_id = f"{config['symbol']}_{config.get('model_type')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            metrics = result['metrics']
            feature_importance = result.get('feature_importance', {})
            model_path = result['model_path']

            # æ³¨å†Œæ¨¡å‹åˆ°TrainingTaskManager
            task_manager = TrainingTaskManager()
            task_manager.tasks[model_id] = {
                'task_id': model_id,
                'status': 'completed',
                'model_path': model_path,
                'config': {
                    'model_type': config['model_type'],
                    'target_period': config['target_period'],
                    'symbol': config['symbol'],
                    'scaler_type': config.get('scaler_type', 'robust'),
                },
                'metrics': metrics,
                'feature_importance': feature_importance,
                'created_at': datetime.now().isoformat(),
                'completed_at': datetime.now().isoformat(),
            }
            task_manager._save_metadata()
            logger.info(f"âœ… æ¨¡å‹å·²æ³¨å†Œåˆ°TrainingTaskManager: {model_id}")

            return model_id, metrics, feature_importance, model_path

        return await asyncio.to_thread(_train)

    async def _run_backtest_async(self, model_id: str, config: Dict) -> Dict:
        """
        å¼‚æ­¥è¿è¡Œå›æµ‹

        Args:
            model_id: æ¨¡å‹ID
            config: é…ç½®

        Returns:
            å›æµ‹ç»“æœ
        """
        result = await self.backtest_service.run_backtest_async(
            model_id=model_id,
            symbol=config['symbol'],
            start_date=config['start_date'],
            end_date=config['end_date']
        )
        return result

    # ==================== æ•°æ®åº“æ“ä½œ ====================

    async def _update_batch_status(self, batch_id: int, status: str, **kwargs):
        """æ›´æ–°æ‰¹æ¬¡çŠ¶æ€"""
        from app.services.batch_manager import BatchManager
        batch_manager = BatchManager()
        await batch_manager.update_batch_status(batch_id, status, **kwargs)

    async def _get_pending_experiments(self, batch_id: int) -> List:
        """è·å–å¾…æ‰§è¡Œçš„å®éªŒ"""
        query = """
            SELECT id, batch_id, experiment_name, config
            FROM experiments
            WHERE batch_id = %s AND status = 'pending'
            ORDER BY id
        """
        return await asyncio.to_thread(self.db._execute_query, query, (batch_id,))

    async def _update_experiment_status(self, exp_id: int, status: str, **kwargs):
        """æ›´æ–°å®éªŒçŠ¶æ€"""
        await asyncio.to_thread(
            self.experiment_repo.update_experiment_status,
            exp_id,
            status,
            **kwargs
        )

    async def _update_experiment_train_result(
        self,
        exp_id: int,
        model_id: str,
        train_metrics: Dict,
        feature_importance: Dict,
        model_path: str,
        train_completed_at: datetime,
        train_duration: int
    ):
        """æ›´æ–°å®éªŒè®­ç»ƒç»“æœ"""
        query = """
            UPDATE experiments
            SET model_id = %s, train_metrics = %s, feature_importance = %s,
                model_path = %s, train_completed_at = %s, train_duration_seconds = %s
            WHERE id = %s
        """
        params = (
            model_id,
            train_metrics,
            feature_importance,
            str(model_path),
            train_completed_at,
            train_duration,
            exp_id
        )
        await asyncio.to_thread(self.db._execute_update, query, params)

    async def _update_experiment_backtest_result(
        self,
        exp_id: int,
        backtest_metrics: Dict,
        backtest_completed_at: datetime,
        backtest_duration: int
    ):
        """æ›´æ–°å®éªŒå›æµ‹ç»“æœ"""
        query = """
            UPDATE experiments
            SET backtest_status = 'completed',
                backtest_metrics = %s,
                backtest_completed_at = %s,
                backtest_duration_seconds = %s
            WHERE id = %s
        """
        params = (
            backtest_metrics,
            backtest_completed_at,
            backtest_duration,
            exp_id
        )
        await asyncio.to_thread(self.db._execute_update, query, params)

    async def _mark_experiment_failed(self, exp_id: int, error_message: str):
        """æ ‡è®°å®éªŒå¤±è´¥"""
        await asyncio.to_thread(
            self.experiment_repo.update_experiment_status,
            exp_id,
            'failed',
            error_message=error_message
        )

    async def _increment_batch_counter(self, batch_id: int, counter_type: str):
        """å¢åŠ æ‰¹æ¬¡è®¡æ•°å™¨"""
        from app.services.batch_manager import BatchManager
        batch_manager = BatchManager()
        await batch_manager.increment_batch_counter(batch_id, counter_type)
