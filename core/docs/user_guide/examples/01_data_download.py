"""
æ•°æ®ä¸‹è½½ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä»å¤šä¸ªæ•°æ®æºä¸‹è½½Aè‚¡æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“ã€‚

ä½œè€…: Quant Team
ç‰ˆæœ¬: v3.0.0
æ—¥æœŸ: 2026-02-01
"""

import argparse
from datetime import datetime, timedelta
from typing import List, Optional

import pandas as pd
from loguru import logger

from src.providers import DataProviderFactory
from src.data.database_manager import DatabaseManager
from src.data.data_validator import DataValidator
from src.utils.exceptions import DataFetchError, DataValidationError


def download_single_stock(
    stock_code: str,
    start_date: str,
    end_date: Optional[str] = None,
    provider_name: str = 'akshare',
    save_to_db: bool = True
) -> pd.DataFrame:
    """
    ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚'000001.SZ'ï¼‰
        start_date: å¼€å§‹æ—¥æœŸï¼ˆ'YYYY-MM-DD'ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ä¸ºä»Šå¤©ï¼‰
        provider_name: æ•°æ®æä¾›è€…ï¼ˆ'akshare'æˆ–'tushare'ï¼‰
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        pd.DataFrame: è‚¡ç¥¨æ•°æ®

    Raises:
        DataFetchError: æ•°æ®è·å–å¤±è´¥
        DataValidationError: æ•°æ®éªŒè¯å¤±è´¥
    """
    logger.info(f"å¼€å§‹ä¸‹è½½ {stock_code} æ•°æ®...")

    # è®¾ç½®ç»“æŸæ—¥æœŸ
    if end_date is None:
        end_date = datetime.now().strftime('%Y-%m-%d')

    try:
        # 1. åˆ›å»ºæ•°æ®æä¾›è€…
        provider = DataProviderFactory.create_provider(provider_name)
        logger.info(f"ä½¿ç”¨æ•°æ®æº: {provider_name}")

        # 2. è·å–æ•°æ®
        data = provider.get_daily_data(
            stock_code=stock_code,
            start_date=start_date,
            end_date=end_date
        )

        logger.info(f"âœ… è·å–äº† {len(data)} æ¡æ•°æ®")

        # 3. æ•°æ®éªŒè¯
        validator = DataValidator()
        is_valid, errors = validator.validate(data)

        if not is_valid:
            logger.warning(f"âš ï¸ æ•°æ®è´¨é‡é—®é¢˜: {errors}")
            # æ¸…æ´—æ•°æ®
            data = validator.clean(data)
            logger.info("âœ… æ•°æ®å·²æ¸…æ´—")

        # 4. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
        if save_to_db:
            db = DatabaseManager()
            db.insert_stock_data(data)
            logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")

        # 5. æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
        logger.info("\næ•°æ®æ¦‚è§ˆ:")
        logger.info(f"  æ—¶é—´èŒƒå›´: {data['trade_date'].min()} ~ {data['trade_date'].max()}")
        logger.info(f"  ä»·æ ¼èŒƒå›´: {data['close'].min():.2f} ~ {data['close'].max():.2f}")
        logger.info(f"  å¹³å‡æˆäº¤é‡: {data['volume'].mean():.0f}")

        return data

    except Exception as e:
        logger.exception(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        raise DataFetchError(f"Failed to download {stock_code}: {e}")


def download_multiple_stocks(
    stock_codes: List[str],
    start_date: str,
    end_date: Optional[str] = None,
    provider_name: str = 'akshare',
    save_to_db: bool = True
) -> dict:
    """
    æ‰¹é‡ä¸‹è½½å¤šåªè‚¡ç¥¨æ•°æ®

    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        provider_name: æ•°æ®æä¾›è€…
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        dict: {è‚¡ç¥¨ä»£ç : DataFrame}
    """
    logger.info(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(stock_codes)} åªè‚¡ç¥¨...")

    results = {}
    success_count = 0
    fail_count = 0

    for i, code in enumerate(stock_codes, 1):
        try:
            logger.info(f"\n[{i}/{len(stock_codes)}] å¤„ç† {code}")

            data = download_single_stock(
                stock_code=code,
                start_date=start_date,
                end_date=end_date,
                provider_name=provider_name,
                save_to_db=save_to_db
            )

            results[code] = data
            success_count += 1

        except Exception as e:
            logger.error(f"âŒ {code} ä¸‹è½½å¤±è´¥: {e}")
            fail_count += 1
            continue

    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "=" * 50)
    logger.info("ä¸‹è½½å®Œæˆ!")
    logger.info(f"  æˆåŠŸ: {success_count}/{len(stock_codes)}")
    logger.info(f"  å¤±è´¥: {fail_count}/{len(stock_codes)}")
    logger.info("=" * 50)

    return results


def download_index_components(
    index_code: str = '000300.SH',
    start_date: str = '2023-01-01',
    save_to_db: bool = True
) -> dict:
    """
    ä¸‹è½½æŒ‡æ•°æˆåˆ†è‚¡æ•°æ®

    Args:
        index_code: æŒ‡æ•°ä»£ç ï¼ˆ'000300.SH'=æ²ªæ·±300ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        dict: æˆåˆ†è‚¡æ•°æ®
    """
    logger.info(f"è·å– {index_code} æˆåˆ†è‚¡...")

    from src.utils.stock_utils import get_index_components

    # è·å–æˆåˆ†è‚¡åˆ—è¡¨
    components = get_index_components(index_code)
    logger.info(f"âœ… è·å–äº† {len(components)} åªæˆåˆ†è‚¡")

    # æ‰¹é‡ä¸‹è½½
    return download_multiple_stocks(
        stock_codes=components,
        start_date=start_date,
        save_to_db=save_to_db
    )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Aè‚¡æ•°æ®ä¸‹è½½å·¥å…·')

    parser.add_argument(
        '--stock',
        type=str,
        default='000001.SZ',
        help='è‚¡ç¥¨ä»£ç ï¼ˆé»˜è®¤ï¼š000001.SZ å¹³å®‰é“¶è¡Œï¼‰'
    )

    parser.add_argument(
        '--stocks',
        type=str,
        nargs='+',
        help='å¤šåªè‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZ 600000.SHï¼‰'
    )

    parser.add_argument(
        '--index',
        type=str,
        help='æŒ‡æ•°ä»£ç ï¼ˆå¦‚ï¼š000300.SH æ²ªæ·±300ï¼‰'
    )

    parser.add_argument(
        '--start',
        type=str,
        default=(datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d'),
        help='å¼€å§‹æ—¥æœŸï¼ˆé»˜è®¤ï¼š1å¹´å‰ï¼‰'
    )

    parser.add_argument(
        '--end',
        type=str,
        default=datetime.now().strftime('%Y-%m-%d'),
        help='ç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ï¼šä»Šå¤©ï¼‰'
    )

    parser.add_argument(
        '--provider',
        type=str,
        default='akshare',
        choices=['akshare', 'tushare'],
        help='æ•°æ®æä¾›è€…ï¼ˆé»˜è®¤ï¼šakshareï¼‰'
    )

    parser.add_argument(
        '--no-db',
        action='store_true',
        help='ä¸ä¿å­˜åˆ°æ•°æ®åº“'
    )

    parser.add_argument(
        '--output',
        type=str,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆCSVæ ¼å¼ï¼‰'
    )

    args = parser.parse_args()

    try:
        # åœºæ™¯1: ä¸‹è½½æŒ‡æ•°æˆåˆ†è‚¡
        if args.index:
            results = download_index_components(
                index_code=args.index,
                start_date=args.start,
                save_to_db=not args.no_db
            )

        # åœºæ™¯2: ä¸‹è½½å¤šåªè‚¡ç¥¨
        elif args.stocks:
            results = download_multiple_stocks(
                stock_codes=args.stocks,
                start_date=args.start,
                end_date=args.end,
                provider_name=args.provider,
                save_to_db=not args.no_db
            )

        # åœºæ™¯3: ä¸‹è½½å•åªè‚¡ç¥¨
        else:
            data = download_single_stock(
                stock_code=args.stock,
                start_date=args.start,
                end_date=args.end,
                provider_name=args.provider,
                save_to_db=not args.no_db
            )

            # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            if args.output:
                data.to_csv(args.output, index=False)
                logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")

        logger.info("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")

    except Exception as e:
        logger.exception(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
