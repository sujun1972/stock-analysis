# æœºå™¨å­¦ä¹ ç³»ç»Ÿå®Œæ•´æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v5.1.0
**æœ€åæ›´æ–°**: 2026-02-07

---

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
- [å®Œæ•´å·¥ä½œæµç¨‹](#å®Œæ•´å·¥ä½œæµç¨‹)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ¨¡å‹ç»´æŠ¤](#æ¨¡å‹ç»´æŠ¤)

**ğŸ“– ä¸“é¢˜æ–‡æ¡£**:
- [MLStockRanker å®Œæ•´æŒ‡å—](./mlstockranker.md) - è‚¡ç¥¨è¯„åˆ†å’Œæ’åå·¥å…·çš„è¯¦ç»†è¯´æ˜
- [è¯„ä¼°æŒ‡æ ‡è¯¦è§£](./evaluation-metrics.md) - RMSE, IC, å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡çš„å®Œæ•´è¯´æ˜

---

## ç³»ç»Ÿæ¦‚è¿°

### æœºå™¨å­¦ä¹ åœ¨ç³»ç»Ÿä¸­çš„è§’è‰²

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             ML å…¥åœºä¿¡å·ç³»ç»Ÿå®Œæ•´æµç¨‹                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é˜¶æ®µ 1: æ•°æ®å‡†å¤‡ä¸ç‰¹å¾å·¥ç¨‹
  â”œâ”€ [è‚¡ç¥¨æ± ] + [å†å²è¡Œæƒ…æ•°æ®]
  â”œâ”€ FeatureEngine.calculate_features()
  â”‚   â”œâ”€ Alpha å› å­ (125+)
  â”‚   â”œâ”€ æŠ€æœ¯æŒ‡æ ‡ (60+)
  â”‚   â”œâ”€ æˆäº¤é‡ç‰¹å¾
  â”‚   â””â”€ å¸‚åœºæƒ…ç»ªç‰¹å¾
  â”œâ”€ ç‰¹å¾é¢„å¤„ç†(ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€æ ‡å‡†åŒ–)
  â””â”€ â†’ [ç‰¹å¾çŸ©é˜µ] (N stocks Ã— 125+ features)
        â†“
é˜¶æ®µ 2: æ¨¡å‹è®­ç»ƒ
  â”œâ”€ LabelGenerator.generate_labels()
  â”œâ”€ ModelTrainer.train()
  â”‚   â”œâ”€ æ¨¡å‹é€‰æ‹©: LightGBM / XGBoost / Neural Net
  â”‚   â”œâ”€ è¶…å‚æ•°ä¼˜åŒ–: Optuna / Grid Search
  â”‚   â””â”€ äº¤å‰éªŒè¯: TimeSeriesSplit
  â”œâ”€ ModelEvaluator.evaluate()
  â”‚   â”œâ”€ IC (Information Coefficient)
  â”‚   â”œâ”€ Rank IC
  â”‚   â””â”€ åˆ†ç»„å›æµ‹
  â””â”€ â†’ [è®­ç»ƒå¥½çš„æ¨¡å‹] (model.pkl)
        â†“
é˜¶æ®µ 3: ä¿¡å·ç”Ÿæˆ(å›æµ‹/å®ç›˜)
  â”œâ”€ MLEntry.generate_signals(stock_pool, date)
  â”‚   â”œâ”€ 1. è®¡ç®—å½“æ—¥ç‰¹å¾
  â”‚   â”œâ”€ 2. æ¨¡å‹é¢„æµ‹(expected_return + confidence)
  â”‚   â”œâ”€ 3. ä¿¡å·ç­›é€‰(ç½®ä¿¡åº¦è¿‡æ»¤ + Top N)
  â”‚   â”œâ”€ 4. æƒé‡è®¡ç®—(sharpe Ã— confidence)
  â”‚   â””â”€ 5. å½’ä¸€åŒ–æƒé‡
  â””â”€ â†’ [äº¤æ˜“ä¿¡å·] {'stock': {'action': 'long/short', 'weight': 0.xx}}
```

### ML ç»„ä»¶å¯¹æ¯”

| ç»„ä»¶ | MLStockRanker | MLEntry |
|------|--------------|---------|
| **ç±»å‹** | è¾…åŠ©å·¥å…· | ç­–ç•¥ç»„ä»¶ |
| **å®šä½** | è‚¡ç¥¨ç­›é€‰å™¨/é¢„æµ‹å™¨ | äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨ |
| **è¾“å…¥** | å¤§è‚¡ç¥¨æ±  (3000+) | å°è‚¡ç¥¨æ±  (50-100) |
| **è¾“å‡º** | è¯„åˆ† + æ’å | å¤šç©ºä¿¡å· + æƒé‡ |
| **ä½¿ç”¨æ—¶æœº** | å›æµ‹å‰(ä¸€æ¬¡æ€§) | å›æµ‹ä¸­(æ¯æ—¥) |
| **é¢‘ç‡** | ä½ | é«˜ |
| **å¯é€‰æ€§** | å®Œå…¨å¯é€‰ | ç­–ç•¥å¿…éœ€ |

---

## æ ¸å¿ƒç»„ä»¶

### 1. ç‰¹å¾å·¥ç¨‹å¼•æ“ (FeatureEngine)

**èŒè´£**: è®¡ç®— 125+ ç‰¹å¾(Alpha å› å­ + æŠ€æœ¯æŒ‡æ ‡ + æˆäº¤é‡ç‰¹å¾)

```python
class FeatureEngine:
    """
    ç‰¹å¾å·¥ç¨‹å¼•æ“
    """

    def __init__(
        self,
        feature_groups: List[str] = None,
        lookback_window: int = 60,
        cache_enabled: bool = True
    ):
        self.feature_groups = feature_groups or ['all']
        self.lookback_window = lookback_window
        self.cache = {} if cache_enabled else None

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        """
        è®¡ç®—ç‰¹å¾çŸ©é˜µ

        Returns:
            pd.DataFrame:
                index = stock_codes
                columns = feature_names (125+)
        """
        features = pd.DataFrame(index=stock_codes)

        # Alpha å› å­ (125+)
        if 'alpha' in self.feature_groups or 'all' in self.feature_groups:
            alpha_features = self._calculate_alpha_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, alpha_features], axis=1)

        # æŠ€æœ¯æŒ‡æ ‡ (60+)
        if 'technical' in self.feature_groups or 'all' in self.feature_groups:
            tech_features = self._calculate_technical_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, tech_features], axis=1)

        # æˆäº¤é‡ç‰¹å¾
        if 'volume' in self.feature_groups or 'all' in self.feature_groups:
            volume_features = self._calculate_volume_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, volume_features], axis=1)

        return features
```

**ç‰¹å¾ç±»åˆ«**:

| ç±»åˆ« | æ•°é‡ | ç¤ºä¾‹ |
|------|------|------|
| Alpha å› å­ | 125+ | åŠ¨é‡ã€åè½¬ã€æ³¢åŠ¨ç‡ã€æˆäº¤é‡ |
| æŠ€æœ¯æŒ‡æ ‡ | 60+ | RSI, MACD, KDJ, å¸ƒæ—å¸¦ |
| æˆäº¤é‡ç‰¹å¾ | 10+ | æˆäº¤é‡æ¯”ç‡ã€æ¢æ‰‹ç‡ |
| å¸‚åœºæƒ…ç»ª | 5+ | å¸‚åœºå®½åº¦ã€æ¶¨è·Œå®¶æ•° |

### 2. æ ‡ç­¾ç”Ÿæˆå™¨ (LabelGenerator)

**èŒè´£**: ç”Ÿæˆè®­ç»ƒæ ‡ç­¾(æœªæ¥æ”¶ç›Šç‡)

```python
class LabelGenerator:
    """
    æ ‡ç­¾ç”Ÿæˆå™¨
    """

    def __init__(
        self,
        forward_window: int = 5,
        label_type: str = 'return'
    ):
        self.forward_window = forward_window
        self.label_type = label_type

    def generate_labels(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.Series:
        """
        ç”Ÿæˆæ ‡ç­¾

        Returns:
            pd.Series:
                index = stock_codes
                values = æœªæ¥æ”¶ç›Šç‡(æˆ–æ–¹å‘)
        """
        labels = {}

        for stock in stock_codes:
            stock_data = market_data[market_data['stock_code'] == stock]

            # æ‰¾åˆ°å½“å‰æ—¥æœŸçš„ä½ç½®
            current_idx = stock_data[stock_data['date'] == date].index
            if len(current_idx) == 0:
                continue

            # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
            current_price = stock_data.loc[current_idx[0], 'close']
            future_idx = current_idx[0] + self.forward_window

            if future_idx < len(stock_data):
                future_price = stock_data.iloc[future_idx]['close']

                if self.label_type == 'return':
                    labels[stock] = (future_price - current_price) / current_price
                elif self.label_type == 'direction':
                    labels[stock] = 1 if future_price > current_price else 0

        return pd.Series(labels)
```

### 3. æ¨¡å‹è®­ç»ƒå™¨ (ModelTrainer)

**èŒè´£**: è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹

```python
@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    model_type: str = 'lightgbm'
    train_start_date: str = '2020-01-01'
    train_end_date: str = '2023-12-31'
    validation_split: float = 0.2
    forward_window: int = 5
    feature_groups: List[str] = None
    hyperparameters: Dict = None


class ModelTrainer:
    """
    æ¨¡å‹è®­ç»ƒå™¨
    """

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.feature_engine = FeatureEngine(
            feature_groups=config.feature_groups,
            lookback_window=60
        )
        self.label_generator = LabelGenerator(
            forward_window=config.forward_window,
            label_type='return'
        )

    def train(
        self,
        stock_pool: List[str],
        market_data: pd.DataFrame
    ) -> 'TrainedModel':
        """
        è®­ç»ƒæ¨¡å‹

        Returns:
            TrainedModel: è®­ç»ƒå¥½çš„æ¨¡å‹
        """
        # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
        X_train, y_train, X_val, y_val = self._prepare_training_data(
            stock_pool, market_data
        )

        # 2. è®­ç»ƒæ¨¡å‹
        model = self._train_model(X_train, y_train, X_val, y_val)

        # 3. è¯„ä¼°æ¨¡å‹
        metrics = self._evaluate_model(model, X_val, y_val)

        return TrainedModel(
            model=model,
            feature_engine=self.feature_engine,
            config=self.config,
            metrics=metrics
        )
```

### 4. è®­ç»ƒå¥½çš„æ¨¡å‹ (TrainedModel)

**èŒè´£**: å°è£…æ¨¡å‹ + ç‰¹å¾å¼•æ“ï¼Œæä¾›é¢„æµ‹æ¥å£

```python
class TrainedModel:
    """
    è®­ç»ƒå¥½çš„æ¨¡å‹(å¯ä¿å­˜å’ŒåŠ è½½)
    """

    def __init__(
        self,
        model,
        feature_engine: FeatureEngine,
        config: TrainingConfig,
        metrics: Dict
    ):
        self.model = model
        self.feature_engine = feature_engine
        self.config = config
        self.metrics = metrics

    def predict(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        """
        é¢„æµ‹

        Returns:
            pd.DataFrame:
                columns = ['expected_return', 'volatility', 'confidence']
                index = stock_codes
        """
        # 1. è®¡ç®—ç‰¹å¾
        features = self.feature_engine.calculate_features(
            stock_codes, market_data, date
        )

        # 2. æ•°æ®æ¸…æ´—
        features = features.fillna(0).replace([np.inf, -np.inf], 0)

        # 3. æ¨¡å‹é¢„æµ‹
        predictions = self.model.predict(features)

        # 4. æ„å»ºé¢„æµ‹ç»“æœ
        result = pd.DataFrame(index=features.index)
        result['expected_return'] = predictions
        result['volatility'] = self._estimate_volatility(
            stock_codes, market_data, date
        )
        result['confidence'] = self._estimate_confidence(features)

        return result

    def save(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        import joblib
        joblib.dump(self, path)

    @staticmethod
    def load(path: str) -> 'TrainedModel':
        """åŠ è½½æ¨¡å‹"""
        import joblib
        return joblib.load(path)
```

### 5. ML å…¥åœºç­–ç•¥ (MLEntry)

**èŒè´£**: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆäº¤æ˜“ä¿¡å·

```python
class MLEntry(EntryStrategy):
    """
    æœºå™¨å­¦ä¹ å…¥åœºç­–ç•¥
    """

    def __init__(
        self,
        model_path: str,
        confidence_threshold: float = 0.7,
        top_long: int = 20,
        top_short: int = 10
    ):
        self.model: TrainedModel = TrainedModel.load(model_path)
        self.confidence_threshold = confidence_threshold
        self.top_long = top_long
        self.top_short = top_short

    def generate_signals(
        self,
        stock_pool: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> Dict[str, Dict]:
        """
        ç”Ÿæˆå…¥åœºä¿¡å·
        """
        # 1. æ¨¡å‹é¢„æµ‹
        predictions = self.model.predict(stock_pool, market_data, date)

        # 2. ç­›é€‰åšå¤šå€™é€‰
        long_candidates = predictions[
            (predictions['expected_return'] > 0) &
            (predictions['confidence'] > self.confidence_threshold)
        ].copy()

        # è®¡ç®—åšå¤šæƒé‡
        long_candidates['weight'] = (
            (long_candidates['expected_return'] / long_candidates['volatility']) *
            long_candidates['confidence']
        )
        long_candidates = long_candidates.nlargest(self.top_long, 'weight')

        # 3. ç­›é€‰åšç©ºå€™é€‰
        short_candidates = predictions[
            (predictions['expected_return'] < 0) &
            (predictions['confidence'] > self.confidence_threshold)
        ].copy()

        # è®¡ç®—åšç©ºæƒé‡
        short_candidates['weight'] = (
            (abs(short_candidates['expected_return']) / short_candidates['volatility']) *
            short_candidates['confidence']
        )
        short_candidates = short_candidates.nlargest(self.top_short, 'weight')

        # 4. åˆå¹¶ä¿¡å·
        signals = {}
        for stock, row in long_candidates.iterrows():
            signals[stock] = {'action': 'long', 'weight': row['weight']}
        for stock, row in short_candidates.iterrows():
            signals[stock] = {'action': 'short', 'weight': row['weight']}

        # 5. å½’ä¸€åŒ–æƒé‡
        total_weight = sum(s['weight'] for s in signals.values())
        if total_weight > 0:
            for stock in signals:
                signals[stock]['weight'] /= total_weight

        return signals
```

---

## å®Œæ•´å·¥ä½œæµç¨‹

### åœºæ™¯ 1: è®­ç»ƒ ML æ¨¡å‹

```python
from core.ml.model_trainer import ModelTrainer, TrainingConfig
from core.data import load_market_data

# Step 1: é…ç½®è®­ç»ƒå‚æ•°
config = TrainingConfig(
    model_type='lightgbm',
    train_start_date='2020-01-01',
    train_end_date='2023-12-31',
    validation_split=0.2,
    forward_window=5,
    feature_groups=['alpha', 'technical', 'volume'],
    hyperparameters={
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.8
    }
)

# Step 2: å‡†å¤‡æ•°æ®
stock_pool = ['600000.SH', '000001.SZ', ..., 300]
market_data = load_market_data(
    stock_codes=stock_pool,
    start_date='2019-01-01',
    end_date='2023-12-31'
)

# Step 3: è®­ç»ƒæ¨¡å‹
trainer = ModelTrainer(config)
trained_model = trainer.train(stock_pool, market_data)

# Step 4: ä¿å­˜æ¨¡å‹
trained_model.save('models/ml_entry_model.pkl')

print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
print(f"éªŒè¯é›† IC: {trained_model.metrics['ic']:.4f}")
print(f"éªŒè¯é›† Rank IC: {trained_model.metrics['rank_ic']:.4f}")
```

### åœºæ™¯ 2: ä½¿ç”¨ ML ç­–ç•¥å›æµ‹

```python
from core.strategies.entries import MLEntry
from core.strategies.exits import TimeBasedExit
from core.risk import RiskManager
from core.backtest import BacktestEngine

# Step 1: åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
entry_strategy = MLEntry(
    model_path='models/ml_entry_model.pkl',
    confidence_threshold=0.7,
    top_long=20,
    top_short=10
)

# Step 2: é…ç½®é€€å‡ºç­–ç•¥å’Œé£æ§
exit_strategy = TimeBasedExit(max_holding_days=10)
risk_manager = RiskManager(
    max_position_loss_pct=0.10,
    max_leverage=1.0
)

# Step 3: è¿è¡Œå›æµ‹
engine = BacktestEngine(
    entry_strategy=entry_strategy,
    exit_strategy=exit_strategy,
    risk_manager=risk_manager
)

result = engine.run(
    stock_pool=stock_pool,
    market_data=market_data,
    start_date='2024-01-01',
    end_date='2024-12-31'
)

# Step 4: åˆ†æç»“æœ
print(f"æ€»æ”¶ç›Šç‡: {result.total_return:.2%}")
print(f"å¹´åŒ–æ”¶ç›Šç‡: {result.annual_return:.2%}")
print(f"å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
print(f"æœ€å¤§å›æ’¤: {result.max_drawdown:.2%}")
```

### åœºæ™¯ 3: MLStockRanker + ML ç­–ç•¥ç»„åˆ

```python
from core.features.ml_ranker import MLStockRanker

# Step 1: ä½¿ç”¨ MLStockRanker ç­›é€‰é«˜æ½œåŠ›è‚¡ç¥¨æ± 
ranker = MLStockRanker(model_path='models/ranker.pkl')
rankings = ranker.rank(
    stock_pool=all_a_stocks,  # å…¨ A è‚¡(3000+)
    market_data=market_data,
    date='2024-01-01',
    return_top_n=100
)

# æå– Top 100 ä½œä¸ºè‚¡ç¥¨æ± 
selected_stock_pool = list(rankings.keys())

# Step 2: åœ¨ç­›é€‰åçš„è‚¡ç¥¨æ± ä¸Šè¿è¡Œ ML ç­–ç•¥
entry_strategy = MLEntry(
    model_path='models/ml_entry_model.pkl',
    confidence_threshold=0.7
)

result = engine.run(
    stock_pool=selected_stock_pool,
    market_data=market_data,
    start_date='2024-01-01',
    end_date='2024-12-31'
)
```

---

## ä½¿ç”¨æŒ‡å—

### æ¨¡å‹è®­ç»ƒæœ€ä½³å®è·µ

#### 1. æ•°æ®å‡†å¤‡

```python
# ç¡®ä¿æ•°æ®å®Œæ•´æ€§
market_data = load_market_data(
    stock_codes=stock_pool,
    start_date='2019-01-01',  # ç•™å‡º lookback window
    end_date='2023-12-31'
)

# æ£€æŸ¥æ•°æ®è´¨é‡
assert market_data.isnull().sum().sum() == 0
assert len(market_data) > 0
```

#### 2. ç‰¹å¾é€‰æ‹©

```python
# å…¨ç‰¹å¾è®­ç»ƒ
config = TrainingConfig(
    feature_groups=['all'],  # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾
    ...
)

# æˆ–é€‰æ‹©ç‰¹å®šç‰¹å¾ç»„
config = TrainingConfig(
    feature_groups=['alpha', 'technical'],  # åªä½¿ç”¨ Alpha å’ŒæŠ€æœ¯æŒ‡æ ‡
    ...
)
```

#### 3. è¶…å‚æ•°è°ƒä¼˜

```python
# LightGBM æ¨èå‚æ•°
hyperparameters = {
    'objective': 'regression',
    'metric': 'l2',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5
}

config = TrainingConfig(
    model_type='lightgbm',
    hyperparameters=hyperparameters,
    ...
)
```

#### 4. æ¨¡å‹è¯„ä¼°

```python
# è¯„ä¼°æŒ‡æ ‡
metrics = trained_model.metrics

print(f"IC: {metrics['ic']:.4f}")           # ä¿¡æ¯ç³»æ•°
print(f"Rank IC: {metrics['rank_ic']:.4f}") # ç§©ç›¸å…³ç³»æ•°

# IC > 0.05 è¡¨ç¤ºæ¨¡å‹æœ‰æ•ˆ
# Rank IC > 0.1 è¡¨ç¤ºæ¨¡å‹ä¼˜ç§€
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. ç‰¹å¾ç¼“å­˜

```python
class CachedFeatureEngine(FeatureEngine):
    """å¸¦ç¼“å­˜çš„ç‰¹å¾å¼•æ“"""

    def __init__(self, cache_dir: str = './cache/features', **kwargs):
        super().__init__(**kwargs)
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{date}_{hash(tuple(sorted(stock_codes)))}"
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.parquet")

        if os.path.exists(cache_path):
            return pd.read_parquet(cache_path)

        # è®¡ç®—ç‰¹å¾
        features = super().calculate_features(stock_codes, market_data, date)

        # ä¿å­˜ç¼“å­˜
        features.to_parquet(cache_path)
        return features
```

### 2. å¹¶è¡Œè®¡ç®—

```python
from joblib import Parallel, delayed

class ParallelFeatureEngine(FeatureEngine):
    """å¹¶è¡Œç‰¹å¾å¼•æ“"""

    def __init__(self, n_jobs: int = 4, **kwargs):
        super().__init__(**kwargs)
        self.n_jobs = n_jobs

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        # å°†è‚¡ç¥¨æ± åˆ†æ‰¹
        batch_size = len(stock_codes) // self.n_jobs
        batches = [
            stock_codes[i:i+batch_size]
            for i in range(0, len(stock_codes), batch_size)
        ]

        # å¹¶è¡Œè®¡ç®—
        results = Parallel(n_jobs=self.n_jobs)(
            delayed(super().calculate_features)(batch, market_data, date)
            for batch in batches
        )

        # åˆå¹¶ç»“æœ
        return pd.concat(results, axis=0)
```

### 3. æ¨¡å‹æ¨ç†ä¼˜åŒ–

```python
# æ‰¹é‡é¢„æµ‹
predictions = model.predict(features, num_iteration=model.best_iteration)

# ä½¿ç”¨ GPU åŠ é€Ÿ (XGBoost)
params = {
    'tree_method': 'gpu_hist',
    'gpu_id': 0
}
```

---

## æ¨¡å‹ç»´æŠ¤

### æ¨¡å‹é‡è®­ç»ƒç­–ç•¥

```python
class ModelUpdateScheduler:
    """æ¨¡å‹æ›´æ–°è°ƒåº¦å™¨"""

    def __init__(
        self,
        retrain_frequency: str = 'quarterly',
        performance_threshold: float = 0.10
    ):
        self.retrain_frequency = retrain_frequency
        self.performance_threshold = performance_threshold

    def should_retrain(
        self,
        current_model: TrainedModel,
        recent_performance: Dict
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è®­ç»ƒ"""
        # ç­–ç•¥ 1: æŒ‰æ—¶é—´å‘¨æœŸ
        if self._is_time_to_retrain():
            return True

        # ç­–ç•¥ 2: æ€§èƒ½ä¸‹é™
        baseline_ic = current_model.metrics['ic']
        recent_ic = recent_performance['ic']

        if (baseline_ic - recent_ic) / baseline_ic > self.performance_threshold:
            return True

        return False
```

### åœ¨çº¿æ€§èƒ½ç›‘æ§

```python
class ModelMonitor:
    """æ¨¡å‹æ€§èƒ½ç›‘æ§"""

    def __init__(self, model: TrainedModel):
        self.model = model
        self.performance_history = []

    def evaluate_recent_performance(
        self,
        stock_pool: List[str],
        market_data: pd.DataFrame,
        start_date: str,
        end_date: str
    ) -> Dict:
        """è¯„ä¼°è¿‘æœŸæ¨¡å‹æ€§èƒ½"""
        dates = pd.date_range(start_date, end_date, freq='B')

        all_predictions = []
        all_actuals = []

        for date in dates:
            # é¢„æµ‹
            predictions = self.model.predict(stock_pool, market_data, date)

            # å®é™…æ”¶ç›Š
            actuals = self._get_actual_returns(
                stock_pool, market_data, date, forward_window=5
            )

            all_predictions.extend(predictions['expected_return'].values)
            all_actuals.extend(actuals.values)

        # è®¡ç®— IC
        ic = np.corrcoef(all_actuals, all_predictions)[0, 1]

        return {'ic': ic, 'period': f'{start_date} to {end_date}'}
```

---

## ç›¸å…³æ–‡æ¡£

- [MLStockRanker å®Œæ•´æŒ‡å—](./mlstockranker.md) - â­ æ¨èé˜…è¯»
- [è¯„ä¼°æŒ‡æ ‡è¯¦è§£](./evaluation-metrics.md) - â­ æ¨èé˜…è¯»
- [æ¶æ„è¯¦è§£](../architecture/overview.md)
- [ç­–ç•¥ç³»ç»Ÿ](../strategies/README.md)
- [ç‰¹å¾å·¥ç¨‹](../features/README.md)
- [API å‚è€ƒ](../api/reference.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v5.1.0
**æœ€åæ›´æ–°**: 2026-02-08
