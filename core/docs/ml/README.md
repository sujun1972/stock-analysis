# æœºå™¨å­¦ä¹ ç³»ç»Ÿå®Œæ•´æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v6.0.0
**æœ€åæ›´æ–°**: 2026-02-08
**å®ç°çŠ¶æ€**: âœ… å®Œå…¨å®ç° - Phase 1-3 å…¨éƒ¨å®Œæˆ (100%)

---

## â­ é‡è¦æ›´æ–°

**Phase 3 Day 18-19 æ–‡æ¡£æ›´æ–° (2026-02-08)**:
- âœ… æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å·²å®ç°å¹¶é€šè¿‡æµ‹è¯•
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡: 93%
- âœ… é›†æˆæµ‹è¯•: 11/11 é€šè¿‡
- âœ… å›æµ‹å¼•æ“å®Œå…¨æ”¯æŒMLEntryç­–ç•¥
- âœ… æä¾›å®Œæ•´ç¤ºä¾‹ä»£ç  (examples/ ç›®å½•)

---

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
  - [FeatureEngine - ç‰¹å¾å·¥ç¨‹å¼•æ“](#1-ç‰¹å¾å·¥ç¨‹å¼•æ“-featureengine)
  - [LabelGenerator - æ ‡ç­¾ç”Ÿæˆå™¨](#2-æ ‡ç­¾ç”Ÿæˆå™¨-labelgenerator)
  - [TrainedModel - è®­ç»ƒå¥½çš„æ¨¡å‹](#3-è®­ç»ƒå¥½çš„æ¨¡å‹-trainedmodel)
  - [MLEntry - MLå…¥åœºç­–ç•¥](#4-ml-å…¥åœºç­–ç•¥-mlentry)
  - [MLStockRanker - è‚¡ç¥¨è¯„åˆ†å·¥å…·](#5-ml-è‚¡ç¥¨è¯„åˆ†å·¥å…·-mlstockranker)
- [å®Œæ•´å·¥ä½œæµç¨‹](#å®Œæ•´å·¥ä½œæµç¨‹)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ¨¡å‹ç»´æŠ¤](#æ¨¡å‹ç»´æŠ¤)
- [å®ç°çŠ¶æ€](#å®ç°çŠ¶æ€)

**ğŸ“– ä¸“é¢˜æ–‡æ¡£**:
- [MLStockRanker å®Œæ•´æŒ‡å—](./mlstockranker.md) - è‚¡ç¥¨è¯„åˆ†å’Œæ’åå·¥å…·çš„è¯¦ç»†è¯´æ˜
- [è¯„ä¼°æŒ‡æ ‡è¯¦è§£](./evaluation-metrics.md) - RMSE, IC, å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡çš„å®Œæ•´è¯´æ˜
- [ä½¿ç”¨æŒ‡å—](./user-guide.md) - å¿«é€Ÿå…¥é—¨å’Œæœ€ä½³å®è·µ

**ğŸ’¡ å¿«é€Ÿå¼€å§‹**:
- æŸ¥çœ‹ [examples/](../../examples/) ç›®å½•è·å–å®Œæ•´ç¤ºä¾‹ä»£ç 
- è¿è¡Œ `python examples/backtest_ml_strategy.py` ä½“éªŒMLç­–ç•¥å›æµ‹

---

## ç³»ç»Ÿæ¦‚è¿°

### æœºå™¨å­¦ä¹ åœ¨ç³»ç»Ÿä¸­çš„è§’è‰²

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             ML å…¥åœºä¿¡å·ç³»ç»Ÿå®Œæ•´æµç¨‹                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é˜¶æ®µ 1: æ•°æ®å‡†å¤‡ä¸ç‰¹å¾å·¥ç¨‹
  â”œâ”€ [è‚¡ç¥¨æ± ] + [å†å²è¡Œæƒ…æ•°æ®]
  â”œâ”€ FeatureEngine.calculate_features()
  â”‚   â”œâ”€ Alpha å› å­ (125+)
  â”‚   â”œâ”€ æŠ€æœ¯æŒ‡æ ‡ (60+)
  â”‚   â”œâ”€ æˆäº¤é‡ç‰¹å¾
  â”‚   â””â”€ å¸‚åœºæƒ…ç»ªç‰¹å¾
  â”œâ”€ ç‰¹å¾é¢„å¤„ç†(ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€æ ‡å‡†åŒ–)
  â””â”€ â†’ [ç‰¹å¾çŸ©é˜µ] (N stocks Ã— 125+ features)
        â†“
é˜¶æ®µ 2: æ¨¡å‹è®­ç»ƒ
  â”œâ”€ LabelGenerator.generate_labels()
  â”œâ”€ ModelTrainer.train()
  â”‚   â”œâ”€ æ¨¡å‹é€‰æ‹©: LightGBM / XGBoost / Neural Net
  â”‚   â”œâ”€ è¶…å‚æ•°ä¼˜åŒ–: Optuna / Grid Search
  â”‚   â””â”€ äº¤å‰éªŒè¯: TimeSeriesSplit
  â”œâ”€ ModelEvaluator.evaluate()
  â”‚   â”œâ”€ IC (Information Coefficient)
  â”‚   â”œâ”€ Rank IC
  â”‚   â””â”€ åˆ†ç»„å›æµ‹
  â””â”€ â†’ [è®­ç»ƒå¥½çš„æ¨¡å‹] (model.pkl)
        â†“
é˜¶æ®µ 3: ä¿¡å·ç”Ÿæˆ(å›æµ‹/å®ç›˜)
  â”œâ”€ MLEntry.generate_signals(stock_pool, date)
  â”‚   â”œâ”€ 1. è®¡ç®—å½“æ—¥ç‰¹å¾
  â”‚   â”œâ”€ 2. æ¨¡å‹é¢„æµ‹(expected_return + confidence)
  â”‚   â”œâ”€ 3. ä¿¡å·ç­›é€‰(ç½®ä¿¡åº¦è¿‡æ»¤ + Top N)
  â”‚   â”œâ”€ 4. æƒé‡è®¡ç®—(sharpe Ã— confidence)
  â”‚   â””â”€ 5. å½’ä¸€åŒ–æƒé‡
  â””â”€ â†’ [äº¤æ˜“ä¿¡å·] {'stock': {'action': 'long/short', 'weight': 0.xx}}
```

### ML ç»„ä»¶å¯¹æ¯”

| ç»„ä»¶ | MLStockRanker | MLEntry |
|------|--------------|---------|
| **ç±»å‹** | è¾…åŠ©å·¥å…· | ç­–ç•¥ç»„ä»¶ |
| **å®šä½** | è‚¡ç¥¨ç­›é€‰å™¨/é¢„æµ‹å™¨ | äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨ |
| **è¾“å…¥** | å¤§è‚¡ç¥¨æ±  (3000+) | å°è‚¡ç¥¨æ±  (50-100) |
| **è¾“å‡º** | è¯„åˆ† + æ’å | å¤šç©ºä¿¡å· + æƒé‡ |
| **ä½¿ç”¨æ—¶æœº** | å›æµ‹å‰(ä¸€æ¬¡æ€§) | å›æµ‹ä¸­(æ¯æ—¥) |
| **é¢‘ç‡** | ä½ | é«˜ |
| **å¯é€‰æ€§** | å®Œå…¨å¯é€‰ | ç­–ç•¥å¿…éœ€ |

---

## æ ¸å¿ƒç»„ä»¶

### 1. ç‰¹å¾å·¥ç¨‹å¼•æ“ (FeatureEngine)

**å®ç°çŠ¶æ€**: âœ… å·²å®ç° ([src/ml/feature_engine.py](../../src/ml/feature_engine.py))
**æµ‹è¯•çŠ¶æ€**: âœ… 100% è¦†ç›–ç‡ (19/19 æµ‹è¯•é€šè¿‡)
**ç¤ºä¾‹ä»£ç **: [examples/feature_engine_demo.py](../../examples/feature_engine_demo.py)

**èŒè´£**: è®¡ç®— 99+ ç‰¹å¾(Alpha å› å­ 58 + æŠ€æœ¯æŒ‡æ ‡ 37 + æˆäº¤é‡ç‰¹å¾ 4)

```python
class FeatureEngine:
    """
    ç‰¹å¾å·¥ç¨‹å¼•æ“
    """

    def __init__(
        self,
        feature_groups: List[str] = None,
        lookback_window: int = 60,
        cache_enabled: bool = True
    ):
        self.feature_groups = feature_groups or ['all']
        self.lookback_window = lookback_window
        self.cache = {} if cache_enabled else None

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        """
        è®¡ç®—ç‰¹å¾çŸ©é˜µ

        Returns:
            pd.DataFrame:
                index = stock_codes
                columns = feature_names (125+)
        """
        features = pd.DataFrame(index=stock_codes)

        # Alpha å› å­ (125+)
        if 'alpha' in self.feature_groups or 'all' in self.feature_groups:
            alpha_features = self._calculate_alpha_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, alpha_features], axis=1)

        # æŠ€æœ¯æŒ‡æ ‡ (60+)
        if 'technical' in self.feature_groups or 'all' in self.feature_groups:
            tech_features = self._calculate_technical_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, tech_features], axis=1)

        # æˆäº¤é‡ç‰¹å¾
        if 'volume' in self.feature_groups or 'all' in self.feature_groups:
            volume_features = self._calculate_volume_features(
                stock_codes, market_data, date
            )
            features = pd.concat([features, volume_features], axis=1)

        return features
```

**ç‰¹å¾ç±»åˆ«** (å®é™…å®ç°):

| ç±»åˆ« | æ•°é‡ | ç¤ºä¾‹ | å®ç°çŠ¶æ€ |
|------|------|------|---------|
| Alpha å› å­ | 58 | åŠ¨é‡ã€åè½¬ã€æ³¢åŠ¨ç‡ã€æˆäº¤é‡ | âœ… å·²å®ç° |
| æŠ€æœ¯æŒ‡æ ‡ | 37 | RSI, MACD, KDJ, å¸ƒæ—å¸¦ | âœ… å·²å®ç° |
| æˆäº¤é‡ç‰¹å¾ | 4 | æˆäº¤é‡æ¯”ç‡ (5d/10d/20d) | âœ… å·²å®ç° |
| **æ€»è®¡** | **99** | | âœ… å®Œå…¨å¯ç”¨ |

**æ€§èƒ½æŒ‡æ ‡** (å®æµ‹):
- 5è‚¡ç¥¨Ã—99ç‰¹å¾è®¡ç®—: < 0.2ç§’
- ç¼“å­˜åŠ é€Ÿ: 18000+x
- æ‰¹é‡è®¡ç®—æ”¯æŒ: âœ…

### 2. æ ‡ç­¾ç”Ÿæˆå™¨ (LabelGenerator)

**å®ç°çŠ¶æ€**: âœ… å·²å®ç° ([src/ml/label_generator.py](../../src/ml/label_generator.py))
**æµ‹è¯•çŠ¶æ€**: âœ… 100% è¦†ç›–ç‡ (24/24 æµ‹è¯•é€šè¿‡)

**èŒè´£**: ç”Ÿæˆè®­ç»ƒæ ‡ç­¾(æ”¯æŒ4ç§æ ‡ç­¾ç±»å‹)

```python
class LabelGenerator:
    """
    æ ‡ç­¾ç”Ÿæˆå™¨
    """

    def __init__(
        self,
        forward_window: int = 5,
        label_type: str = 'return'
    ):
        self.forward_window = forward_window
        self.label_type = label_type

    def generate_labels(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.Series:
        """
        ç”Ÿæˆæ ‡ç­¾

        Returns:
            pd.Series:
                index = stock_codes
                values = æœªæ¥æ”¶ç›Šç‡(æˆ–æ–¹å‘)
        """
        labels = {}

        for stock in stock_codes:
            stock_data = market_data[market_data['stock_code'] == stock]

            # æ‰¾åˆ°å½“å‰æ—¥æœŸçš„ä½ç½®
            current_idx = stock_data[stock_data['date'] == date].index
            if len(current_idx) == 0:
                continue

            # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
            current_price = stock_data.loc[current_idx[0], 'close']
            future_idx = current_idx[0] + self.forward_window

            if future_idx < len(stock_data):
                future_price = stock_data.iloc[future_idx]['close']

                if self.label_type == 'return':
                    labels[stock] = (future_price - current_price) / current_price
                elif self.label_type == 'direction':
                    labels[stock] = 1 if future_price > current_price else 0

        return pd.Series(labels)
```

**æ”¯æŒçš„æ ‡ç­¾ç±»å‹**:

| æ ‡ç­¾ç±»å‹ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ | å®ç°çŠ¶æ€ |
|---------|------|---------|---------|
| `return` | æœªæ¥æ”¶ç›Šç‡ | å›å½’ä»»åŠ¡ | âœ… |
| `direction` | æ¶¨è·Œæ–¹å‘ (0/1) | äºŒåˆ†ç±» | âœ… |
| `classification` | å¤šåˆ†ç±» (ä¸‹è·Œ/æ¨ªç›˜/ä¸Šæ¶¨) | ä¸‰åˆ†ç±» | âœ… |
| `regression` | æ ‡å‡†åŒ–æ”¶ç›Šç‡ | å›å½’ä»»åŠ¡ | âœ… |

**ç‰¹æ®ŠåŠŸèƒ½**:
- âœ… å¤šæ—¶é—´çª—å£æ ‡ç­¾ç”Ÿæˆ (`generate_multi_horizon_labels()`)
- âœ… çµæ´»çš„åˆ†ç±»é˜ˆå€¼é…ç½®
- âœ… å¥å£®çš„è¾¹ç¼˜æƒ…å†µå¤„ç†

### 3. è®­ç»ƒå¥½çš„æ¨¡å‹ (TrainedModel)

**å®ç°çŠ¶æ€**: âœ… å·²å®ç° ([src/ml/trained_model.py](../../src/ml/trained_model.py))
**æµ‹è¯•çŠ¶æ€**: âœ… 95% è¦†ç›–ç‡ (29/29 æµ‹è¯•é€šè¿‡)

**èŒè´£**: å°è£…æ¨¡å‹ + ç‰¹å¾å¼•æ“ï¼Œæä¾›ç»Ÿä¸€é¢„æµ‹æ¥å£

### 4. æ¨¡å‹è®­ç»ƒå™¨ (ModelTrainer)

**å®ç°çŠ¶æ€**: âœ… å·²è°ƒæ•´ ([src/models/model_trainer.py](../../src/models/model_trainer.py))
**é…ç½®ç±»**: `TrainingConfig` (æ¨¡å‹é…ç½®) + `ModelTrainerConfig` (è®­ç»ƒå™¨é…ç½®)

**èŒè´£**: è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä½¿ç”¨TrainingConfigé…ç½®

```python
@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    model_type: str = 'lightgbm'
    train_start_date: str = '2020-01-01'
    train_end_date: str = '2023-12-31'
    validation_split: float = 0.2
    forward_window: int = 5
    feature_groups: List[str] = None
    hyperparameters: Dict = None


class ModelTrainer:
    """
    æ¨¡å‹è®­ç»ƒå™¨
    """

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.feature_engine = FeatureEngine(
            feature_groups=config.feature_groups,
            lookback_window=60
        )
        self.label_generator = LabelGenerator(
            forward_window=config.forward_window,
            label_type='return'
        )

    def train(
        self,
        stock_pool: List[str],
        market_data: pd.DataFrame
    ) -> 'TrainedModel':
        """
        è®­ç»ƒæ¨¡å‹

        Returns:
            TrainedModel: è®­ç»ƒå¥½çš„æ¨¡å‹
        """
        # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
        X_train, y_train, X_val, y_val = self._prepare_training_data(
            stock_pool, market_data
        )

        # 2. è®­ç»ƒæ¨¡å‹
        model = self._train_model(X_train, y_train, X_val, y_val)

        # 3. è¯„ä¼°æ¨¡å‹
        metrics = self._evaluate_model(model, X_val, y_val)

        return TrainedModel(
            model=model,
            feature_engine=self.feature_engine,
            config=self.config,
            metrics=metrics
        )
```

### 5. ML å…¥åœºç­–ç•¥ (MLEntry)

**å®ç°çŠ¶æ€**: âœ… å·²å®ç° ([src/ml/ml_entry.py](../../src/ml/ml_entry.py))
**æµ‹è¯•çŠ¶æ€**: âœ… 96% è¦†ç›–ç‡ (21/21 æµ‹è¯•é€šè¿‡)
**ç¤ºä¾‹ä»£ç **: [examples/ml_entry_demo.py](../../examples/ml_entry_demo.py)

**èŒè´£**: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆäº¤æ˜“ä¿¡å·

**æ ¸å¿ƒåŠŸèƒ½**:
- âœ… åšå¤š/åšç©ºåŒå‘äº¤æ˜“ä¿¡å·
- âœ… åŸºäºç½®ä¿¡åº¦å’Œå¤æ™®æ¯”ç‡çš„æƒé‡è®¡ç®—
- âœ… Top N è‚¡ç¥¨ç­›é€‰
- âœ… è‡ªåŠ¨æƒé‡å½’ä¸€åŒ–

### 6. ML è‚¡ç¥¨è¯„åˆ†å·¥å…· (MLStockRanker)

**å®ç°çŠ¶æ€**: âœ… å·²å®ç° ([src/ml/ml_stock_ranker.py](../../src/ml/ml_stock_ranker.py))
**æµ‹è¯•çŠ¶æ€**: âœ… 95%+ è¦†ç›–ç‡ (30/30 æµ‹è¯•é€šè¿‡)
**ç¤ºä¾‹ä»£ç **: [examples/ml_stock_ranker_demo.py](../../examples/ml_stock_ranker_demo.py)

**èŒè´£**: ä»å¤§è‚¡ç¥¨æ± ä¸­ç­›é€‰é«˜æ½œåŠ›è‚¡ç¥¨

**æ ¸å¿ƒåŠŸèƒ½**:
- âœ… ä¸‰ç§è¯„åˆ†æ–¹æ³• (simple/sharpe/risk_adjusted)
- âœ… è‚¡ç¥¨è¿‡æ»¤å’Œæ’å
- âœ… æ‰¹é‡è¯„åˆ†æ”¯æŒ
- âœ… DataFrameæ ¼å¼è¾“å‡º

---

## å®Œæ•´å·¥ä½œæµç¨‹

### â­ åœºæ™¯ 1: è®­ç»ƒ ML æ¨¡å‹ (å®Œæ•´ç¤ºä¾‹)

**å‚è€ƒæ–‡ä»¶**: [examples/train_ml_model.py](../../examples/train_ml_model.py)

```python
from core.src.ml import FeatureEngine, LabelGenerator, TrainedModel, TrainingConfig
from core.src.models import ModelTrainer, ModelTrainerConfig
from core.src.data import DataManager

# Step 1: é…ç½®è®­ç»ƒå‚æ•°
model_config = TrainingConfig(
    model_type='lightgbm',
    train_start_date='2020-01-01',
    train_end_date='2023-12-31',
    validation_split=0.2,
    forward_window=5,
    feature_groups=['alpha', 'technical'],
    hyperparameters={
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.8
    }
)

trainer_config = ModelTrainerConfig(
    output_dir='models/',
    early_stopping=True
)

# Step 2: å‡†å¤‡æ•°æ®
data_manager = DataManager()
stock_pool = ['600000.SH', '000001.SZ']  # ... æ›´å¤šè‚¡ç¥¨
market_data = data_manager.load_data(
    stock_codes=stock_pool,
    start_date='2019-01-01',
    end_date='2023-12-31'
)

# Step 3: è®­ç»ƒæ¨¡å‹
trainer = ModelTrainer(model_config, trainer_config)
trained_model = trainer.train(stock_pool, market_data)

# Step 4: ä¿å­˜æ¨¡å‹
trained_model.save('models/ml_entry_model.pkl')

print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
print(f"éªŒè¯é›† IC: {trained_model.metrics['ic']:.4f}")
print(f"éªŒè¯é›† Rank IC: {trained_model.metrics['rank_ic']:.4f}")
```

### â­ åœºæ™¯ 2: ä½¿ç”¨ ML ç­–ç•¥å›æµ‹ (å®Œæ•´ç¤ºä¾‹)

**å‚è€ƒæ–‡ä»¶**: [examples/backtest_ml_strategy.py](../../examples/backtest_ml_strategy.py)

```python
class TrainedModel:
    """
    è®­ç»ƒå¥½çš„æ¨¡å‹(å¯ä¿å­˜å’ŒåŠ è½½)
    """

    def __init__(
        self,
        model,
        feature_engine: FeatureEngine,
        config: TrainingConfig,
        metrics: Dict
    ):
        self.model = model
        self.feature_engine = feature_engine
        self.config = config
        self.metrics = metrics

    def predict(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        """
        é¢„æµ‹

        Returns:
            pd.DataFrame:
                columns = ['expected_return', 'volatility', 'confidence']
                index = stock_codes
        """
        # 1. è®¡ç®—ç‰¹å¾
        features = self.feature_engine.calculate_features(
            stock_codes, market_data, date
        )

        # 2. æ•°æ®æ¸…æ´—
        features = features.fillna(0).replace([np.inf, -np.inf], 0)

        # 3. æ¨¡å‹é¢„æµ‹
        predictions = self.model.predict(features)

        # 4. æ„å»ºé¢„æµ‹ç»“æœ
        result = pd.DataFrame(index=features.index)
        result['expected_return'] = predictions
        result['volatility'] = self._estimate_volatility(
            stock_codes, market_data, date
        )
        result['confidence'] = self._estimate_confidence(features)

        return result

    def save(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        import joblib
        joblib.dump(self, path)

    @staticmethod
    def load(path: str) -> 'TrainedModel':
        """åŠ è½½æ¨¡å‹"""
        import joblib
        return joblib.load(path)
```

```python
from core.src.ml import MLEntry
from core.src.backtest import BacktestEngine
from core.src.data import DataManager

# Step 1: åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
ml_strategy = MLEntry(
    model_path='models/ml_entry_model.pkl',
    confidence_threshold=0.7,
    top_long=20,
    top_short=0,  # åªåšå¤š
    enable_short=False
)

# Step 2: å‡†å¤‡å›æµ‹æ•°æ®
data_manager = DataManager()
market_data = data_manager.load_data(
    stock_codes=stock_pool,
    start_date='2023-06-01',
    end_date='2024-01-31'
)

# Step 3: è¿è¡Œå›æµ‹ (ä½¿ç”¨æ–°çš„ backtest_ml_strategy æ–¹æ³•)
backtest_engine = BacktestEngine(
    initial_capital=1000000,
    commission_rate=0.0003,
    slippage_rate=0.0001
)

result = backtest_engine.backtest_ml_strategy(
    ml_strategy=ml_strategy,
    stock_pool=stock_pool,
    market_data=market_data,
    start_date='2023-07-01',
    end_date='2024-01-31',
    rebalance_frequency='W'  # æ¯å‘¨è°ƒä»“
)

# Step 4: åˆ†æç»“æœ
print(f"\nğŸ“ˆ å›æµ‹ç»“æœ:")
print(f"  æ€»æ”¶ç›Šç‡:     {result['total_return']:.2%}")
print(f"  å¹´åŒ–æ”¶ç›Šç‡:   {result['annual_return']:.2%}")
print(f"  å¤æ™®æ¯”ç‡:     {result['sharpe_ratio']:.2f}")
print(f"  æœ€å¤§å›æ’¤:     {result['max_drawdown']:.2%}")
print(f"  èƒœç‡:         {result['win_rate']:.2%}")
```

### â­ åœºæ™¯ 3: MLStockRanker è‚¡ç¥¨ç­›é€‰ (å®Œæ•´ç¤ºä¾‹)

**å‚è€ƒæ–‡ä»¶**: [examples/ml_stock_ranker_demo.py](../../examples/ml_stock_ranker_demo.py)

```python
from core.src.ml import MLStockRanker

# Step 1: åˆ›å»º MLStockRanker
ranker = MLStockRanker(
    model_path='models/ranker.pkl',
    scoring_method='sharpe',  # æˆ– 'simple', 'risk_adjusted'
    min_confidence=0.7,
    min_expected_return=0.01
)

# Step 2: è¯„åˆ†æ’å (è¿”å›å­—å…¸)
rankings = ranker.rank(
    stock_pool=all_a_stocks,  # å…¨ A è‚¡(3000+)
    market_data=market_data,
    date='2024-01-01',
    return_top_n=100,
    ascending=False
)

# æŸ¥çœ‹è¯„åˆ†ç»“æœ
print(f"âœ… Top 100 é«˜æ½œåŠ›è‚¡ç¥¨:")
for stock, score in list(rankings.items())[:10]:
    print(f"  {stock}: {score:.4f}")

# Step 3: è¯¦ç»†è¯„åˆ† (è¿”å›DataFrame)
result_df = ranker.rank_dataframe(
    stock_pool=stock_pool,
    market_data=market_data,
    date='2024-01-01',
    return_top_n=100
)

print(result_df.head())
# è¾“å‡º:
#             score  expected_return  confidence  volatility
# 600000.SH   1.250           0.0500       0.850       0.034
# 000001.SZ   1.180           0.0450       0.830       0.032

# Step 4: æ‰¹é‡è¯„åˆ† (å¤šæ—¥æœŸ)
batch_results = ranker.batch_rank(
    stock_pool=stock_pool,
    market_data=market_data,
    dates=['2024-01-01', '2024-01-02', '2024-01-03'],
    return_top_n=50
)

for date, rankings in batch_results.items():
    print(f"{date}: {len(rankings)} åªè‚¡ç¥¨")
```

---

## ä½¿ç”¨æŒ‡å—

### æ¨¡å‹è®­ç»ƒæœ€ä½³å®è·µ

#### 1. æ•°æ®å‡†å¤‡

```python
# ç¡®ä¿æ•°æ®å®Œæ•´æ€§
market_data = load_market_data(
    stock_codes=stock_pool,
    start_date='2019-01-01',  # ç•™å‡º lookback window
    end_date='2023-12-31'
)

# æ£€æŸ¥æ•°æ®è´¨é‡
assert market_data.isnull().sum().sum() == 0
assert len(market_data) > 0
```

#### 2. ç‰¹å¾é€‰æ‹©

```python
# å…¨ç‰¹å¾è®­ç»ƒ
config = TrainingConfig(
    feature_groups=['all'],  # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾
    ...
)

# æˆ–é€‰æ‹©ç‰¹å®šç‰¹å¾ç»„
config = TrainingConfig(
    feature_groups=['alpha', 'technical'],  # åªä½¿ç”¨ Alpha å’ŒæŠ€æœ¯æŒ‡æ ‡
    ...
)
```

#### 3. è¶…å‚æ•°è°ƒä¼˜

```python
# LightGBM æ¨èå‚æ•°
hyperparameters = {
    'objective': 'regression',
    'metric': 'l2',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5
}

config = TrainingConfig(
    model_type='lightgbm',
    hyperparameters=hyperparameters,
    ...
)
```

#### 4. æ¨¡å‹è¯„ä¼°

```python
# è¯„ä¼°æŒ‡æ ‡
metrics = trained_model.metrics

print(f"IC: {metrics['ic']:.4f}")           # ä¿¡æ¯ç³»æ•°
print(f"Rank IC: {metrics['rank_ic']:.4f}") # ç§©ç›¸å…³ç³»æ•°

# IC > 0.05 è¡¨ç¤ºæ¨¡å‹æœ‰æ•ˆ
# Rank IC > 0.1 è¡¨ç¤ºæ¨¡å‹ä¼˜ç§€
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. ç‰¹å¾ç¼“å­˜

```python
class CachedFeatureEngine(FeatureEngine):
    """å¸¦ç¼“å­˜çš„ç‰¹å¾å¼•æ“"""

    def __init__(self, cache_dir: str = './cache/features', **kwargs):
        super().__init__(**kwargs)
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{date}_{hash(tuple(sorted(stock_codes)))}"
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.parquet")

        if os.path.exists(cache_path):
            return pd.read_parquet(cache_path)

        # è®¡ç®—ç‰¹å¾
        features = super().calculate_features(stock_codes, market_data, date)

        # ä¿å­˜ç¼“å­˜
        features.to_parquet(cache_path)
        return features
```

### 2. å¹¶è¡Œè®¡ç®—

```python
from joblib import Parallel, delayed

class ParallelFeatureEngine(FeatureEngine):
    """å¹¶è¡Œç‰¹å¾å¼•æ“"""

    def __init__(self, n_jobs: int = 4, **kwargs):
        super().__init__(**kwargs)
        self.n_jobs = n_jobs

    def calculate_features(
        self,
        stock_codes: List[str],
        market_data: pd.DataFrame,
        date: str
    ) -> pd.DataFrame:
        # å°†è‚¡ç¥¨æ± åˆ†æ‰¹
        batch_size = len(stock_codes) // self.n_jobs
        batches = [
            stock_codes[i:i+batch_size]
            for i in range(0, len(stock_codes), batch_size)
        ]

        # å¹¶è¡Œè®¡ç®—
        results = Parallel(n_jobs=self.n_jobs)(
            delayed(super().calculate_features)(batch, market_data, date)
            for batch in batches
        )

        # åˆå¹¶ç»“æœ
        return pd.concat(results, axis=0)
```

### 3. æ¨¡å‹æ¨ç†ä¼˜åŒ–

```python
# æ‰¹é‡é¢„æµ‹
predictions = model.predict(features, num_iteration=model.best_iteration)

# ä½¿ç”¨ GPU åŠ é€Ÿ (XGBoost)
params = {
    'tree_method': 'gpu_hist',
    'gpu_id': 0
}
```

---

## æ¨¡å‹ç»´æŠ¤

### æ¨¡å‹é‡è®­ç»ƒç­–ç•¥

```python
class ModelUpdateScheduler:
    """æ¨¡å‹æ›´æ–°è°ƒåº¦å™¨"""

    def __init__(
        self,
        retrain_frequency: str = 'quarterly',
        performance_threshold: float = 0.10
    ):
        self.retrain_frequency = retrain_frequency
        self.performance_threshold = performance_threshold

    def should_retrain(
        self,
        current_model: TrainedModel,
        recent_performance: Dict
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è®­ç»ƒ"""
        # ç­–ç•¥ 1: æŒ‰æ—¶é—´å‘¨æœŸ
        if self._is_time_to_retrain():
            return True

        # ç­–ç•¥ 2: æ€§èƒ½ä¸‹é™
        baseline_ic = current_model.metrics['ic']
        recent_ic = recent_performance['ic']

        if (baseline_ic - recent_ic) / baseline_ic > self.performance_threshold:
            return True

        return False
```

### åœ¨çº¿æ€§èƒ½ç›‘æ§

```python
class ModelMonitor:
    """æ¨¡å‹æ€§èƒ½ç›‘æ§"""

    def __init__(self, model: TrainedModel):
        self.model = model
        self.performance_history = []

    def evaluate_recent_performance(
        self,
        stock_pool: List[str],
        market_data: pd.DataFrame,
        start_date: str,
        end_date: str
    ) -> Dict:
        """è¯„ä¼°è¿‘æœŸæ¨¡å‹æ€§èƒ½"""
        dates = pd.date_range(start_date, end_date, freq='B')

        all_predictions = []
        all_actuals = []

        for date in dates:
            # é¢„æµ‹
            predictions = self.model.predict(stock_pool, market_data, date)

            # å®é™…æ”¶ç›Š
            actuals = self._get_actual_returns(
                stock_pool, market_data, date, forward_window=5
            )

            all_predictions.extend(predictions['expected_return'].values)
            all_actuals.extend(actuals.values)

        # è®¡ç®— IC
        ic = np.corrcoef(all_actuals, all_predictions)[0, 1]

        return {'ic': ic, 'period': f'{start_date} to {end_date}'}
```

---

## å®ç°çŠ¶æ€

### Phase 1: æ ¸å¿ƒMLæ¨¡å— (âœ… 100% å®Œæˆ)

| æ¨¡å— | æ–‡ä»¶ | æµ‹è¯•è¦†ç›–ç‡ | çŠ¶æ€ |
|------|------|-----------|------|
| FeatureEngine | [src/ml/feature_engine.py](../../src/ml/feature_engine.py) | 100% | âœ… |
| LabelGenerator | [src/ml/label_generator.py](../../src/ml/label_generator.py) | 100% | âœ… |
| TrainedModel | [src/ml/trained_model.py](../../src/ml/trained_model.py) | 95% | âœ… |
| MLEntry | [src/ml/ml_entry.py](../../src/ml/ml_entry.py) | 96% | âœ… |
| MLStockRanker | [src/ml/ml_stock_ranker.py](../../src/ml/ml_stock_ranker.py) | 95% | âœ… |

**å•å…ƒæµ‹è¯•**: 123/123 é€šè¿‡
**é›†æˆæµ‹è¯•**: 11/11 é€šè¿‡
**æ€»è¦†ç›–ç‡**: 93%

### Phase 2: å›æµ‹é›†æˆ (âœ… 100% å®Œæˆ)

| åŠŸèƒ½ | å®ç°çŠ¶æ€ | æµ‹è¯•çŠ¶æ€ |
|------|---------|---------|
| ModelTrainerä½¿ç”¨TrainingConfig | âœ… å®Œæˆ | 49/49 é€šè¿‡ |
| æ¨¡å‹è¯„ä¼°å¢å¼º (IC/Rank IC) | âœ… å®Œæˆ | 37/37 é€šè¿‡ |
| BacktestEngineæ”¯æŒMLEntry | âœ… å®Œæˆ | 7/7 é€šè¿‡ |
| ç¤ºä¾‹ä»£ç  | âœ… å®Œæˆ | 3ä¸ªå®Œæ•´ç¤ºä¾‹ |

### Phase 3: æµ‹è¯•ä¸æ–‡æ¡£ (âœ… 67% å®Œæˆ)

| ä»»åŠ¡ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| ç«¯åˆ°ç«¯æµ‹è¯• | âœ… å®Œæˆ | 11/11 é€šè¿‡ |
| æ–‡æ¡£æ›´æ–° | â³ è¿›è¡Œä¸­ | Day 18-19 |
| Code Review | â³ å¾…å¼€å§‹ | Day 20 |

### ç¤ºä¾‹ä»£ç 

æ‰€æœ‰ç¤ºä¾‹ä»£ç ä½äº [examples/](../../examples/) ç›®å½•:

| ç¤ºä¾‹ | æ–‡ä»¶ | è¯´æ˜ |
|------|------|------|
| ç‰¹å¾å¼•æ“ç¤ºä¾‹ | [feature_engine_demo.py](../../examples/feature_engine_demo.py) | 5ä¸ªåœºæ™¯ |
| MLå…¥åœºç­–ç•¥ç¤ºä¾‹ | [ml_entry_demo.py](../../examples/ml_entry_demo.py) | 4ä¸ªåœºæ™¯ |
| è‚¡ç¥¨è¯„åˆ†ç¤ºä¾‹ | [ml_stock_ranker_demo.py](../../examples/ml_stock_ranker_demo.py) | 6ä¸ªåœºæ™¯ |
| MLç­–ç•¥å›æµ‹ | [backtest_ml_strategy.py](../../examples/backtest_ml_strategy.py) | 3ä¸ªåœºæ™¯ |
| å¢å¼ºè¯„ä¼° | [enhanced_model_evaluation_demo.py](../../examples/enhanced_model_evaluation_demo.py) | 7ä¸ªåœºæ™¯ |

### æµ‹è¯•æŠ¥å‘Š

è¯¦ç»†æµ‹è¯•æŠ¥å‘Š:
- [Phase 1 å®ŒæˆæŠ¥å‘Š](../planning/phase1_completion_report.md)
- [Phase 3 æµ‹è¯•æŠ¥å‘Š](../../tests/integration/PHASE3_TEST_REPORT.md)

---

## ç›¸å…³æ–‡æ¡£

**ğŸ“– æ ¸å¿ƒæ–‡æ¡£**:
- [MLStockRanker å®Œæ•´æŒ‡å—](./mlstockranker.md) - â­ è‚¡ç¥¨è¯„åˆ†å·¥å…·è¯¦è§£
- [è¯„ä¼°æŒ‡æ ‡è¯¦è§£](./evaluation-metrics.md) - â­ IC/å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡è¯´æ˜
- [ä½¿ç”¨æŒ‡å—](./user-guide.md) - â­ å¿«é€Ÿå…¥é—¨å’Œæœ€ä½³å®è·µ

**ğŸ”§ æŠ€æœ¯æ–‡æ¡£**:
- [æ¶æ„è¯¦è§£](../architecture/overview.md)
- [MLç³»ç»Ÿé‡æ„æ–¹æ¡ˆ](../planning/ml_system_refactoring_plan.md)
- [ç‰¹å¾å·¥ç¨‹](../features/README.md)

**ğŸ’» ç¤ºä¾‹ä»£ç **:
- [examples/](../../examples/) - æ‰€æœ‰ç¤ºä¾‹ä»£ç 
- [tests/integration/](../../tests/integration/) - é›†æˆæµ‹è¯•

---

## å¿«é€Ÿé“¾æ¥

**å¼€å§‹ä½¿ç”¨**:
1. æŸ¥çœ‹ [ä½¿ç”¨æŒ‡å—](./user-guide.md)
2. è¿è¡Œ `python examples/backtest_ml_strategy.py`
3. é˜…è¯» [MLStockRanker å®Œæ•´æŒ‡å—](./mlstockranker.md)

**æ·±å…¥å­¦ä¹ **:
1. é˜…è¯» [è¯„ä¼°æŒ‡æ ‡è¯¦è§£](./evaluation-metrics.md)
2. æŸ¥çœ‹ [MLç³»ç»Ÿé‡æ„æ–¹æ¡ˆ](../planning/ml_system_refactoring_plan.md)
3. ç ”ç©¶ [examples/](../../examples/) ä¸­çš„ç¤ºä¾‹ä»£ç 

---

**æ–‡æ¡£ç‰ˆæœ¬**: v6.0.0
**æœ€åæ›´æ–°**: 2026-02-08
**å®ç°çŠ¶æ€**: âœ… Phase 1-2 å®Œæˆ (100%), Phase 3 è¿›è¡Œä¸­ (67%)
