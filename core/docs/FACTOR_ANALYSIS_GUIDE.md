# å› å­åˆ†æå’Œå‚æ•°ä¼˜åŒ–å®Œæ•´æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»coreé‡åŒ–ç³»ç»Ÿæ–°å¢çš„ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼š

### ç¬¬ä¸€éƒ¨åˆ†ï¼šå› å­æœ‰æ•ˆæ€§åˆ†æå·¥å…·
- ICåˆ†æï¼ˆä¿¡æ¯ç³»æ•°ï¼‰
- åˆ†å±‚å›æµ‹ï¼ˆæŒ‰å› å­å€¼åˆ†ç»„æµ‹è¯•ï¼‰
- å› å­ç›¸å…³æ€§åˆ†æå’Œçƒ­åŠ›å›¾
- å› å­ç»„åˆä¼˜åŒ–

### ç¬¬äºŒéƒ¨åˆ†ï¼šå‚æ•°ä¼˜åŒ–æ¨¡å—
- ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨
- è´å¶æ–¯ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨scikit-optimizeï¼‰
- Walk-ForwardéªŒè¯æ¡†æ¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
cd core
source ../stock_env/bin/activate  # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
pip install scipy  # å› å­åˆ†æéœ€è¦
pip install seaborn networkx  # ç›¸å…³æ€§å¯è§†åŒ–éœ€è¦
pip install scikit-optimize  # è´å¶æ–¯ä¼˜åŒ–éœ€è¦ï¼ˆå¯é€‰ï¼‰
```

### è¿è¡Œç¤ºä¾‹

```bash
python examples/complete_factor_analysis_example.py
```

---

## ğŸ“Š ç¬¬ä¸€éƒ¨åˆ†ï¼šå› å­æœ‰æ•ˆæ€§åˆ†æ

### 1. ICåˆ†æï¼ˆInformation Coefficientï¼‰

**ç”¨é€”**ï¼šè¯„ä¼°å› å­çš„é¢„æµ‹èƒ½åŠ›

**ç¤ºä¾‹**ï¼š

```python
from analysis import ICCalculator

# åˆ›å»ºICè®¡ç®—å™¨
ic_calc = ICCalculator(
    forward_periods=5,  # å‰ç»æœŸ5å¤©
    method='spearman'   # ä½¿ç”¨ç§©ç›¸å…³ï¼ˆæ›´ç¨³å¥ï¼‰
)

# è®¡ç®—ICç»Ÿè®¡
ic_result = ic_calc.calculate_ic_stats(factor_df, prices_df)

print(f"ICå‡å€¼: {ic_result.mean_ic:.4f}")
print(f"ICIR: {ic_result.ic_ir:.4f}")
print(f"ICæ­£å€¼ç‡: {ic_result.positive_rate:.2%}")

# ç»˜åˆ¶ICæ—¶é—´åºåˆ—
ic_calc.plot_ic_series(ic_result, title="å› å­ICåˆ†æ")
```

**åˆ¤æ–­æ ‡å‡†**ï¼š
- |IC| > 0.03ï¼šæœ‰æ•ˆå› å­
- ICIR > 0.5ï¼šç¨³å®šçš„æœ‰æ•ˆå› å­
- ICæ­£å€¼ç‡ > 55%ï¼šæœ‰æ–¹å‘æ€§

**é«˜çº§åŠŸèƒ½**ï¼š

```python
# æ‰¹é‡è®¡ç®—å¤šä¸ªå› å­çš„IC
ic_summary = ic_calc.calculate_multi_factor_ic(factor_dict, prices_df)

# ICè¡°å‡åˆ†æï¼ˆä¸åŒæŒæœ‰æœŸï¼‰
decay_df = ic_calc.analyze_ic_decay(factor_df, prices_df, max_period=20)

# æ»šåŠ¨ICï¼ˆè¯„ä¼°å› å­ç¨³å®šæ€§ï¼‰
rolling_ic = ic_calc.calculate_rolling_ic(factor_df, prices_df, window=60)
```

---

### 2. åˆ†å±‚å›æµ‹

**ç”¨é€”**ï¼šæµ‹è¯•å› å­çš„å•è°ƒæ€§ï¼ˆæ˜¯å¦åˆ†å±‚è¶Šé«˜æ”¶ç›Šè¶Šé«˜ï¼‰

**ç¤ºä¾‹**ï¼š

```python
from analysis import LayeringTest

# åˆ›å»ºåˆ†å±‚æµ‹è¯•å·¥å…·
layering_test = LayeringTest(
    n_layers=5,         # åˆ†ä¸º5å±‚
    holding_period=5,    # æŒæœ‰æœŸ5å¤©
    long_short=True      # è®¡ç®—å¤šç©ºç»„åˆæ”¶ç›Š
)

# æ‰§è¡Œåˆ†å±‚æµ‹è¯•
result_df = layering_test.perform_layering_test(factor_df, prices_df)

print(result_df)

# åˆ†æå•è°ƒæ€§
monotonicity = layering_test.analyze_monotonicity(result_df)
print(f"æ˜¯å¦å•è°ƒ: {monotonicity['æ˜¯å¦å•è°ƒ']}")
print(f"æ”¶ç›Šå·®è·: {monotonicity['æ”¶ç›Šå·®è·']:.4f}")

# ç»˜åˆ¶åˆ†å±‚ç»“æœ
layering_test.plot_layering_result(result_df)
```

**é«˜çº§åŠŸèƒ½**ï¼š

```python
# å®Œæ•´å‡€å€¼å›æµ‹
equity_curves = layering_test.backtest_layers(
    factor_df,
    prices_df,
    initial_capital=1_000_000
)

# æŸ¥çœ‹å„å±‚å‡€å€¼æ›²çº¿
for layer_name, curve in equity_curves.items():
    print(f"{layer_name}: {curve.iloc[-1]:,.2f}")
```

---

### 3. å› å­ç›¸å…³æ€§åˆ†æ

**ç”¨é€”**ï¼šè¯†åˆ«é«˜åº¦ç›¸å…³çš„å› å­ï¼Œé¿å…é‡å¤

**ç¤ºä¾‹**ï¼š

```python
from analysis import FactorCorrelation

# åˆ›å»ºç›¸å…³æ€§åˆ†æå·¥å…·
corr_analyzer = FactorCorrelation(method='spearman')

# è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
corr_matrix = corr_analyzer.calculate_factor_correlation(
    factor_dict,
    aggregate_method='concat'  # æˆ–'mean'
)

# æ‰¾å‡ºé«˜ç›¸å…³æ€§å› å­å¯¹
high_corr_pairs = corr_analyzer.find_high_correlation_pairs(
    corr_matrix,
    threshold=0.7
)

# é€‰æ‹©ä½ç›¸å…³æ€§å› å­
selected_factors = corr_analyzer.select_low_correlation_factors(
    corr_matrix,
    max_corr=0.7,
    ic_scores=ic_scores  # åŸºäºICä¼˜å…ˆé€‰æ‹©
)

# ç»˜åˆ¶çƒ­åŠ›å›¾
corr_analyzer.plot_correlation_heatmap(corr_matrix)

# ç»˜åˆ¶ç½‘ç»œå›¾
corr_analyzer.plot_correlation_network(corr_matrix, threshold=0.5)
```

**é«˜çº§åŠŸèƒ½**ï¼š

```python
# å› å­èšç±»
clusters = corr_analyzer.cluster_factors(corr_matrix, n_clusters=5)

for cluster_id, factors in clusters.items():
    print(f"ç°‡{cluster_id}: {factors}")
```

---

### 4. å› å­ç»„åˆä¼˜åŒ–

**ç”¨é€”**ï¼šä¼˜åŒ–å¤šå› å­çš„æƒé‡ç»„åˆ

**ç¤ºä¾‹**ï¼š

```python
from analysis import FactorOptimizer

optimizer = FactorOptimizer()

# æ–¹æ³•1ï¼šç­‰æƒé‡
equal_w = optimizer.equal_weight(factor_names)

# æ–¹æ³•2ï¼šICåŠ æƒ
ic_w = optimizer.ic_weight(ic_stats)

# æ–¹æ³•3ï¼šICIRåŠ æƒï¼ˆæ¨èï¼‰
icir_w = optimizer.ic_ir_weight(ic_stats)

# æ–¹æ³•4ï¼šä¼˜åŒ–æœ€å¤§åŒ–ICIR
opt_result = optimizer.optimize_max_icir(
    ic_series_dict,
    method='SLSQP',
    max_weight=0.5  # å•å› å­æœ€å¤§æƒé‡é™åˆ¶
)

print(f"æœ€ä¼˜æƒé‡:\n{opt_result.weights}")
print(f"ç»„åˆICIR: {opt_result.ic_ir:.4f}")

# ç»„åˆå› å­
combined_factor = optimizer.combine_factors(
    factor_dict,
    opt_result.weights,
    normalize=True
)
```

**é«˜çº§åŠŸèƒ½**ï¼š

```python
# æœ€å°ç›¸å…³æ€§ä¼˜åŒ–
opt_result = optimizer.optimize_min_correlation(
    ic_series_dict,
    corr_matrix,
    max_avg_corr=0.3  # æœ€å¤§å¹³å‡ç›¸å…³æ€§
)
```

---

## âš™ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šå‚æ•°ä¼˜åŒ–

### 1. ç½‘æ ¼æœç´¢

**ç”¨é€”**ï¼šéå†æ‰€æœ‰å‚æ•°ç»„åˆï¼ˆé€‚åˆå‚æ•°ç©ºé—´å°çš„æƒ…å†µï¼‰

**ç¤ºä¾‹**ï¼š

```python
from optimization import GridSearchOptimizer

# åˆ›å»ºä¼˜åŒ–å™¨
grid_optimizer = GridSearchOptimizer(
    metric='sharpe_ratio',
    n_jobs=4,  # å¹¶è¡Œä»»åŠ¡æ•°
    verbose=True
)

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'lookback': [10, 20, 30, 40],
    'top_n': [30, 50, 70, 100]
}

# å®šä¹‰ç›®æ ‡å‡½æ•°
def backtest_strategy(params):
    strategy = MomentumStrategy('MOM', params)
    result = strategy.backtest(engine, prices_df)
    return result['sharpe_ratio']

# æ‰§è¡Œæœç´¢
result = grid_optimizer.search(backtest_strategy, param_grid)

print(f"æœ€ä¼˜å‚æ•°: {result.best_params}")
print(f"æœ€ä¼˜å¾—åˆ†: {result.best_score:.4f}")

# å‚æ•°é‡è¦æ€§åˆ†æ
importance = grid_optimizer.analyze_param_importance(result)
print(importance)

# ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§
grid_optimizer.plot_param_sensitivity(result, 'lookback')
```

---

### 2. è´å¶æ–¯ä¼˜åŒ–

**ç”¨é€”**ï¼šæ™ºèƒ½æœç´¢å‚æ•°ç©ºé—´ï¼ˆé€‚åˆè®¡ç®—æ˜‚è´µçš„ç›®æ ‡å‡½æ•°ï¼‰

**ç¤ºä¾‹**ï¼š

```python
from optimization import BayesianOptimizer

# åˆ›å»ºä¼˜åŒ–å™¨
bayesian_optimizer = BayesianOptimizer(
    n_calls=50,           # æ€»è¿­ä»£æ¬¡æ•°
    n_initial_points=10,   # éšæœºåˆå§‹åŒ–ç‚¹æ•°
    acq_func='EI'          # é‡‡é›†å‡½æ•°ï¼ˆæœŸæœ›æ”¹è¿›ï¼‰
)

# å®šä¹‰å‚æ•°ç©ºé—´
param_space = {
    'lookback': (5, 50),      # æ•´æ•°èŒƒå›´
    'threshold': (0.0, 1.0),  # æµ®ç‚¹æ•°èŒƒå›´
    'method': ['pearson', 'spearman']  # ç±»åˆ«é€‰æ‹©
}

# æ‰§è¡Œä¼˜åŒ–
result = bayesian_optimizer.optimize(
    backtest_strategy,
    param_space,
    maximize=True
)

print(f"æœ€ä¼˜å‚æ•°: {result.best_params}")
print(f"è¿­ä»£æ¬¡æ•°: {result.n_iterations}")

# ç»˜åˆ¶æ”¶æ•›æ›²çº¿
bayesian_optimizer.plot_convergence(result)
```

**ä¼˜åŠ¿**ï¼š
- æ¯”ç½‘æ ¼æœç´¢å¿«5-10å€
- è‡ªåŠ¨èšç„¦åˆ°æœ€ä¼˜åŒºåŸŸ
- é€‚åˆæ˜‚è´µçš„å›æµ‹å‡½æ•°

---

### 3. Walk-ForwardéªŒè¯

**ç”¨é€”**ï¼šé˜²æ­¢å‚æ•°è¿‡æ‹Ÿåˆçš„æ»šåŠ¨éªŒè¯

**ç¤ºä¾‹**ï¼š

```python
from optimization import WalkForwardValidator

# åˆ›å»ºéªŒè¯å™¨
validator = WalkForwardValidator(
    train_period=252,  # è®­ç»ƒæœŸ1å¹´
    test_period=63,    # æµ‹è¯•æœŸ1å­£åº¦
    step_size=63       # æ»šåŠ¨æ­¥é•¿
)

# å‡†å¤‡æ•°æ®
data = {
    'prices': prices_df,
    'features': features_df
}

# æ‰§è¡ŒéªŒè¯
results_df = validator.validate(
    objective_func=backtest_strategy,
    optimizer=grid_optimizer,  # æˆ– bayesian_optimizer
    data=data,
    dates=prices_df.index.tolist()
)

# æŸ¥çœ‹ç»“æœ
print(results_df[['çª—å£', 'è®­ç»ƒå¾—åˆ†', 'æµ‹è¯•å¾—åˆ†', 'è¿‡æ‹Ÿåˆåº¦']])

# ç»˜åˆ¶éªŒè¯ç»“æœ
validator.plot_validation_results(results_df)
```

**éªŒè¯æŒ‡æ ‡**ï¼š
- å¹³å‡è¿‡æ‹Ÿåˆåº¦ < 0.1ï¼šå‚æ•°ç¨³å®š
- æµ‹è¯•å¾—åˆ†æ ‡å‡†å·®ï¼šå‚æ•°é²æ£’æ€§
- è¿‡æ‹Ÿåˆçª—å£æ•°ï¼šå‚æ•°å¯é æ€§

---

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

### å¤šå› å­ç­–ç•¥å¼€å‘æµç¨‹

```python
from analysis import *
from optimization import *

# æ­¥éª¤1ï¼šè®¡ç®—å› å­
from features.alpha_factors import AlphaFactors

af = AlphaFactors(price_df)
af.add_all_alpha_factors()
factor_df = af.get_dataframe()

# æ­¥éª¤2ï¼šICåˆ†æç­›é€‰å› å­
ic_calc = ICCalculator(forward_periods=5, method='spearman')
ic_summary = ic_calc.calculate_multi_factor_ic(factor_dict, prices_df)

# é€‰å‡ºICIR > 0.3çš„å› å­
good_factors = ic_summary[ic_summary['ICIR'] > 0.3].index.tolist()

# æ­¥éª¤3ï¼šç›¸å…³æ€§åˆ†æå»é‡
corr_analyzer = FactorCorrelation()
corr_matrix = corr_analyzer.calculate_factor_correlation(good_factor_dict)

selected_factors = corr_analyzer.select_low_correlation_factors(
    corr_matrix,
    max_corr=0.7,
    ic_scores=ic_summary['ICå‡å€¼'].abs()
)

# æ­¥éª¤4ï¼šä¼˜åŒ–å› å­æƒé‡
optimizer = FactorOptimizer()
opt_result = optimizer.optimize_max_icir(selected_ic_series_dict)

combined_factor = optimizer.combine_factors(
    selected_factor_dict,
    opt_result.weights
)

# æ­¥éª¤5ï¼šç­–ç•¥å‚æ•°ä¼˜åŒ–
from strategies import MultiFactorStrategy

def backtest_multi_factor(params):
    strategy = MultiFactorStrategy('MF', params)
    result = strategy.backtest(engine, prices_df, features=combined_factor)
    return result['sharpe_ratio']

# ç½‘æ ¼æœç´¢
grid_optimizer = GridSearchOptimizer()
param_grid = {'top_n': [30, 50, 70], 'holding_period': [5, 10, 20]}

grid_result = grid_optimizer.search(backtest_multi_factor, param_grid)

# æ­¥éª¤6ï¼šWalk-ForwardéªŒè¯
validator = WalkForwardValidator(train_period=252, test_period=63)

wf_results = validator.validate(
    objective_func=backtest_multi_factor,
    optimizer=grid_optimizer,
    data={'prices': prices_df, 'features': combined_factor},
    dates=dates
)

# æ­¥éª¤7ï¼šæŸ¥çœ‹æœ€ç»ˆç»“æœ
print("\næœ€ç»ˆå¤šå› å­ç­–ç•¥ï¼š")
print(f"å› å­ç»„åˆ: {selected_factors}")
print(f"å› å­æƒé‡: {opt_result.weights}")
print(f"ç­–ç•¥å‚æ•°: {grid_result.best_params}")
print(f"å¹³å‡æµ‹è¯•å¾—åˆ†: {wf_results['æµ‹è¯•å¾—åˆ†'].mean():.4f}")
print(f"å‚æ•°ç¨³å®šæ€§: {wf_results['è¿‡æ‹Ÿåˆåº¦'].std():.4f}")
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å› å­åˆ†æåŠ é€Ÿ

1. **å¹¶è¡Œè®¡ç®—å¤šå› å­IC**
```python
# ä½¿ç”¨Taskå·¥å…·å¹¶è¡Œè®¡ç®—
from joblib import Parallel, delayed

ic_results = Parallel(n_jobs=-1)(
    delayed(ic_calc.calculate_ic_stats)(factor_df, prices_df)
    for factor_df in factor_dict.values()
)
```

2. **ç¼“å­˜ICåºåˆ—**
```python
# é¿å…é‡å¤è®¡ç®—IC
ic_cache = {}
for name, factor_df in factor_dict.items():
    if name not in ic_cache:
        ic_cache[name] = ic_calc.calculate_ic_series(factor_df, prices_df)
```

### å‚æ•°ä¼˜åŒ–åŠ é€Ÿ

1. **ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ä»£æ›¿ç½‘æ ¼æœç´¢**
```python
# 50æ¬¡è´å¶æ–¯ä¼˜åŒ– vs 1000æ¬¡ç½‘æ ¼æœç´¢
bayesian_optimizer = BayesianOptimizer(n_calls=50)
```

2. **å¹¶è¡Œç½‘æ ¼æœç´¢**
```python
grid_optimizer = GridSearchOptimizer(n_jobs=-1)  # ä½¿ç”¨æ‰€æœ‰CPU
```

3. **å‡å°‘Walk-Forwardçª—å£æ•°**
```python
validator = WalkForwardValidator(
    train_period=120,
    test_period=30,
    step_size=60  # å¢å¤§æ­¥é•¿ï¼Œå‡å°‘çª—å£æ•°
)
```

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. ICå€¼å¾ˆå°æ€ä¹ˆåŠï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
- å› å­ç¡®å®æ— æ•ˆ
- å‰ç»æœŸè®¾ç½®ä¸å½“
- æ•°æ®è´¨é‡é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å°è¯•ä¸åŒå‰ç»æœŸ
for period in [1, 3, 5, 10, 20]:
    ic_calc = ICCalculator(forward_periods=period)
    ic_result = ic_calc.calculate_ic_stats(factor_df, prices_df)
    print(f"å‰ç»æœŸ{period}å¤©: IC={ic_result.mean_ic:.4f}")
```

### 2. åˆ†å±‚æµ‹è¯•ä¸å•è°ƒï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
- å› å­å™ªå£°å¤§
- åˆ†å±‚æ•°å¤ªå¤š
- æŒæœ‰æœŸä¸åˆé€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å‡å°‘åˆ†å±‚æ•°ï¼Œå¢åŠ æ¯å±‚è‚¡ç¥¨æ•°
layering_test = LayeringTest(n_layers=3, holding_period=10)
```

### 3. Walk-ForwardéªŒè¯å¤±è´¥ï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
- è®­ç»ƒé›†å¤ªå°
- å‚æ•°è¿‡æ‹Ÿåˆ
- æ•°æ®ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
validator = WalkForwardValidator(
    min_train_size=60,  # é™ä½æœ€å°è®­ç»ƒé›†è¦æ±‚
    train_period=180    # å¢å¤§è®­ç»ƒçª—å£
)
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **ICåˆ†æ**
   - Grinold & Kahn, "Active Portfolio Management"

2. **å› å­ç»„åˆ**
   - Meucci, "Risk and Asset Allocation"

3. **å‚æ•°ä¼˜åŒ–**
   - Bergstra et al., "Algorithms for Hyper-Parameter Optimization"

4. **Walk-ForwardéªŒè¯**
   - Pardo, "The Evaluation and Optimization of Trading Strategies"

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å› å­å¼€å‘**ï¼š
   - å…ˆç”¨ICå¿«é€Ÿç­›é€‰
   - å†ç”¨åˆ†å±‚æµ‹è¯•éªŒè¯
   - æœ€åç»„åˆä¼˜åŒ–

2. **å‚æ•°ä¼˜åŒ–**ï¼š
   - ç²—æœç´¢ç”¨ç½‘æ ¼
   - ç²¾æœç´¢ç”¨è´å¶æ–¯
   - éªŒè¯ç”¨Walk-Forward

3. **é¿å…è¿‡æ‹Ÿåˆ**ï¼š
   - é™åˆ¶å‚æ•°æ•°é‡ < 5ä¸ª
   - Walk-Forwardçª—å£ >= 10ä¸ª
   - è¿‡æ‹Ÿåˆåº¦ < 10%

---

**å®Œæˆæ—¥æœŸ**ï¼š2026-01-29
**ä½œè€…**ï¼šClaude (Anthropic)
**ç‰ˆæœ¬**ï¼šv1.0
