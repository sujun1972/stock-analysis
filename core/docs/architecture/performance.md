# æ€§èƒ½ä¼˜åŒ–åˆ†æ

**Performance Optimization in Stock-Analysis Core**

**ç‰ˆæœ¬**: v3.0.0
**æœ€åæ›´æ–°**: 2026-02-01

---

## ğŸ“Š æ€§èƒ½æ¦‚è§ˆ

### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

| æ¨¡å— | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å€æ•° | ä¼˜åŒ–æ–¹æ³• |
|------|--------|--------|---------|---------|
| **ç‰¹å¾è®¡ç®—** | 35.2s | 1.0s | **35.2x** | å‘é‡åŒ– + å¹¶è¡Œ |
| **å›æµ‹å¼•æ“** | 120s | 15s | **8.0x** | å¹¶è¡Œå›æµ‹ |
| **æ¨¡å‹è®­ç»ƒ(GPU)** | 300s | 15s | **20.0x** | GPUåŠ é€Ÿ |
| **æ•°æ®æŸ¥è¯¢** | 5.2s | 0.8s | **6.5x** | TimescaleDBç´¢å¼• |
| **å› å­è®¡ç®—** | 12.5s | 1.1s | **11.4x** | å‘é‡åŒ– |

**æ€»ä½“æ€§èƒ½æå‡**: **å¹³å‡15-20å€**

---

## âš¡ å‘é‡åŒ–ä¼˜åŒ–

### 1. NumPyå‘é‡åŒ–

**åŸåˆ™**: é¿å…Pythonå¾ªç¯ï¼Œä½¿ç”¨NumPyæ•°ç»„æ“ä½œ

#### æ¡ˆä¾‹ï¼šåŠ¨é‡å› å­è®¡ç®—

**ä¼˜åŒ–å‰** (å¾ªç¯å®ç°):
```python
def calculate_momentum_slow(prices: pd.Series, window: int = 20) -> pd.Series:
    """æ…¢é€Ÿç‰ˆæœ¬ - ä½¿ç”¨å¾ªç¯"""
    momentum = []
    for i in range(len(prices)):
        if i < window:
            momentum.append(np.nan)
        else:
            ret = (prices.iloc[i] / prices.iloc[i-window]) - 1
            momentum.append(ret)
    return pd.Series(momentum, index=prices.index)

# æ€§èƒ½: 12.5ç§’ (1000åªè‚¡ç¥¨ x 1å¹´æ•°æ®)
```

**ä¼˜åŒ–å** (å‘é‡åŒ–):
```python
def calculate_momentum_fast(prices: pd.Series, window: int = 20) -> pd.Series:
    """å¿«é€Ÿç‰ˆæœ¬ - å‘é‡åŒ–"""
    return prices / prices.shift(window) - 1

# æ€§èƒ½: 1.1ç§’ (æå‡11.4å€)
```

**å…³é”®æ”¹è¿›**:
- âœ… é¿å…æ˜¾å¼å¾ªç¯
- âœ… ä½¿ç”¨pandaså†…ç½®æ–¹æ³•
- âœ… åˆ©ç”¨NumPyåº•å±‚ä¼˜åŒ–

---

### 2. Pandaså‘é‡åŒ–æŠ€å·§

#### æ¡ä»¶ç­›é€‰å‘é‡åŒ–

**ä¼˜åŒ–å‰**:
```python
# æ…¢é€Ÿ: ä½¿ç”¨apply
signals = df['alpha'].apply(lambda x: 1 if x > 0.5 else -1 if x < -0.5 else 0)
```

**ä¼˜åŒ–å**:
```python
# å¿«é€Ÿ: ä½¿ç”¨å‘é‡åŒ–æ¡ä»¶
signals = np.where(df['alpha'] > 0.5, 1,
           np.where(df['alpha'] < -0.5, -1, 0))
```

#### æ»šåŠ¨çª—å£ä¼˜åŒ–

```python
# é«˜æ•ˆçš„æ»šåŠ¨è®¡ç®—
ma20 = df['close'].rolling(20).mean()
std20 = df['close'].rolling(20).std()
z_score = (df['close'] - ma20) / std20

# æ€§èƒ½æå‡: 3-5å€
```

---

## ğŸš€ å¹¶è¡Œè®¡ç®—

### 1. å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹

**ä½ç½®**: `src/backtest/parallel_backtest.py`

```python
from multiprocessing import Pool, cpu_count
from typing import List

def parallel_backtest(
    stock_codes: List[str],
    strategy: BaseStrategy,
    n_jobs: int = -1
) -> Dict[str, BacktestResult]:
    """
    å¹¶è¡Œå›æµ‹å¤šåªè‚¡ç¥¨

    Args:
        stock_codes: è‚¡ç¥¨åˆ—è¡¨
        strategy: äº¤æ˜“ç­–ç•¥
        n_jobs: å¹¶è¡Œè¿›ç¨‹æ•° (-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPU)

    Returns:
        æ¯åªè‚¡ç¥¨çš„å›æµ‹ç»“æœ
    """
    if n_jobs == -1:
        n_jobs = cpu_count()

    with Pool(n_jobs) as pool:
        results = pool.starmap(
            _backtest_single_stock,
            [(code, strategy) for code in stock_codes]
        )

    return dict(zip(stock_codes, results))

def _backtest_single_stock(stock_code: str, strategy: BaseStrategy):
    """å•åªè‚¡ç¥¨å›æµ‹"""
    data = load_stock_data(stock_code)
    engine = BacktestEngine(strategy)
    return engine.run(data)

# æ€§èƒ½å¯¹æ¯”
# å•è¿›ç¨‹: 120ç§’ (100åªè‚¡ç¥¨)
# 8è¿›ç¨‹:  15ç§’ (æå‡8.0å€)
```

### 2. å¤šçº¿ç¨‹ç‰¹å¾è®¡ç®—

```python
from concurrent.futures import ThreadPoolExecutor
import pandas as pd

def calculate_features_parallel(
    df: pd.DataFrame,
    feature_functions: List[Callable],
    n_threads: int = 4
) -> pd.DataFrame:
    """å¹¶è¡Œè®¡ç®—å¤šä¸ªç‰¹å¾"""

    with ThreadPoolExecutor(max_workers=n_threads) as executor:
        futures = {
            executor.submit(func, df): func.__name__
            for func in feature_functions
        }

        features = {}
        for future in futures:
            feature_name = futures[future]
            features[feature_name] = future.result()

    return pd.DataFrame(features, index=df.index)

# æ€§èƒ½æå‡: 3-4å€ (CPUå¯†é›†å‹ä»»åŠ¡)
```

---

## ğŸ® GPUåŠ é€Ÿ

### 1. PyTorch GPUè®­ç»ƒ

**ä½ç½®**: `src/models/gru_model.py`

```python
import torch

class GRUModel:
    def __init__(self, use_gpu: bool = True):
        self.device = torch.device(
            "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
        )
        self.model = self._build_model().to(self.device)

    def train(self, X: np.ndarray, y: np.ndarray):
        """GPUè®­ç»ƒ"""
        X_tensor = torch.FloatTensor(X).to(self.device)
        y_tensor = torch.FloatTensor(y).to(self.device)

        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.epochs):
            outputs = self.model(X_tensor)
            loss = self.criterion(outputs, y_tensor)
            # ...

# æ€§èƒ½å¯¹æ¯”
# CPUè®­ç»ƒ: 300ç§’
# GPUè®­ç»ƒ: 15ç§’ (æå‡20å€)
```

### 2. CuPyåŠ é€Ÿæ•°ç»„è®¡ç®—

```python
import cupy as cp  # GPUç‰ˆæœ¬çš„NumPy

# CPUç‰ˆæœ¬
cpu_array = np.random.rand(10000, 10000)
result_cpu = np.dot(cpu_array, cpu_array.T)  # 12ç§’

# GPUç‰ˆæœ¬
gpu_array = cp.random.rand(10000, 10000)
result_gpu = cp.dot(gpu_array, gpu_array.T)  # 0.8ç§’ (æå‡15å€)
```

---

## ğŸ’¾ æ•°æ®åº“ä¼˜åŒ–

### 1. TimescaleDBæ—¶åºä¼˜åŒ–

**ç´¢å¼•ç­–ç•¥**:
```sql
-- åˆ›å»ºæ—¶é—´ç´¢å¼•
CREATE INDEX idx_stock_data_time ON stock_data (time DESC);

-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_stock_code_time ON stock_data (stock_code, time DESC);

-- åˆ›å»ºåˆ†åŒºè¡¨
SELECT create_hypertable('stock_data', 'time',
    chunk_time_interval => INTERVAL '1 month');
```

**æŸ¥è¯¢ä¼˜åŒ–**:
```python
# ä¼˜åŒ–å‰: å…¨è¡¨æ‰«æ (5.2ç§’)
df = pd.read_sql(
    "SELECT * FROM stock_data WHERE stock_code='000001.SZ'",
    engine
)

# ä¼˜åŒ–å: ä½¿ç”¨ç´¢å¼• + æ—¶é—´èŒƒå›´ (0.8ç§’)
df = pd.read_sql(
    """
    SELECT * FROM stock_data
    WHERE stock_code='000001.SZ'
      AND time >= '2023-01-01'
      AND time <= '2023-12-31'
    ORDER BY time DESC
    """,
    engine
)

# æ€§èƒ½æå‡: 6.5å€
```

### 2. æ•°æ®åˆ†åŒºç­–ç•¥

```python
# æŒ‰æœˆåˆ†åŒºå­˜å‚¨
SELECT create_hypertable(
    'stock_data',
    'time',
    chunk_time_interval => INTERVAL '1 month'
);

# è‡ªåŠ¨æ•°æ®å‹ç¼©
ALTER TABLE stock_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'stock_code',
    timescaledb.compress_orderby = 'time DESC'
);

# å‹ç¼©å†å²æ•°æ®
SELECT add_compression_policy('stock_data', INTERVAL '7 days');
```

---

## ğŸ—„ï¸ ç¼“å­˜ç­–ç•¥

### 1. LRUç¼“å­˜

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_stock_data(stock_code: str, date: str) -> pd.DataFrame:
    """LRUç¼“å­˜ - æœ€å¤šç¼“å­˜128ä¸ªç»“æœ"""
    return fetch_from_database(stock_code, date)

# é¦–æ¬¡è°ƒç”¨: 800ms (æ•°æ®åº“æŸ¥è¯¢)
# ç¼“å­˜å‘½ä¸­: 0.1ms (æå‡8000å€)
```

### 2. Redisç¼“å­˜

```python
import redis
import pickle

class FeatureCache:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379)
        self.ttl = 3600  # 1å°æ—¶è¿‡æœŸ

    def get(self, key: str) -> Optional[pd.DataFrame]:
        """ä»Redisè·å–ç¼“å­˜"""
        data = self.redis_client.get(key)
        if data:
            return pickle.loads(data)
        return None

    def set(self, key: str, value: pd.DataFrame):
        """å­˜å‚¨åˆ°Redis"""
        self.redis_client.setex(
            key,
            self.ttl,
            pickle.dumps(value)
        )

# ä½¿ç”¨ç¤ºä¾‹
cache = FeatureCache()
features = cache.get(f"features_{stock_code}")
if features is None:
    features = calculate_features(stock_code)
    cache.set(f"features_{stock_code}", features)
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### 1. æ€§èƒ½åˆ†æå·¥å…·

#### cProfileæ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

# æ€§èƒ½åˆ†æ
profiler = cProfile.Profile()
profiler.enable()

# è¿è¡Œä»£ç 
result = backtest_engine.run(data)

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)  # æ‰“å°å‰20ä¸ªæœ€è€—æ—¶çš„å‡½æ•°
```

#### line_profileré€è¡Œåˆ†æ

```bash
# å®‰è£…
pip install line_profiler

# ä½¿ç”¨è£…é¥°å™¨
@profile
def calculate_alpha_factor(data):
    # ä»£ç 

# è¿è¡Œåˆ†æ
kernprof -l -v script.py
```

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•

**ä½ç½®**: `tests/performance/`

```python
import pytest
from time import time

@pytest.mark.benchmark
def test_feature_calculation_performance():
    """ç‰¹å¾è®¡ç®—æ€§èƒ½åŸºå‡†"""
    data = generate_test_data(n_stocks=100, n_days=252)

    start = time()
    features = calculate_all_features(data)
    elapsed = time() - start

    # æ–­è¨€æ€§èƒ½è¦æ±‚
    assert elapsed < 5.0, f"Feature calculation too slow: {elapsed:.2f}s"
    print(f"âœ… Feature calculation: {elapsed:.2f}s")
```

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ¸…å•

### ä»£ç å±‚é¢

- [ ] ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£å¾ªç¯
- [ ] é¿å…ä¸å¿…è¦çš„æ•°æ®å¤åˆ¶
- [ ] ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ•°æ®
- [ ] åˆç†ä½¿ç”¨å¹¶è¡Œè®¡ç®—
- [ ] å¯ç”¨GPUåŠ é€Ÿï¼ˆå¦‚é€‚ç”¨ï¼‰

### æ•°æ®åº“å±‚é¢

- [ ] åˆ›å»ºåˆé€‚çš„ç´¢å¼•
- [ ] ä½¿ç”¨åˆ†åŒºè¡¨
- [ ] ä¼˜åŒ–æŸ¥è¯¢è¯­å¥
- [ ] å¯ç”¨æŸ¥è¯¢ç¼“å­˜
- [ ] å‹ç¼©å†å²æ•°æ®

### æ¶æ„å±‚é¢

- [ ] å®ç°å¤šå±‚ç¼“å­˜
- [ ] å¼‚æ­¥å¤„ç†IOæ“ä½œ
- [ ] ä½¿ç”¨è¿æ¥æ± 
- [ ] é¢„è®¡ç®—å¸¸ç”¨ç‰¹å¾
- [ ] è´Ÿè½½å‡è¡¡

---

## ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ

### å®Œæ•´å·¥ä½œæµæ€§èƒ½

| é˜¶æ®µ | æ—¶é—´ | å æ¯” |
|------|------|------|
| æ•°æ®åŠ è½½ | 0.8s | 5% |
| ç‰¹å¾è®¡ç®— | 1.0s | 6% |
| æ¨¡å‹é¢„æµ‹ | 0.5s | 3% |
| å›æµ‹æ‰§è¡Œ | 15.0s | 86% |
| **æ€»è®¡** | **17.3s** | **100%** |

**å¯¹æ¯”v2.0.0**: 120s â†’ 17.3s (**æå‡7å€**)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- ğŸ—ï¸ [æ¶æ„æ€»è§ˆè¯¦è§£](overview.md)
- ğŸ¨ [è®¾è®¡æ¨¡å¼è¯¦è§£](design_patterns.md)
- ğŸ”§ [æŠ€æœ¯æ ˆè¯¦è§£](tech_stack.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v3.0.0
**ç»´æŠ¤å›¢é˜Ÿ**: Quant Team
**æœ€åæ›´æ–°**: 2026-02-01
