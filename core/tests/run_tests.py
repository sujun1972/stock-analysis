#!/usr/bin/env python3
"""
ç»Ÿä¸€æµ‹è¯•è¿è¡Œå™¨ - Coreé¡¹ç›®

åŠŸèƒ½ï¼š
- è¿è¡Œæ‰€æœ‰æµ‹è¯•æˆ–é€‰æ‹©ç‰¹å®šæµ‹è¯•
- ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Šå¹¶æ£€æŸ¥é˜ˆå€¼
- æ”¯æŒæ’é™¤æ…¢é€Ÿæµ‹è¯•
- äº¤äº’å¼èœå•é€‰æ‹©ï¼ˆæ˜¾ç¤ºé¢„è®¡æ—¶é—´ï¼‰
- è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šå’Œç»Ÿè®¡
- å¹¶è¡Œæµ‹è¯•æ”¯æŒ
- å¤±è´¥æµ‹è¯•ä¼˜å…ˆé‡è¯•

ä½¿ç”¨æ–¹æ³•ï¼š
    python run_tests.py                    # äº¤äº’å¼èœå•
    python run_tests.py --all              # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python run_tests.py --unit             # åªè¿è¡Œå•å…ƒæµ‹è¯•
    python run_tests.py --integration      # åªè¿è¡Œé›†æˆæµ‹è¯•
    python run_tests.py --coverage         # è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
    python run_tests.py --fast             # å¿«é€Ÿæµ‹è¯•ï¼ˆæ’é™¤æ…¢é€Ÿæµ‹è¯•ï¼‰
    python run_tests.py --layer strategies # è¿è¡Œç­–ç•¥å±‚æµ‹è¯•
    python run_tests.py --layer data       # è¿è¡Œæ•°æ®å±‚æµ‹è¯•
    python run_tests.py --list-modules     # åˆ—å‡ºæ‰€æœ‰æµ‹è¯•æ¨¡å—
    python run_tests.py --module xxx       # è¿è¡ŒæŒ‡å®šæ¨¡å—æµ‹è¯•
    python run_tests.py --parallel         # å¹¶è¡Œè¿è¡Œæµ‹è¯•
    python run_tests.py --failed-first     # ä¼˜å…ˆè¿è¡Œä¸Šæ¬¡å¤±è´¥çš„æµ‹è¯•
    python run_tests.py --min-coverage 80  # è®¾ç½®æœ€å°è¦†ç›–ç‡é˜ˆå€¼

ä½œè€…: Stock Analysis Team
åˆ›å»º: 2026-01-29
æ›´æ–°: 2026-01-30
"""

import sys
import os
import argparse
import subprocess
import time
import json
import re
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from datetime import datetime

# é¢œè‰²è¾“å‡º
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_header(text: str):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{Colors.HEADER}{Colors.BOLD}{'='*80}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{text:^80}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{'='*80}{Colors.ENDC}\n")

def print_success(text: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"{Colors.OKGREEN}âœ“ {text}{Colors.ENDC}")

def print_error(text: str):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"{Colors.FAIL}âœ— {text}{Colors.ENDC}")

def print_warning(text: str):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"{Colors.WARNING}âš  {text}{Colors.ENDC}")

def print_info(text: str):
    """æ‰“å°ä¿¡æ¯"""
    print(f"{Colors.OKBLUE}â„¹ {text}{Colors.ENDC}")

def get_project_root() -> Path:
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    return Path(__file__).parent.parent

def check_venv() -> bool:
    """æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ"""
    # Coreé¡¹ç›®ä½¿ç”¨è‡ªå·±çš„è™šæ‹Ÿç¯å¢ƒ
    venv_path = get_project_root() / 'venv'
    return venv_path.exists()

def get_python_cmd() -> str:
    """è·å–Pythonå‘½ä»¤"""
    # Coreé¡¹ç›®ä½¿ç”¨è‡ªå·±çš„è™šæ‹Ÿç¯å¢ƒ
    venv_path = get_project_root() / 'venv'
    if venv_path.exists():
        return str(venv_path / 'bin' / 'python')
    return 'python3'

def parse_pytest_output(output: str) -> Dict:
    """è§£æpytestè¾“å‡ºï¼Œæå–æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'passed': 0,
        'failed': 0,
        'skipped': 0,
        'errors': 0,
        'warnings': 0,
        'duration': 0.0,
        'coverage': None,
        'interrupted': False
    }

    # é¦–å…ˆå°è¯•ä»æœ€ç»ˆç»Ÿè®¡è¡Œè§£æ (ä¾‹å¦‚: "1427 passed, 17 skipped in 26.95s")
    result_pattern = r'(\d+)\s+(passed|failed|skipped|error)'
    found_summary = False
    for match in re.finditer(result_pattern, output):
        found_summary = True
        count = int(match.group(1))
        status = match.group(2)
        if status == 'passed':
            stats['passed'] = count
        elif status == 'failed':
            stats['failed'] = count
        elif status == 'skipped':
            stats['skipped'] = count
        elif status == 'error':
            stats['errors'] = count

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»Ÿè®¡è¡Œï¼ˆæµ‹è¯•è¢«ä¸­æ–­ï¼‰ï¼Œä»å®æ—¶è¾“å‡ºä¸­ç»Ÿè®¡
    if not found_summary:
        stats['interrupted'] = True
        # ç»Ÿè®¡æ¯ä¸€è¡Œçš„æµ‹è¯•ç»“æœ
        passed_pattern = r'PASSED\s+\['
        failed_pattern = r'FAILED\s+\['
        skipped_pattern = r'SKIPPED\s+\['
        error_pattern = r'ERROR\s+\['

        stats['passed'] = len(re.findall(passed_pattern, output))
        stats['failed'] = len(re.findall(failed_pattern, output))
        stats['skipped'] = len(re.findall(skipped_pattern, output))
        stats['errors'] = len(re.findall(error_pattern, output))

    # è§£ææ‰§è¡Œæ—¶é—´
    time_pattern = r'in\s+([\d.]+)s'
    time_match = re.search(time_pattern, output)
    if time_match:
        stats['duration'] = float(time_match.group(1))

    # è§£æè¦†ç›–ç‡
    coverage_pattern = r'TOTAL\s+\d+\s+\d+\s+(\d+)%'
    coverage_match = re.search(coverage_pattern, output)
    if coverage_match:
        stats['coverage'] = int(coverage_match.group(1))

    return stats

def print_test_summary(stats: Dict, duration: float):
    """æ‰“å°æµ‹è¯•æ‘˜è¦"""
    print_header("æµ‹è¯•æ‰§è¡Œæ‘˜è¦")

    total = stats['passed'] + stats['failed'] + stats['skipped']

    # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
    if stats.get('interrupted', False):
        print_warning("âš ï¸  æµ‹è¯•è¿è¡Œè¢«ä¸­æ–­æˆ–æœªå®Œæˆ")

    print(f"{Colors.BOLD}æ‰§è¡Œæ—¶é—´:{Colors.ENDC} {duration:.2f}ç§’")
    print(f"{Colors.BOLD}æ€»æµ‹è¯•æ•°:{Colors.ENDC} {total}", end="")
    if stats.get('interrupted', False):
        print(f" {Colors.WARNING}(ç»Ÿè®¡è‡ªå®æ—¶è¾“å‡ºï¼Œå¯èƒ½ä¸å®Œæ•´){Colors.ENDC}")
    else:
        print()
    print()

    if total == 0:
        print_error("æœªæ£€æµ‹åˆ°ä»»ä½•æµ‹è¯•ç»“æœ")
        print_warning("å¯èƒ½åŸå› :")
        print("  â€¢ æµ‹è¯•åœ¨æ”¶é›†é˜¶æ®µå¤±è´¥")
        print("  â€¢ pytestè¾“å‡ºæ ¼å¼æ”¹å˜")
        print("  â€¢ æµ‹è¯•è¿›ç¨‹è¢«å¼ºåˆ¶ç»ˆæ­¢")
        print()
        return

    if stats['passed'] > 0:
        print_success(f"é€šè¿‡: {stats['passed']} ({stats['passed']/total*100:.1f}%)")

    if stats['failed'] > 0:
        print_error(f"å¤±è´¥: {stats['failed']} ({stats['failed']/total*100:.1f}%)")

    if stats['skipped'] > 0:
        print_warning(f"è·³è¿‡: {stats['skipped']} ({stats['skipped']/total*100:.1f}%)")

    if stats['errors'] > 0:
        print_error(f"é”™è¯¯: {stats['errors']}")

    if stats.get('coverage') is not None:
        coverage = stats['coverage']
        print()
        if coverage >= 80:
            print_success(f"ä»£ç è¦†ç›–ç‡: {coverage}%")
        elif coverage >= 70:
            print_warning(f"ä»£ç è¦†ç›–ç‡: {coverage}% (å»ºè®®â‰¥80%)")
        else:
            print_error(f"ä»£ç è¦†ç›–ç‡: {coverage}% (å»ºè®®â‰¥80%)")

    print()

def check_coverage_threshold(output: str, min_coverage: int) -> bool:
    """æ£€æŸ¥è¦†ç›–ç‡æ˜¯å¦è¾¾åˆ°é˜ˆå€¼"""
    coverage_pattern = r'TOTAL\s+\d+\s+\d+\s+(\d+)%'
    coverage_match = re.search(coverage_pattern, output)

    if not coverage_match:
        print_warning("æ— æ³•æå–è¦†ç›–ç‡ä¿¡æ¯")
        return True

    coverage = int(coverage_match.group(1))

    if coverage < min_coverage:
        print_error(f"è¦†ç›–ç‡ {coverage}% ä½äºé˜ˆå€¼ {min_coverage}%")
        return False

    print_success(f"è¦†ç›–ç‡ {coverage}% è¾¾åˆ°é˜ˆå€¼ {min_coverage}%")
    return True

def run_command(cmd: List[str], description: str = "", capture_output: bool = False) -> Tuple[int, str]:
    """è¿è¡Œå‘½ä»¤"""
    if description:
        print_info(f"{description}...")

    print(f"{Colors.OKCYAN}æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}{Colors.ENDC}\n")

    start_time = time.time()

    if capture_output:
        result = subprocess.run(cmd, cwd=get_project_root(),
                              capture_output=True, text=True)
        output = result.stdout + result.stderr
        print(output)  # åŒæ—¶æ‰“å°åˆ°ç»ˆç«¯
    else:
        result = subprocess.run(cmd, cwd=get_project_root())
        output = ""

    duration = time.time() - start_time

    # è§£æå¹¶æ‰“å°æ‘˜è¦
    if capture_output and output:
        stats = parse_pytest_output(output)
        print_test_summary(stats, duration)

        # å¦‚æœæœ‰å¤±è´¥æˆ–é”™è¯¯ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯æç¤º
        if stats['failed'] > 0 or stats['errors'] > 0:
            print_warning("\næç¤º: è¦æŸ¥çœ‹å¤±è´¥æµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‘ä¸Šæ»šåŠ¨æŸ¥çœ‹å®Œæ•´è¾“å‡º")
            print_info("æˆ–è€…è¿è¡Œ: pytest <æµ‹è¯•æ–‡ä»¶> -v --tb=short æ¥æŸ¥çœ‹ç‰¹å®šæµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯")

    return result.returncode, output

def build_pytest_cmd(
    test_path: Optional[str] = None,
    coverage: bool = False,
    verbose: bool = True,
    exclude_slow: bool = False,
    markers: Optional[str] = None,
    timeout: Optional[int] = None,
    parallel: bool = False,
    failed_first: bool = False,
    num_workers: int = 4
) -> List[str]:
    """æ„å»ºpytestå‘½ä»¤"""
    python_cmd = get_python_cmd()
    cmd = [python_cmd, '-m', 'pytest']

    # æµ‹è¯•è·¯å¾„
    if test_path:
        cmd.append(test_path)
    else:
        cmd.append('tests/')

    # æ€»æ˜¯æ’é™¤CLIæµ‹è¯•ï¼ˆä½¿ç”¨ä¸“é—¨çš„run_cli_tests.pyè¿è¡Œï¼‰
    cmd.append('--ignore=tests/cli/')
    print_info("å·²æ’é™¤CLIæµ‹è¯•ï¼ˆè¯·ä½¿ç”¨ python run_cli_tests.py è¿è¡ŒCLIæµ‹è¯•ï¼‰")

    # è¦†ç›–ç‡é€‰é¡¹
    if coverage:
        cmd.extend([
            '--cov=src',
            '--cov-report=html:tests/reports/htmlcov',
            '--cov-report=term',
            '--cov-report=xml:tests/reports/coverage.xml'
        ])

    # è¯¦ç»†è¾“å‡º
    if verbose:
        cmd.append('-v')
    else:
        cmd.append('-q')

    # æ’é™¤æ…¢é€Ÿæµ‹è¯•
    if exclude_slow:
        # æ’é™¤GRUæ¨¡å‹æµ‹è¯•ï¼ˆæœ€æ…¢çš„æµ‹è¯•ï¼Œä¼šå¯¼è‡´æ®µé”™è¯¯ï¼‰
        cmd.append('--ignore=tests/unit/models/test_gru_model.py')
        cmd.append('--ignore=tests/unit/test_gru_model_comprehensive.py')

        # æ’é™¤è€—æ—¶çš„å•å…ƒæµ‹è¯•ï¼ˆæ¯ä¸ªæµ‹è¯•1-5ç§’ï¼‰
        cmd.append('--ignore=tests/unit/analysis/test_factor_analyzer.py')  # 5.28s, 4.20s, 1.76s
        cmd.append('--ignore=tests/unit/backtest/test_parallel_backtester.py')  # 1.07s, 1.04s, 1.01s
        cmd.append('--ignore=tests/unit/utils/test_parallel_executor.py')  # 1.55s, 1.29s, 1.12s

        # æ’é™¤å¤–éƒ¨APIé›†æˆæµ‹è¯•ï¼ˆéœ€è¦ç½‘ç»œè¿æ¥å’ŒAPI tokenï¼‰
        cmd.append('--ignore=tests/integration/providers/akshare/')
        cmd.append('--ignore=tests/integration/providers/test_tushare_provider.py')
        print_warning("å·²æ’é™¤æ…¢é€Ÿæµ‹è¯•ï¼šGRUæ¨¡å‹ã€å› å­åˆ†æå™¨ã€å¹¶è¡Œå›æµ‹ã€å¹¶è¡Œæ‰§è¡Œå™¨ã€å¤–éƒ¨API")

    # æ ‡è®°è¿‡æ»¤
    if markers:
        cmd.extend(['-m', markers])

    # è¶…æ—¶è®¾ç½®
    if timeout:
        cmd.extend(['--timeout', str(timeout)])

    # å¹¶è¡Œæµ‹è¯•
    if parallel:
        cmd.extend(['-n', str(num_workers)])
        print_info(f"å¯ç”¨å¹¶è¡Œæµ‹è¯•ï¼Œä½¿ç”¨ {num_workers} ä¸ªå·¥ä½œè¿›ç¨‹")

    # ä¼˜å…ˆè¿è¡Œå¤±è´¥çš„æµ‹è¯•
    if failed_first:
        cmd.append('--failed-first')
        print_info("ä¼˜å…ˆè¿è¡Œä¸Šæ¬¡å¤±è´¥çš„æµ‹è¯•")

    # å…¶ä»–æœ‰ç”¨çš„é€‰é¡¹
    cmd.extend([
        '--tb=short',  # ç®€çŸ­çš„é”™è¯¯å›æº¯
    ])

    return cmd

def show_menu():
    """æ˜¾ç¤ºäº¤äº’å¼èœå•"""
    print_header("Coreé¡¹ç›®æµ‹è¯•è¿è¡Œå™¨")

    # é¢„è®¡æ—¶é—´ï¼ˆåŸºäº2026-02-01å®æµ‹æ•°æ® - å·²ä¼˜åŒ–ï¼‰
    estimated_times = {
        '1': '~260ç§’ (4.5åˆ†é’Ÿ)',
        '2': '~38ç§’',        # å¿«é€Ÿå•å…ƒæµ‹è¯•ï¼ˆå·²ä¼˜åŒ–ï¼‰âš¡
        '3': '~80ç§’',        # æ‰€æœ‰å•å…ƒæµ‹è¯• (æ’é™¤GRU)
        '4': '~175ç§’ (3åˆ†é’Ÿ)',  # æ‰€æœ‰é›†æˆæµ‹è¯•
        '5': '~3ç§’',
        '6': 'å˜åŒ–',
        'I1': '~30ç§’',       # é›†æˆæµ‹è¯•-å¿«é€Ÿ
        'I2': '~120ç§’',      # é›†æˆæµ‹è¯•-å®Œæ•´ä¸å«å¤–éƒ¨API
        'I3': '~175ç§’',      # é›†æˆæµ‹è¯•-å…¨éƒ¨
    }

    print("è¯·é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•:")
    print()
    print(f"{Colors.BOLD}[å¿«é€Ÿæµ‹è¯• - æ¨èæ—¥å¸¸ä½¿ç”¨]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[2]{Colors.ENDC} å¿«é€Ÿå•å…ƒæµ‹è¯• (æ’é™¤æ…¢é€Ÿæµ‹è¯•: GRU/å› å­åˆ†æ/å¹¶è¡Œ) {Colors.OKCYAN}[{estimated_times['2']}]{Colors.ENDC} âš¡")
    print(f"  {Colors.BOLD}[Q]{Colors.ENDC} å¿«é€Ÿé›†æˆæµ‹è¯• (æ’é™¤å¤–éƒ¨API) {Colors.OKCYAN}[{estimated_times['I1']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[X]{Colors.ENDC} å¿«é€Ÿè¯Šæ–­ (åªè¿è¡Œå¤±è´¥è¿‡çš„æµ‹è¯•) {Colors.OKCYAN}[<10ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[QM]{Colors.ENDC} MLå¿«é€ŸéªŒè¯ (ML-2/ML-3/ML-4) {Colors.OKCYAN}[~15ç§’]{Colors.ENDC} ğŸš€")
    print()
    print(f"{Colors.BOLD}[å®Œæ•´æµ‹è¯•]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[1]{Colors.ENDC} è¿è¡Œæ‰€æœ‰æµ‹è¯• (å•å…ƒ+é›†æˆ, å¸¦è¦†ç›–ç‡) {Colors.OKCYAN}[{estimated_times['1']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[3]{Colors.ENDC} æ‰€æœ‰å•å…ƒæµ‹è¯• (æ’é™¤GRU) {Colors.OKCYAN}[{estimated_times['3']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[4]{Colors.ENDC} æ‰€æœ‰é›†æˆæµ‹è¯• {Colors.OKCYAN}[{estimated_times['4']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[5]{Colors.ENDC} æ€§èƒ½æµ‹è¯• {Colors.OKCYAN}[{estimated_times['5']}]{Colors.ENDC}")
    print()
    print(f"{Colors.BOLD}[é›†æˆæµ‹è¯•åˆ†ç±» - æŒ‰é€Ÿåº¦]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[I1]{Colors.ENDC} å¿«é€Ÿé›†æˆæµ‹è¯• (æ’é™¤å¤–éƒ¨API) {Colors.OKCYAN}[{estimated_times['I1']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[I2]{Colors.ENDC} ä¸­é€Ÿé›†æˆæµ‹è¯• (å«æ•°æ®åº“/ä¸å«API) {Colors.OKCYAN}[{estimated_times['I2']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[I3]{Colors.ENDC} å®Œæ•´é›†æˆæµ‹è¯• (å«å¤–éƒ¨API) {Colors.OKCYAN}[{estimated_times['I3']}]{Colors.ENDC}")
    print()
    print(f"{Colors.BOLD}[å•å…ƒæµ‹è¯• - æŒ‰åŠŸèƒ½å±‚]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[D]{Colors.ENDC} æ•°æ®å±‚ (data + providers) {Colors.OKCYAN}[~8ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[F]{Colors.ENDC} ç‰¹å¾å±‚ (features) {Colors.OKCYAN}[~15ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[M]{Colors.ENDC} æ¨¡å‹å±‚ (models, æ’é™¤GRU) {Colors.OKCYAN}[~20ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[B]{Colors.ENDC} å›æµ‹å±‚ (backtest) {Colors.OKCYAN}[~8ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[S]{Colors.ENDC} ç­–ç•¥å±‚ (strategies) {Colors.OKCYAN}[~5ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[R]{Colors.ENDC} é£æ§å±‚ (risk_management) {Colors.OKCYAN}[~2ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[A]{Colors.ENDC} å› å­åˆ†æå±‚ (analysis) {Colors.OKCYAN}[~4ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[O]{Colors.ENDC} å‚æ•°ä¼˜åŒ–å±‚ (optimization) {Colors.OKCYAN}[~3ç§’]{Colors.ENDC}")
    print()
    print(f"{Colors.BOLD}[å…¶ä»–é€‰é¡¹]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[6]{Colors.ENDC} è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯• {Colors.OKCYAN}[{estimated_times['6']}]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[L]{Colors.ENDC} æŒ‰å±‚çº§æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æµ‹è¯•æ¨¡å— {Colors.OKCYAN}[<1ç§’]{Colors.ENDC}")
    print(f"  {Colors.BOLD}[P]{Colors.ENDC} åˆ‡æ¢å¹¶è¡Œæ¨¡å¼ (åŠ é€Ÿæµ‹è¯•æ‰§è¡Œ)")
    print(f"  {Colors.BOLD}[T]{Colors.ENDC} æŸ¥çœ‹æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯")
    print(f"  {Colors.BOLD}[0]{Colors.ENDC} é€€å‡º")
    print()

    choice = input(f"{Colors.OKBLUE}è¯·è¾“å…¥é€‰é¡¹: {Colors.ENDC}")
    return choice.strip().upper()

def run_all_tests(coverage: bool = True, fast: bool = False, parallel: bool = False, failed_first: bool = False):
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print_header("è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    cmd = build_pytest_cmd(coverage=coverage, exclude_slow=fast, parallel=parallel, failed_first=failed_first)
    returncode, output = run_command(cmd, "è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶", capture_output=True)
    return returncode

def run_unit_tests(coverage: bool = True, parallel: bool = False):
    """è¿è¡Œå•å…ƒæµ‹è¯•"""
    print_header("è¿è¡Œå•å…ƒæµ‹è¯•")
    cmd = build_pytest_cmd('tests/unit/', coverage=coverage, parallel=parallel)
    returncode, output = run_command(cmd, "è¿è¡Œå•å…ƒæµ‹è¯•", capture_output=True)
    return returncode

def run_integration_tests(coverage: bool = True, parallel: bool = False, speed_level: str = 'all'):
    """
    è¿è¡Œé›†æˆæµ‹è¯•

    Args:
        coverage: æ˜¯å¦ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
        parallel: æ˜¯å¦å¹¶è¡Œè¿è¡Œ
        speed_level: é€Ÿåº¦çº§åˆ«
            - 'fast': å¿«é€Ÿæµ‹è¯•ï¼Œæ’é™¤å¤–éƒ¨APIå’Œæ…¢é€Ÿæµ‹è¯• (~30ç§’)
            - 'medium': ä¸­é€Ÿæµ‹è¯•ï¼ŒåŒ…å«æ•°æ®åº“æµ‹è¯•ï¼Œæ’é™¤å¤–éƒ¨API (~120ç§’)
            - 'all': æ‰€æœ‰é›†æˆæµ‹è¯• (~175ç§’)
    """
    if speed_level == 'fast':
        print_header("è¿è¡Œå¿«é€Ÿé›†æˆæµ‹è¯• (æ’é™¤å¤–éƒ¨APIå’Œæ…¢é€Ÿæµ‹è¯•)")
    elif speed_level == 'medium':
        print_header("è¿è¡Œä¸­é€Ÿé›†æˆæµ‹è¯• (åŒ…å«æ•°æ®åº“ï¼Œæ’é™¤å¤–éƒ¨API)")
    else:
        print_header("è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•")

    # æ„å»ºå‘½ä»¤
    python_cmd = get_python_cmd()
    cmd = [python_cmd, '-m', 'pytest', 'tests/integration/']

    # æ ¹æ®é€Ÿåº¦çº§åˆ«æ’é™¤æµ‹è¯•
    if speed_level in ['fast', 'medium']:
        # æ’é™¤å¤–éƒ¨APIæµ‹è¯• (æœ€è€—æ—¶: æ¯ä¸ªæµ‹è¯•4-5ç§’)
        cmd.append('--ignore=tests/integration/providers/')
        cmd.append('--ignore=tests/integration/test_multi_data_source.py')
        cmd.append('--ignore=tests/integration/test_end_to_end_workflow.py')
        print_info("å·²æ’é™¤å¤–éƒ¨APIæµ‹è¯• (providers, multi_data_source, end_to_end_workflow)")

    if speed_level == 'fast':
        # é¢å¤–æ’é™¤ä¸­é€Ÿæµ‹è¯•
        cmd.append('--ignore=tests/integration/test_database_security_and_concurrency.py')
        cmd.append('--ignore=tests/integration/test_database_manager_refactored.py')
        cmd.append('--ignore=tests/integration/test_parallel_ic_calculation.py')
        cmd.append('--ignore=tests/integration/test_gpu_integration.py')
        cmd.append('--ignore=tests/integration/test_model_trainer_integration.py')
        print_info("å·²æ’é™¤æ•°æ®åº“å’ŒGPUç›¸å…³æ…¢é€Ÿæµ‹è¯•")

    # è¦†ç›–ç‡é€‰é¡¹
    if coverage:
        cmd.extend([
            '--cov=src',
            '--cov-report=html:tests/reports/htmlcov',
            '--cov-report=term',
        ])

    # å…¶ä»–é€‰é¡¹
    cmd.extend(['-v', '--tb=short'])

    if parallel:
        cmd.extend(['-n', '4'])

    returncode, _ = run_command(cmd, "è¿è¡Œé›†æˆæµ‹è¯•", capture_output=True)
    return returncode

def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print_header("è¿è¡Œæ€§èƒ½æµ‹è¯•")
    cmd = build_pytest_cmd('tests/performance/', coverage=False)
    returncode, output = run_command(cmd, "è¿è¡Œæ€§èƒ½æµ‹è¯•", capture_output=True)
    return returncode

def run_provider_tests(coverage: bool = True):
    """è¿è¡ŒProvideræµ‹è¯•"""
    print_header("è¿è¡ŒProvideræµ‹è¯•")

    print_info("è¿è¡Œå•å…ƒæµ‹è¯•...")
    cmd = build_pytest_cmd('tests/unit/providers/', coverage=coverage)
    ret1, _ = run_command(cmd, capture_output=True)

    print_info("è¿è¡Œé›†æˆæµ‹è¯•...")
    cmd2 = build_pytest_cmd('tests/integration/providers/', coverage=coverage)
    ret2, _ = run_command(cmd2, capture_output=True)

    return ret1 + ret2

def run_model_tests(coverage: bool = True, exclude_gru: bool = True):
    """è¿è¡Œæ¨¡å‹æµ‹è¯•"""
    print_header("è¿è¡Œæ¨¡å‹æµ‹è¯•")

    if exclude_gru:
        print_warning("æ’é™¤GRUæ¨¡å‹æµ‹è¯•ï¼ˆè®­ç»ƒè¾ƒæ…¢ï¼‰")
        cmd = build_pytest_cmd('tests/unit/models/', coverage=coverage, exclude_slow=True)
    else:
        cmd = build_pytest_cmd('tests/unit/models/', coverage=coverage)

    returncode, output = run_command(cmd, "è¿è¡Œæ¨¡å‹æµ‹è¯•", capture_output=True)
    return returncode

def run_feature_tests(coverage: bool = True):
    """è¿è¡Œç‰¹å¾å·¥ç¨‹æµ‹è¯•"""
    print_header("è¿è¡Œç‰¹å¾å·¥ç¨‹æµ‹è¯•")
    cmd = build_pytest_cmd('tests/unit/features/', coverage=coverage)
    returncode, output = run_command(cmd, "è¿è¡Œç‰¹å¾å·¥ç¨‹æµ‹è¯•", capture_output=True)
    return returncode

def run_quick_tests():
    """
    è¿è¡ŒMLå¿«é€ŸéªŒè¯æµ‹è¯•ï¼ˆML-2, ML-3, ML-4ï¼‰

    è¿™äº›æµ‹è¯•éªŒè¯æ ¸å¿ƒMLåŠŸèƒ½çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼š
    - ML-2: å¤šå› å­åŠ æƒæ¨¡å‹ï¼ˆå½’ä¸€åŒ–ã€å› å­æƒé‡ã€å› å­åˆ†ç»„ï¼‰
    - ML-3: LightGBMæ’åºæ¨¡å‹ï¼ˆè®­ç»ƒã€ä¿å­˜ã€åŠ è½½ã€é€‰è‚¡ï¼‰
    - ML-4: å› å­åº“é›†æˆï¼ˆ125+å› å­ã€é€šé…ç¬¦ç‰¹å¾ã€æ€§èƒ½å¯¹æ¯”ï¼‰
    """
    print_header("è¿è¡ŒMLå¿«é€ŸéªŒè¯æµ‹è¯•")

    print_info("è¿™äº›æµ‹è¯•å°†éªŒè¯ä»¥ä¸‹MLåŠŸèƒ½æ¨¡å—:")
    print("  â€¢ ML-2: å¤šå› å­åŠ æƒæ¨¡å‹å¢å¼ºåŠŸèƒ½")
    print("  â€¢ ML-3: LightGBMæ’åºæ¨¡å‹è®­ç»ƒä¸é€‰è‚¡")
    print("  â€¢ ML-4: å®Œæ•´å› å­åº“é›†æˆï¼ˆ125+å› å­ï¼‰")
    print()

    # è¿è¡ŒMLç›¸å…³çš„å•å…ƒæµ‹è¯•
    print_info("è¿è¡ŒMLé€‰è‚¡å™¨å•å…ƒæµ‹è¯•...")
    cmd = build_pytest_cmd(
        'tests/unit/strategies/three_layer/selectors/test_ml_selector.py',
        coverage=False,
        verbose=True
    )
    returncode, output = run_command(cmd, "è¿è¡ŒMLé€‰è‚¡å™¨æµ‹è¯•", capture_output=True)

    if returncode == 0:
        print_success("âœ… MLå¿«é€ŸéªŒè¯æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        print()
        print_info("éªŒè¯çš„åŠŸèƒ½åŒ…æ‹¬:")
        print("  âœ“ å¤šå› å­åŠ æƒæ¨¡å‹ï¼ˆå½’ä¸€åŒ–ã€æƒé‡é…ç½®ï¼‰")
        print("  âœ“ LightGBMæ’åºæ¨¡å‹ï¼ˆè®­ç»ƒã€é¢„æµ‹ï¼‰")
        print("  âœ“ å› å­åº“é›†æˆï¼ˆ125+å› å­ï¼‰")
        print("  âœ“ é€šé…ç¬¦ç‰¹å¾è§£æ")
        print("  âœ“ å‘åå…¼å®¹æ€§")
        return 0
    else:
        print_error("âŒ MLå¿«é€ŸéªŒè¯æµ‹è¯•å¤±è´¥")
        print_warning("è¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡ºä»¥äº†è§£å¤±è´¥åŸå› ")
        return 1

def run_layer_tests(layer: str, coverage: bool = True, parallel: bool = False):
    """
    æŒ‰æ ¸å¿ƒå±‚è¿è¡Œæµ‹è¯•

    Args:
        layer: å±‚çº§åç§° ('data', 'features', 'models', 'backtest', 'strategies',
                        'risk_management', 'analysis', 'optimization')
        coverage: æ˜¯å¦ç”Ÿæˆè¦†ç›–ç‡
        parallel: æ˜¯å¦å¹¶è¡Œè¿è¡Œ
    """
    layer_config = {
        'data': {
            'name': 'æ•°æ®å±‚',
            'paths': ['tests/unit/data/', 'tests/unit/providers/'],
            'src': ['src/data/', 'src/providers/']
        },
        'features': {
            'name': 'ç‰¹å¾å±‚',
            'paths': ['tests/unit/features/'],
            'src': ['src/features/']
        },
        'models': {
            'name': 'æ¨¡å‹å±‚',
            'paths': ['tests/unit/models/'],
            'src': ['src/models/'],
            'exclude': ['tests/unit/models/test_gru_model.py', 'tests/unit/test_gru_model_comprehensive.py']
        },
        'backtest': {
            'name': 'å›æµ‹å±‚',
            'paths': ['tests/unit/backtest/', 'tests/integration/test_backtest_with_cost_analysis.py'],
            'src': ['src/backtest/']
        },
        'strategies': {
            'name': 'ç­–ç•¥å±‚',
            'paths': ['tests/unit/strategies/'],
            'src': ['src/strategies/']
        },
        'risk_management': {
            'name': 'é£æ§å±‚',
            'paths': ['tests/unit/risk_management/'],
            'src': ['src/risk_management/']
        },
        'analysis': {
            'name': 'å› å­åˆ†æå±‚',
            'paths': ['tests/unit/analysis/'],
            'src': ['src/analysis/']
        },
        'optimization': {
            'name': 'å‚æ•°ä¼˜åŒ–å±‚',
            'paths': ['tests/unit/optimization/'],
            'src': ['src/optimization/']
        }
    }

    if layer not in layer_config:
        print_error(f"æœªçŸ¥çš„å±‚çº§: {layer}")
        return 1

    config = layer_config[layer]
    print_header(f"è¿è¡Œ{config['name']}æµ‹è¯•")

    # æ„å»ºæµ‹è¯•è·¯å¾„
    test_paths = ' '.join(config['paths'])

    # æ„å»ºpytestå‘½ä»¤
    python_cmd = get_python_cmd()
    cmd = [python_cmd, '-m', 'pytest'] + config['paths']

    # æ·»åŠ è¦†ç›–ç‡é€‰é¡¹
    if coverage:
        # ä¸ºæ¯ä¸ªæºç è·¯å¾„å•ç‹¬æ·»åŠ  --cov å‚æ•°
        for src_path in config['src']:
            cmd.append(f'--cov={src_path}')
        cmd.extend([
            '--cov-report=html:tests/reports/htmlcov',
            '--cov-report=term',
        ])

    # æ·»åŠ æ’é™¤é¡¹
    if 'exclude' in config:
        for exclude_path in config['exclude']:
            cmd.extend(['--ignore', exclude_path])

    # æ·»åŠ å…¶ä»–é€‰é¡¹
    cmd.extend(['-v', '--tb=short'])

    if parallel:
        cmd.extend(['-n', '4'])

    returncode, output = run_command(cmd, f"è¿è¡Œ{config['name']}æµ‹è¯•", capture_output=True)
    return returncode

def list_all_test_modules():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æµ‹è¯•æ¨¡å—ï¼ˆæŒ‰å±‚çº§ï¼‰"""
    print_header("å¯ç”¨çš„æµ‹è¯•æ¨¡å—")

    layers = {
        'æ•°æ®å±‚': 'tests/unit/data tests/unit/providers',
        'ç‰¹å¾å±‚': 'tests/unit/features',
        'æ¨¡å‹å±‚': 'tests/unit/models',
        'å›æµ‹å±‚': 'tests/unit/backtest',
        'ç­–ç•¥å±‚': 'tests/unit/strategies',
        'é£æ§å±‚': 'tests/unit/risk_management',
        'å› å­åˆ†æå±‚': 'tests/unit/analysis',
        'å‚æ•°ä¼˜åŒ–å±‚': 'tests/unit/optimization',
        'é…ç½®å±‚': 'tests/unit/config',
        'å·¥å…·å±‚': 'tests/unit/utils',
    }

    for layer_name, path in layers.items():
        print(f"\n{Colors.BOLD}{layer_name}:{Colors.ENDC}")
        paths = path.split()
        for p in paths:
            full_path = get_project_root() / p
            if full_path.exists():
                files = sorted(full_path.glob('test_*.py'))
                for f in files:
                    print(f"  - {f.relative_to(get_project_root())}")

    print()
    return 0

def run_specific_module():
    """è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•"""
    print_header("è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•")
    print()
    print("å¯ç”¨çš„æµ‹è¯•æ¨¡å—:")
    print("  - unit/test_data_loader.py")
    print("  - unit/test_feature_engineer.py")
    print("  - unit/test_model_trainer.py")
    print("  - integration/test_data_pipeline.py")
    print("  - ç­‰ç­‰...")
    print()

    module = input(f"{Colors.OKBLUE}è¯·è¾“å…¥æ¨¡å—è·¯å¾„ (å¦‚: unit/test_data_loader.py): {Colors.ENDC}")

    if not module:
        print_error("æœªè¾“å…¥æ¨¡å—è·¯å¾„")
        return 1

    test_path = f"tests/{module}"
    if not Path(get_project_root() / test_path).exists():
        print_error(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_path}")
        return 1

    cmd = build_pytest_cmd(test_path, coverage=True)
    returncode, output = run_command(cmd, f"è¿è¡Œ {module}", capture_output=True)
    return returncode

def run_failed_first():
    """ä¼˜å…ˆè¿è¡Œå¤±è´¥çš„æµ‹è¯•"""
    print_header("å¿«é€Ÿè¯Šæ–­ - è¿è¡Œå¤±è´¥è¿‡çš„æµ‹è¯•")
    cmd = build_pytest_cmd(coverage=False, failed_first=True, exclude_slow=True)
    returncode, _ = run_command(cmd, "ä¼˜å…ˆè¿è¡Œå¤±è´¥æµ‹è¯•", capture_output=True)
    return returncode

def show_test_statistics():
    """æ˜¾ç¤ºæµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
    print_header("æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯")

    test_categories = {
        'å•å…ƒæµ‹è¯•': {
            'æ•°æ®å±‚': 'tests/unit/data tests/unit/providers',
            'ç‰¹å¾å±‚': 'tests/unit/features',
            'æ¨¡å‹å±‚': 'tests/unit/models',
            'å›æµ‹å±‚': 'tests/unit/backtest',
            'ç­–ç•¥å±‚': 'tests/unit/strategies',
            'é£æ§å±‚': 'tests/unit/risk_management',
            'å› å­åˆ†æå±‚': 'tests/unit/analysis',
            'å‚æ•°ä¼˜åŒ–å±‚': 'tests/unit/optimization',
            'å…¶ä»–': 'tests/unit/config tests/unit/utils tests/unit/api',
        },
        'é›†æˆæµ‹è¯•': {
            'å¤–éƒ¨API (æ…¢)': 'tests/integration/providers tests/integration/test_multi_data_source.py tests/integration/test_end_to_end_workflow.py',
            'æ•°æ®åº“ (ä¸­)': 'tests/integration/test_database_*.py',
            'GPU/æ¨¡å‹ (ä¸­)': 'tests/integration/test_gpu_integration.py tests/integration/test_model_trainer_integration.py',
            'å…¶ä»– (å¿«)': 'tests/integration/test_phase*.py tests/integration/test_backtest*.py tests/integration/test_feature*.py',
        }
    }

    for category, subcats in test_categories.items():
        print(f"\n{Colors.BOLD}{category}:{Colors.ENDC}")
        for subcat, paths in subcats.items():
            count = 0
            for path in paths.split():
                full_path = get_project_root() / path
                if full_path.exists():
                    if full_path.is_file():
                        count += 1
                    else:
                        files = list(full_path.glob('test_*.py'))
                        count += len(files)

            print(f"  {subcat}: {count} ä¸ªæµ‹è¯•æ–‡ä»¶")

    print(f"\n{Colors.BOLD}è€—æ—¶å‚è€ƒ (åŸºäº2026-02-01å®æµ‹):{Colors.ENDC}")
    print(f"  å¿«é€Ÿå•å…ƒæµ‹è¯•: ~38ç§’ (2582ä¸ªæµ‹è¯•) âš¡")
    print(f"  å®Œæ•´å•å…ƒæµ‹è¯• (æ’é™¤GRU): ~80ç§’ (2665ä¸ªæµ‹è¯•)")
    print(f"  å¿«é€Ÿé›†æˆæµ‹è¯•: ~30ç§’")
    print(f"  ä¸­é€Ÿé›†æˆæµ‹è¯•: ~120ç§’")
    print(f"  å®Œæ•´é›†æˆæµ‹è¯•: ~175ç§’")
    print(f"  æ‰€æœ‰æµ‹è¯•: ~260ç§’ (4.5åˆ†é’Ÿ)")
    print()

    return 0

def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼"""
    parallel_mode = False

    while True:
        choice = show_menu()

        if choice == '0':
            print_info("é€€å‡ºæµ‹è¯•è¿è¡Œå™¨")
            return 0
        # å¿«é€Ÿæµ‹è¯•
        elif choice == '2':
            return run_all_tests(coverage=False, fast=True, parallel=parallel_mode)
        elif choice == 'Q':
            return run_integration_tests(coverage=False, parallel=parallel_mode, speed_level='fast')
        elif choice == 'X':
            return run_failed_first()
        elif choice == 'QM':
            return run_quick_tests()
        # å®Œæ•´æµ‹è¯•
        elif choice == '1':
            return run_all_tests(coverage=True, fast=False, parallel=parallel_mode)
        elif choice == '3':
            return run_unit_tests(coverage=True, parallel=parallel_mode)
        elif choice == '4':
            return run_integration_tests(coverage=True, parallel=parallel_mode, speed_level='all')
        elif choice == '5':
            return run_performance_tests()
        # é›†æˆæµ‹è¯•åˆ†ç±»
        elif choice == 'I1':
            return run_integration_tests(coverage=False, parallel=parallel_mode, speed_level='fast')
        elif choice == 'I2':
            return run_integration_tests(coverage=False, parallel=parallel_mode, speed_level='medium')
        elif choice == 'I3':
            return run_integration_tests(coverage=True, parallel=parallel_mode, speed_level='all')
        # å•å…ƒæµ‹è¯•æŒ‰å±‚
        elif choice == 'D':
            return run_layer_tests('data', coverage=True, parallel=parallel_mode)
        elif choice == 'F':
            return run_layer_tests('features', coverage=True, parallel=parallel_mode)
        elif choice == 'M':
            return run_layer_tests('models', coverage=True, parallel=parallel_mode)
        elif choice == 'B':
            return run_layer_tests('backtest', coverage=True, parallel=parallel_mode)
        elif choice == 'S':
            return run_layer_tests('strategies', coverage=True, parallel=parallel_mode)
        elif choice == 'R':
            return run_layer_tests('risk_management', coverage=True, parallel=parallel_mode)
        elif choice == 'A':
            return run_layer_tests('analysis', coverage=True, parallel=parallel_mode)
        elif choice == 'O':
            return run_layer_tests('optimization', coverage=True, parallel=parallel_mode)
        # å…¶ä»–é€‰é¡¹
        elif choice == '6':
            return run_specific_module()
        elif choice == 'L':
            list_all_test_modules()
            continue
        elif choice == 'T':
            show_test_statistics()
            continue
        elif choice == 'P':
            parallel_mode = not parallel_mode
            if parallel_mode:
                print_success("âœ“ å·²å¯ç”¨å¹¶è¡Œæ¨¡å¼ (ä½¿ç”¨4ä¸ªå·¥ä½œè¿›ç¨‹)")
            else:
                print_info("å·²ç¦ç”¨å¹¶è¡Œæ¨¡å¼")
            continue
        else:
            print_error("æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")
            continue

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Coreé¡¹ç›®ç»Ÿä¸€æµ‹è¯•è¿è¡Œå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                           # äº¤äº’å¼èœå•
  %(prog)s --all                     # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  %(prog)s --all --coverage          # è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡
  %(prog)s --fast                    # å¿«é€Ÿæµ‹è¯•ï¼ˆæ’é™¤æ…¢é€Ÿæµ‹è¯•å’Œå¤–éƒ¨APIæµ‹è¯•ï¼‰
  %(prog)s --fast --parallel         # å¿«é€Ÿ+å¹¶è¡Œæµ‹è¯•
  %(prog)s --quick-ml                # MLå¿«é€ŸéªŒè¯æµ‹è¯•ï¼ˆML-2/ML-3/ML-4ï¼‰
  %(prog)s --unit                    # åªè¿è¡Œå•å…ƒæµ‹è¯•
  %(prog)s --integration             # åªè¿è¡Œé›†æˆæµ‹è¯•
  %(prog)s --performance             # åªè¿è¡Œæ€§èƒ½æµ‹è¯•

  # æ ¸å¿ƒå±‚æµ‹è¯•ï¼ˆæ¨èï¼‰
  %(prog)s --layer strategies        # è¿è¡Œç­–ç•¥å±‚æµ‹è¯•
  %(prog)s --layer data              # è¿è¡Œæ•°æ®å±‚æµ‹è¯•ï¼ˆå«providersï¼‰
  %(prog)s --layer features          # è¿è¡Œç‰¹å¾å±‚æµ‹è¯•
  %(prog)s --layer models            # è¿è¡Œæ¨¡å‹å±‚æµ‹è¯•
  %(prog)s --layer backtest          # è¿è¡Œå›æµ‹å±‚æµ‹è¯•
  %(prog)s --layer risk_management   # è¿è¡Œé£æ§å±‚æµ‹è¯•
  %(prog)s --layer analysis          # è¿è¡Œå› å­åˆ†æå±‚æµ‹è¯•
  %(prog)s --layer optimization      # è¿è¡Œå‚æ•°ä¼˜åŒ–å±‚æµ‹è¯•
  %(prog)s --layer data --parallel   # å¹¶è¡Œè¿è¡Œæ•°æ®å±‚æµ‹è¯•
  %(prog)s --list-modules            # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æµ‹è¯•æ¨¡å—

  # ä¼ ç»Ÿæ¨¡å—æµ‹è¯•ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
  %(prog)s --providers               # è¿è¡ŒProvideræµ‹è¯•
  %(prog)s --models                  # è¿è¡Œæ¨¡å‹æµ‹è¯•
  %(prog)s --features                # è¿è¡Œç‰¹å¾å·¥ç¨‹æµ‹è¯•
  %(prog)s --module unit/test_xxx.py # è¿è¡Œç‰¹å®šæ¨¡å—
  %(prog)s --failed-first            # ä¼˜å…ˆè¿è¡Œå¤±è´¥çš„æµ‹è¯•
  %(prog)s --min-coverage 80         # è®¾ç½®æœ€å°è¦†ç›–ç‡é˜ˆå€¼
        """
    )

    # ç»¼åˆæµ‹è¯•é€‰é¡¹
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰æµ‹è¯•')
    parser.add_argument('--fast', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆæ’é™¤æ…¢é€Ÿæµ‹è¯•å’Œå¤–éƒ¨APIæµ‹è¯•ï¼‰')
    parser.add_argument('--unit', action='store_true', help='è¿è¡Œå•å…ƒæµ‹è¯•')
    parser.add_argument('--integration', action='store_true', help='è¿è¡Œé›†æˆæµ‹è¯•')
    parser.add_argument('--performance', action='store_true', help='è¿è¡Œæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--quick-ml', action='store_true', help='è¿è¡ŒMLå¿«é€ŸéªŒè¯æµ‹è¯•ï¼ˆML-2/ML-3/ML-4ï¼‰')

    # æ ¸å¿ƒå±‚æµ‹è¯•é€‰é¡¹
    parser.add_argument('--layer', type=str, choices=[
        'data', 'features', 'models', 'backtest', 'strategies',
        'risk_management', 'analysis', 'optimization'
    ], help='è¿è¡ŒæŒ‡å®šæ ¸å¿ƒå±‚çš„æµ‹è¯•')

    # ä¼ ç»Ÿæ¨¡å—æµ‹è¯•é€‰é¡¹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    parser.add_argument('--providers', action='store_true', help='è¿è¡ŒProvideræµ‹è¯•')
    parser.add_argument('--models', action='store_true', help='è¿è¡Œæ¨¡å‹æµ‹è¯•')
    parser.add_argument('--features', action='store_true', help='è¿è¡Œç‰¹å¾å·¥ç¨‹æµ‹è¯•')
    parser.add_argument('--module', type=str, help='è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•')

    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--list-modules', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æµ‹è¯•æ¨¡å—')
    parser.add_argument('--coverage', action='store_true', default=True, help='ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Šï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--no-coverage', action='store_true', help='ä¸ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š')
    parser.add_argument('--parallel', action='store_true', help='å¹¶è¡Œè¿è¡Œæµ‹è¯•')
    parser.add_argument('--failed-first', action='store_true', help='ä¼˜å…ˆè¿è¡Œä¸Šæ¬¡å¤±è´¥çš„æµ‹è¯•')
    parser.add_argument('--min-coverage', type=int, default=0, help='æœ€å°è¦†ç›–ç‡é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤4ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if not check_venv():
        print_warning("æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ stock_envï¼Œå°†ä½¿ç”¨ç³»ç»ŸPython")

    # ç¡®å®šè¦†ç›–ç‡é€‰é¡¹
    coverage = args.coverage and not args.no_coverage

    # å¦‚æœæ²¡æœ‰ä»»ä½•å‚æ•°ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
    if len(sys.argv) == 1:
        return interactive_mode()

    # æ ¹æ®å‚æ•°è¿è¡Œç›¸åº”çš„æµ‹è¯•
    returncode = 0

    # åˆ—å‡ºæ¨¡å—
    if args.list_modules:
        return list_all_test_modules()

    # å¿«é€ŸMLéªŒè¯æµ‹è¯•
    if args.quick_ml:
        return run_quick_tests()
    # æ ¸å¿ƒå±‚æµ‹è¯•
    elif args.layer:
        returncode = run_layer_tests(args.layer, coverage=coverage, parallel=args.parallel)
    # ç»¼åˆæµ‹è¯•
    elif args.all or args.fast:
        returncode = run_all_tests(coverage=coverage, fast=args.fast,
                                   parallel=args.parallel, failed_first=args.failed_first)
    elif args.unit:
        returncode = run_unit_tests(coverage=coverage, parallel=args.parallel)
    elif args.integration:
        returncode = run_integration_tests(coverage=coverage, parallel=args.parallel, speed_level='all')
    elif args.performance:
        returncode = run_performance_tests()
    # ä¼ ç»Ÿæ¨¡å—æµ‹è¯•ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    elif args.providers:
        returncode = run_provider_tests(coverage=coverage)
    elif args.models:
        returncode = run_model_tests(coverage=coverage, exclude_gru=True)
    elif args.features:
        returncode = run_feature_tests(coverage=coverage)
    elif args.module:
        test_path = f"tests/{args.module}"
        if not Path(get_project_root() / test_path).exists():
            print_error(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_path}")
            return 1
        cmd = build_pytest_cmd(test_path, coverage=coverage)
        returncode, _ = run_command(cmd, f"è¿è¡Œ {args.module}", capture_output=True)
    elif args.failed_first:
        returncode = run_failed_first()
    else:
        parser.print_help()
        return 0

    return returncode

if __name__ == '__main__':
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print_warning("\n\næµ‹è¯•å·²è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print_error(f"å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
