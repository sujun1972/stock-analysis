"""
Alphaå› å­ç¼“å­˜æœºåˆ¶æµ‹è¯•

æµ‹è¯• FactorCache ç±»çš„æ‰€æœ‰åŠŸèƒ½ï¼š
- LRUç¼“å­˜æ·˜æ±°ç­–ç•¥
- çº¿ç¨‹å®‰å…¨æ€§
- åŸå­æ“ä½œ get_or_compute
- ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
- å¹¶å‘åœºæ™¯

ä½œè€…: Stock Analysis Team
åˆ›å»º: 2026-01-30
"""

import pytest
import pandas as pd
import numpy as np
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from src.features.alpha_factors import (
    FactorCache,
    BaseFactorCalculator,
    MomentumFactorCalculator,
)


# ==================== åŸºç¡€æµ‹è¯• ====================


class TestFactorCacheBasics:
    """FactorCache åŸºç¡€åŠŸèƒ½æµ‹è¯•"""

    def test_cache_init(self):
        """æµ‹è¯•ç¼“å­˜åˆå§‹åŒ–"""
        cache = FactorCache(max_size=100)
        assert cache.max_size == 100
        assert len(cache._cache) == 0
        assert len(cache._access_order) == 0

    def test_cache_put_and_get(self):
        """æµ‹è¯•åŸºæœ¬çš„å­˜å–æ“ä½œ"""
        cache = FactorCache()
        cache.put("key1", "value1")
        cache.put("key2", {"data": [1, 2, 3]})

        assert cache.get("key1") == "value1"
        assert cache.get("key2") == {"data": [1, 2, 3]}
        assert cache.get("key3") is None  # ä¸å­˜åœ¨çš„é”®

    def test_cache_overwrite(self):
        """æµ‹è¯•è¦†ç›–å·²å­˜åœ¨çš„é”®"""
        cache = FactorCache()
        cache.put("key1", "value1")
        cache.put("key1", "value2")  # è¦†ç›–

        assert cache.get("key1") == "value2"
        assert len(cache._cache) == 1  # åªæœ‰ä¸€ä¸ªé”®

    def test_cache_clear(self):
        """æµ‹è¯•æ¸…ç©ºç¼“å­˜"""
        cache = FactorCache()
        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.get("key1")  # è§¦å‘ä¸€æ¬¡å‘½ä¸­

        cache.clear()

        assert len(cache._cache) == 0
        assert len(cache._access_order) == 0
        assert cache._hit_count == 0
        assert cache._miss_count == 0


# ==================== LRUæ·˜æ±°ç­–ç•¥æµ‹è¯• ====================


class TestFactorCacheLRU:
    """LRUç¼“å­˜æ·˜æ±°ç­–ç•¥æµ‹è¯•"""

    def test_lru_eviction_basic(self):
        """æµ‹è¯•åŸºæœ¬LRUæ·˜æ±°"""
        cache = FactorCache(max_size=3)

        # å¡«æ»¡ç¼“å­˜
        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.put("key3", "value3")

        # æ·»åŠ ç¬¬4ä¸ªé”®ï¼Œåº”æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„key1
        cache.put("key4", "value4")

        assert cache.get("key1") is None  # å·²è¢«æ·˜æ±°
        assert cache.get("key2") == "value2"
        assert cache.get("key3") == "value3"
        assert cache.get("key4") == "value4"

    def test_lru_eviction_with_access(self):
        """æµ‹è¯•è®¿é—®å½±å“LRUé¡ºåº"""
        cache = FactorCache(max_size=3)

        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.put("key3", "value3")

        # è®¿é—®key1ï¼Œä½¿å…¶æˆä¸ºæœ€è¿‘ä½¿ç”¨
        cache.get("key1")

        # æ·»åŠ æ–°é”®ï¼Œåº”æ·˜æ±°key2ï¼ˆæœ€ä¹…æœªä½¿ç”¨ï¼‰
        cache.put("key4", "value4")

        assert cache.get("key1") == "value1"  # ä¿ç•™
        assert cache.get("key2") is None      # æ·˜æ±°
        assert cache.get("key3") == "value3"  # ä¿ç•™
        assert cache.get("key4") == "value4"  # æ–°å¢

    def test_lru_eviction_multiple_accesses(self):
        """æµ‹è¯•å¤šæ¬¡è®¿é—®çš„å½±å“"""
        cache = FactorCache(max_size=3)

        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.put("key3", "value3")

        # å¤šæ¬¡è®¿é—®key1å’Œkey3
        for _ in range(5):
            cache.get("key1")
            cache.get("key3")

        # æ·»åŠ æ–°é”®ï¼Œåº”æ·˜æ±°key2ï¼ˆä»æœªè¢«è®¿é—®ï¼‰
        cache.put("key4", "value4")

        assert cache.get("key1") == "value1"
        assert cache.get("key2") is None
        assert cache.get("key3") == "value3"

    def test_lru_with_put_updates(self):
        """æµ‹è¯•putæ“ä½œä¹Ÿä¼šæ›´æ–°è®¿é—®é¡ºåº"""
        cache = FactorCache(max_size=3)

        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.put("key3", "value3")

        # æ›´æ–°key1çš„å€¼ï¼ˆç›¸å½“äºè®¿é—®ï¼‰
        cache.put("key1", "new_value1")

        # æ·»åŠ æ–°é”®
        cache.put("key4", "value4")

        # key1åº”è¯¥è¢«ä¿ç•™ï¼ˆåˆšæ›´æ–°è¿‡ï¼‰ï¼Œkey2åº”è¯¥è¢«æ·˜æ±°
        assert cache.get("key1") == "new_value1"
        assert cache.get("key2") is None


# ==================== çº¿ç¨‹å®‰å…¨æµ‹è¯• ====================


class TestFactorCacheThreadSafety:
    """ç¼“å­˜çº¿ç¨‹å®‰å…¨æ€§æµ‹è¯•"""

    def test_concurrent_puts(self):
        """æµ‹è¯•å¹¶å‘å†™å…¥"""
        cache = FactorCache(max_size=1000)
        results = []
        errors = []

        def worker(key, value):
            try:
                cache.put(key, value)
                results.append(cache.get(key))
            except Exception as e:
                errors.append(e)

        # åˆ›å»º100ä¸ªçº¿ç¨‹å¹¶å‘å†™å…¥
        threads = [
            threading.Thread(target=worker, args=(f"key{i}", f"value{i}"))
            for i in range(100)
        ]

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # éªŒè¯
        assert len(errors) == 0  # æ²¡æœ‰å¼‚å¸¸
        assert len(results) == 100  # æ‰€æœ‰å†™å…¥æˆåŠŸ
        assert all(r is not None for r in results)

    def test_concurrent_gets(self):
        """æµ‹è¯•å¹¶å‘è¯»å–"""
        cache = FactorCache()
        cache.put("shared_key", "shared_value")

        results = []

        def worker():
            results.append(cache.get("shared_key"))

        # 100ä¸ªçº¿ç¨‹åŒæ—¶è¯»å–
        threads = [threading.Thread(target=worker) for _ in range(100)]

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # æ‰€æœ‰è¯»å–éƒ½åº”æˆåŠŸ
        assert len(results) == 100
        assert all(r == "shared_value" for r in results)

    def test_concurrent_put_and_get(self):
        """æµ‹è¯•è¯»å†™æ··åˆå¹¶å‘"""
        cache = FactorCache(max_size=500)

        def writer(i):
            cache.put(f"key{i}", f"value{i}")

        def reader(i):
            return cache.get(f"key{i}")

        # ä½¿ç”¨çº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=20) as executor:
            # å…ˆå†™å…¥50ä¸ª
            write_futures = [executor.submit(writer, i) for i in range(50)]
            for f in as_completed(write_futures):
                f.result()

            # åŒæ—¶è¿›è¡Œè¯»å†™
            mixed_futures = []
            for i in range(100):
                if i % 2 == 0:
                    mixed_futures.append(executor.submit(writer, i + 50))
                else:
                    mixed_futures.append(executor.submit(reader, i % 50))

            # ç­‰å¾…å®Œæˆ
            for f in as_completed(mixed_futures):
                f.result()

        # éªŒè¯ç¼“å­˜å¤§å°åˆç†
        assert len(cache._cache) > 0

    def test_concurrent_eviction(self):
        """æµ‹è¯•å¹¶å‘ç¯å¢ƒä¸‹çš„LRUæ·˜æ±°"""
        cache = FactorCache(max_size=10)

        def worker(i):
            # æ¯ä¸ªçº¿ç¨‹å°è¯•å†™å…¥3ä¸ªé”®
            for j in range(3):
                key = f"thread{i}_key{j}"
                cache.put(key, f"value{i}_{j}")
                time.sleep(0.001)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´

        # 20ä¸ªçº¿ç¨‹ï¼Œæ€»å…±60ä¸ªé”®ï¼Œç¼“å­˜åªèƒ½å®¹çº³10ä¸ª
        threads = [threading.Thread(target=worker, args=(i,)) for i in range(20)]

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # éªŒè¯ç¼“å­˜å¤§å°
        assert len(cache._cache) <= cache.max_size


# ==================== get_or_compute æµ‹è¯• ====================


class TestFactorCacheGetOrCompute:
    """åŸå­æ“ä½œ get_or_compute æµ‹è¯•"""

    def test_get_or_compute_cache_miss(self):
        """æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­æ—¶çš„è®¡ç®—"""
        cache = FactorCache()
        compute_count = 0

        def expensive_compute():
            nonlocal compute_count
            compute_count += 1
            return "computed_value"

        # ç¬¬ä¸€æ¬¡è°ƒç”¨åº”è§¦å‘è®¡ç®—
        result = cache.get_or_compute("test_key", expensive_compute)

        assert result == "computed_value"
        assert compute_count == 1
        assert cache.get("test_key") == "computed_value"

    def test_get_or_compute_cache_hit(self):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­æ—¶ä¸é‡æ–°è®¡ç®—"""
        cache = FactorCache()
        compute_count = 0

        def expensive_compute():
            nonlocal compute_count
            compute_count += 1
            return "computed_value"

        # ç¬¬ä¸€æ¬¡è®¡ç®—
        result1 = cache.get_or_compute("test_key", expensive_compute)
        assert compute_count == 1

        # ç¬¬äºŒæ¬¡åº”ä½¿ç”¨ç¼“å­˜
        result2 = cache.get_or_compute("test_key", expensive_compute)

        assert result2 == "computed_value"
        assert compute_count == 1  # æ²¡æœ‰å†æ¬¡è®¡ç®—

    def test_get_or_compute_different_keys(self):
        """æµ‹è¯•ä¸åŒé”®çš„ç‹¬ç«‹è®¡ç®—"""
        cache = FactorCache()

        def compute_value(prefix):
            def _compute():
                return f"{prefix}_value"
            return _compute

        result1 = cache.get_or_compute("key1", compute_value("first"))
        result2 = cache.get_or_compute("key2", compute_value("second"))

        assert result1 == "first_value"
        assert result2 == "second_value"

    def test_get_or_compute_concurrent(self):
        """æµ‹è¯•å¹¶å‘è°ƒç”¨get_or_computeï¼ˆé˜²æ­¢é‡å¤è®¡ç®—ï¼‰"""
        cache = FactorCache()
        compute_count = 0
        compute_lock = threading.Lock()

        def expensive_compute():
            nonlocal compute_count
            with compute_lock:
                compute_count += 1
            time.sleep(0.01)  # æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—
            return "computed_value"

        results = []

        def worker():
            result = cache.get_or_compute("shared_key", expensive_compute)
            results.append(result)

        # 10ä¸ªçº¿ç¨‹åŒæ—¶è¯·æ±‚åŒä¸€ä¸ªé”®
        threads = [threading.Thread(target=worker) for _ in range(10)]

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # éªŒè¯ï¼šæ‰€æœ‰çº¿ç¨‹éƒ½æ‹¿åˆ°äº†ç»“æœ
        assert len(results) == 10
        assert all(r == "computed_value" for r in results)

        # å…³é”®éªŒè¯ï¼šè®¡ç®—å‡½æ•°åº”è¯¥åªè¢«è°ƒç”¨ä¸€æ¬¡ï¼ˆæˆ–å¾ˆå°‘æ¬¡ï¼‰
        # ç”±äºRLockçš„åŒé‡æ£€æŸ¥æœºåˆ¶ï¼Œå¯èƒ½æœ‰2-3æ¬¡è®¡ç®—
        assert compute_count <= 3

    def test_get_or_compute_with_exception(self):
        """æµ‹è¯•è®¡ç®—å‡½æ•°æŠ›å‡ºå¼‚å¸¸çš„æƒ…å†µ"""
        cache = FactorCache()

        def failing_compute():
            raise ValueError("Computation failed")

        # å¼‚å¸¸åº”è¯¥è¢«ä¼ æ’­
        with pytest.raises(ValueError, match="Computation failed"):
            cache.get_or_compute("test_key", failing_compute)

        # å¤±è´¥åç¼“å­˜ä¸­ä¸åº”æœ‰è¯¥é”®
        assert cache.get("test_key") is None


# ==================== ç¼“å­˜ç»Ÿè®¡æµ‹è¯• ====================


class TestFactorCacheStats:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•"""

    def test_stats_initial(self):
        """æµ‹è¯•åˆå§‹ç»Ÿè®¡ä¿¡æ¯"""
        cache = FactorCache(max_size=10)
        stats = cache.get_stats()

        assert stats['size'] == 0
        assert stats['max_size'] == 10
        assert stats['hits'] == 0
        assert stats['misses'] == 0
        assert stats['hit_rate'] == 0.0

    def test_stats_hits_and_misses(self):
        """æµ‹è¯•å‘½ä¸­å’Œæœªå‘½ä¸­ç»Ÿè®¡"""
        cache = FactorCache()
        cache.put("key1", "value1")

        # 2æ¬¡å‘½ä¸­
        cache.get("key1")
        cache.get("key1")

        # 3æ¬¡æœªå‘½ä¸­
        cache.get("key2")
        cache.get("key3")
        cache.get("key4")

        stats = cache.get_stats()
        assert stats['hits'] == 2
        assert stats['misses'] == 3
        assert stats['hit_rate'] == 2/5  # 40%
        assert stats['size'] == 1  # åªæœ‰key1

    def test_stats_after_clear(self):
        """æµ‹è¯•æ¸…ç©ºåçš„ç»Ÿè®¡"""
        cache = FactorCache()
        cache.put("key1", "value1")
        cache.get("key1")  # hit
        cache.get("key2")  # miss

        cache.clear()
        stats = cache.get_stats()

        assert stats['hits'] == 0
        assert stats['misses'] == 0
        assert stats['size'] == 0

    def test_stats_with_eviction(self):
        """æµ‹è¯•LRUæ·˜æ±°ä¸å½±å“ç»Ÿè®¡"""
        cache = FactorCache(max_size=2)

        cache.put("key1", "value1")
        cache.put("key2", "value2")
        cache.get("key1")  # hit

        # è§¦å‘æ·˜æ±°
        cache.put("key3", "value3")  # key2è¢«æ·˜æ±°

        stats = cache.get_stats()
        assert stats['size'] == 2  # åªèƒ½å®¹çº³2ä¸ª
        assert stats['hits'] == 1  # ä¹‹å‰çš„å‘½ä¸­è®°å½•ä¿ç•™


# ==================== å®é™…ä½¿ç”¨åœºæ™¯æµ‹è¯• ====================


class TestFactorCacheIntegration:
    """ä¸BaseFactorCalculatoré›†æˆæµ‹è¯•"""

    @pytest.fixture
    def sample_price_data(self):
        """ç”Ÿæˆæ ·æœ¬æ•°æ®"""
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=100, freq='D')
        prices = 100 + np.cumsum(np.random.randn(100) * 0.5)

        return pd.DataFrame({
            'close': prices,
            'vol': np.random.uniform(1000000, 10000000, 100)
        }, index=dates)

    def test_shared_cache_across_instances(self, sample_price_data):
        """æµ‹è¯•å…±äº«ç¼“å­˜åœ¨å¤šä¸ªå®ä¾‹é—´å·¥ä½œ"""
        # åˆ›å»ºä¸¤ä¸ªè®¡ç®—å™¨å®ä¾‹
        calc1 = MomentumFactorCalculator(sample_price_data)
        calc2 = MomentumFactorCalculator(sample_price_data)

        # å®ƒä»¬åº”è¯¥å…±äº«åŒä¸€ä¸ªç¼“å­˜
        assert calc1._shared_cache is calc2._shared_cache

    def test_cache_key_with_df_hash(self, sample_price_data):
        """æµ‹è¯•ç¼“å­˜é”®åŒ…å«æ•°æ®æŒ‡çº¹"""
        calc = MomentumFactorCalculator(sample_price_data)

        # æ•°æ®æŒ‡çº¹åº”è¯¥è¢«è®¡ç®—
        assert calc._df_hash is not None
        assert len(calc._df_hash) == 16  # MD5å‰16ä½

    def test_cache_effectiveness_in_computation(self, sample_price_data):
        """æµ‹è¯•ç¼“å­˜åœ¨å®é™…è®¡ç®—ä¸­çš„æ•ˆæœ"""
        # æ¸…ç©ºå…±äº«ç¼“å­˜
        MomentumFactorCalculator._shared_cache.clear()

        calc = MomentumFactorCalculator(sample_price_data)

        # ç¬¬ä¸€æ¬¡è®¡ç®—
        start = time.time()
        result1 = calc.add_rsi(periods=[14, 28])
        time1 = time.time() - start

        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats = calc._shared_cache.get_stats()
        initial_size = stats['size']

        # ç¬¬äºŒæ¬¡è®¡ç®—ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰- ä½¿ç”¨ç›¸åŒæ–¹æ³•å
        calc2 = MomentumFactorCalculator(sample_price_data)
        start = time.time()
        result2 = calc2.add_rsi(periods=[14, 28])
        time2 = time.time() - start

        # éªŒè¯ç»“æœä¸€è‡´
        pd.testing.assert_frame_equal(result1, result2)

        # ç¼“å­˜åº”è¯¥è¢«ä½¿ç”¨ï¼ˆç¬¬äºŒæ¬¡æ›´å¿«ï¼‰
        # æ³¨æ„ï¼šè¿™ä¸ªæ–­è¨€å¯èƒ½åœ¨å¿«é€Ÿæœºå™¨ä¸Šä¸ç¨³å®šï¼Œä»…ç”¨äºæ¼”ç¤º
        # assert time2 < time1 * 0.8  # è‡³å°‘å¿«20%

    def test_different_df_use_different_cache(self):
        """æµ‹è¯•ä¸åŒæ•°æ®ä½¿ç”¨ä¸åŒç¼“å­˜"""
        # ä¸¤ä¸ªä¸åŒçš„DataFrame
        df1 = pd.DataFrame({'close': [100, 101, 102]},
                          index=pd.date_range('2023-01-01', periods=3))
        df2 = pd.DataFrame({'close': [200, 201, 202]},
                          index=pd.date_range('2023-06-01', periods=3))

        calc1 = MomentumFactorCalculator(df1)
        calc2 = MomentumFactorCalculator(df2)

        # æ•°æ®æŒ‡çº¹åº”è¯¥ä¸åŒ
        assert calc1._df_hash != calc2._df_hash


# ==================== è¾¹ç•Œå’Œå¼‚å¸¸æµ‹è¯• ====================


class TestFactorCacheEdgeCases:
    """è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æµ‹è¯•"""

    def test_max_size_zero(self):
        """æµ‹è¯•max_size=0çš„æƒ…å†µ"""
        cache = FactorCache(max_size=0)
        cache.put("key1", "value1")

        # max_size=0æ—¶ï¼Œç¼“å­˜åº”è¯¥ä¸ºç©ºï¼ˆç«‹å³æ·˜æ±°ï¼‰
        assert len(cache._cache) == 0

    def test_max_size_one(self):
        """æµ‹è¯•max_size=1çš„æƒ…å†µ"""
        cache = FactorCache(max_size=1)
        cache.put("key1", "value1")
        cache.put("key2", "value2")

        # åªèƒ½ä¿ç•™1ä¸ª
        assert len(cache._cache) == 1
        assert cache.get("key2") == "value2"
        assert cache.get("key1") is None

    def test_large_values(self):
        """æµ‹è¯•å­˜å‚¨å¤§å¯¹è±¡"""
        cache = FactorCache(max_size=5)

        # å­˜å‚¨å¤§DataFrame
        large_df = pd.DataFrame(np.random.randn(10000, 100))
        cache.put("large_key", large_df)

        # éªŒè¯èƒ½æ­£ç¡®å­˜å–
        result = cache.get("large_key")
        pd.testing.assert_frame_equal(result, large_df)

    def test_none_value(self):
        """æµ‹è¯•å­˜å‚¨Noneå€¼"""
        cache = FactorCache()
        cache.put("none_key", None)

        # åº”è¯¥èƒ½å­˜å‚¨None
        # ä½†getè¿”å›Noneæ—¶æ— æ³•åŒºåˆ†æ˜¯ä¸å­˜åœ¨è¿˜æ˜¯å€¼ä¸ºNone
        # è¿™æ˜¯å½“å‰è®¾è®¡çš„é™åˆ¶
        result = cache.get("none_key")
        assert result is None

    def test_empty_key(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²é”®"""
        cache = FactorCache()
        cache.put("", "empty_key_value")

        assert cache.get("") == "empty_key_value"

    def test_unicode_keys(self):
        """æµ‹è¯•Unicodeé”®"""
        cache = FactorCache()
        cache.put("é”®1", "å€¼1")
        cache.put("ğŸ”‘2", "ğŸ¯2")

        assert cache.get("é”®1") == "å€¼1"
        assert cache.get("ğŸ”‘2") == "ğŸ¯2"


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
