#!/usr/bin/env python3
"""
å¤šç­–ç•¥å›æµ‹å¯¹æ¯”ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•å¯¹æ¯”ä¸åŒç­–ç•¥çš„è¡¨ç°ï¼ŒåŒ…æ‹¬:
1. åŠ¨é‡ç­–ç•¥ vs åè½¬ç­–ç•¥
2. å•å› å­ç­–ç•¥ vs å¤šå› å­ç­–ç•¥
3. æœºå™¨å­¦ä¹ ç­–ç•¥ vs ä¼ ç»Ÿç­–ç•¥
4. ç­–ç•¥ç»„åˆä¼˜åŒ–

Author: Stock Analysis Core Team
Date: 2026-01-30
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import numpy as np
from loguru import logger
from typing import Dict, List, Callable

from src.backtest import BacktestEngine, PerformanceAnalyzer


def create_sample_data(n_days=504, n_stocks=100):
    """
    åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ˆ2å¹´ï¼‰

    å‚æ•°:
        n_days: äº¤æ˜“æ—¥æ•°ï¼ˆé»˜è®¤504å¤©=2å¹´ï¼‰
        n_stocks: è‚¡ç¥¨æ•°é‡

    è¿”å›:
        (prices_df, features_df): ä»·æ ¼å’Œç‰¹å¾DataFrame
    """
    logger.info(f"ç”Ÿæˆç¤ºä¾‹æ•°æ®: {n_days}å¤© x {n_stocks}åªè‚¡ç¥¨")

    np.random.seed(42)

    dates = pd.date_range('2022-01-01', periods=n_days, freq='D')
    stocks = [f'{600000+i:06d}' for i in range(n_stocks)]

    # ä»·æ ¼æ•°æ®
    price_data = {}
    for i, stock in enumerate(stocks):
        base_price = 10.0 + i * 0.05
        # ä¸€åŠè‚¡ç¥¨æœ‰ä¸Šæ¶¨è¶‹åŠ¿ï¼Œä¸€åŠä¸‹è·Œ
        trend = 0.0003 if i < n_stocks // 2 else -0.0001
        returns = np.random.normal(trend, 0.015, n_days)
        prices = base_price * (1 + returns).cumprod()
        price_data[stock] = prices

    prices_df = pd.DataFrame(price_data, index=dates)

    # ç‰¹å¾æ•°æ®ï¼ˆç”¨äºæ„å»ºä¸åŒç­–ç•¥ï¼‰
    features = {}

    # åŠ¨é‡ç‰¹å¾
    features['MOM5'] = prices_df.pct_change(5)
    features['MOM10'] = prices_df.pct_change(10)
    features['MOM20'] = prices_df.pct_change(20)
    features['MOM60'] = prices_df.pct_change(60)

    # åè½¬ç‰¹å¾ï¼ˆè´ŸåŠ¨é‡ï¼‰
    features['REV5'] = -features['MOM5']
    features['REV10'] = -features['MOM10']

    # æ³¢åŠ¨ç‡ç‰¹å¾
    features['VOL20'] = prices_df.pct_change().rolling(20).std()
    features['VOL60'] = prices_df.pct_change().rolling(60).std()

    # æˆäº¤é‡ç‰¹å¾ï¼ˆæ¨¡æ‹Ÿï¼‰
    volume_data = {}
    for stock in stocks:
        base_vol = 1000000 * (1 + np.random.rand())
        volumes = base_vol * (1 + np.random.randn(n_days) * 0.3)
        volumes = np.abs(volumes)
        volume_data[stock] = volumes

    volumes_df = pd.DataFrame(volume_data, index=dates)
    features['VOL_CHANGE'] = volumes_df.pct_change(5)

    logger.info(f"ç”Ÿæˆäº† {len(features)} ä¸ªç‰¹å¾")

    return prices_df, features


class StrategyFactory:
    """ç­–ç•¥å·¥å‚ï¼šåˆ›å»ºä¸åŒçš„äº¤æ˜“ç­–ç•¥"""

    @staticmethod
    def momentum_strategy(features: Dict, lookback: int = 20) -> pd.DataFrame:
        """
        åŠ¨é‡ç­–ç•¥ï¼šä¹°å…¥è¿‡å»è¡¨ç°å¥½çš„è‚¡ç¥¨

        å‚æ•°:
            features: ç‰¹å¾å­—å…¸
            lookback: å›çœ‹æœŸ

        è¿”å›:
            ä¿¡å·DataFrame
        """
        signal_key = f'MOM{lookback}'
        if signal_key in features:
            return features[signal_key].copy()
        else:
            raise ValueError(f"ç‰¹å¾ {signal_key} ä¸å­˜åœ¨")

    @staticmethod
    def reversal_strategy(features: Dict, lookback: int = 5) -> pd.DataFrame:
        """
        åè½¬ç­–ç•¥ï¼šä¹°å…¥è¿‡å»è¡¨ç°å·®çš„è‚¡ç¥¨ï¼ˆé€†å‘æŠ•èµ„ï¼‰

        å‚æ•°:
            features: ç‰¹å¾å­—å…¸
            lookback: å›çœ‹æœŸ

        è¿”å›:
            ä¿¡å·DataFrame
        """
        signal_key = f'REV{lookback}'
        if signal_key in features:
            return features[signal_key].copy()
        else:
            raise ValueError(f"ç‰¹å¾ {signal_key} ä¸å­˜åœ¨")

    @staticmethod
    def low_volatility_strategy(features: Dict) -> pd.DataFrame:
        """
        ä½æ³¢åŠ¨ç­–ç•¥ï¼šä¹°å…¥æ³¢åŠ¨ç‡ä½çš„è‚¡ç¥¨

        è¿”å›:
            ä¿¡å·DataFrameï¼ˆæ³¢åŠ¨ç‡è¶Šä½ï¼Œä¿¡å·è¶Šå¼ºï¼‰
        """
        vol = features['VOL20']
        # æ³¢åŠ¨ç‡å–è´Ÿæ•°ï¼ˆä½æ³¢åŠ¨=é«˜ä¿¡å·ï¼‰
        return -vol

    @staticmethod
    def multi_factor_strategy(
        features: Dict,
        factor_names: List[str],
        weights: List[float] = None
    ) -> pd.DataFrame:
        """
        å¤šå› å­ç­–ç•¥ï¼šç»„åˆå¤šä¸ªå› å­

        å‚æ•°:
            features: ç‰¹å¾å­—å…¸
            factor_names: å› å­åç§°åˆ—è¡¨
            weights: å› å­æƒé‡ï¼ˆNone=ç­‰æƒï¼‰

        è¿”å›:
            ä¿¡å·DataFrame
        """
        if weights is None:
            weights = [1.0 / len(factor_names)] * len(factor_names)

        # å› å­æ ‡å‡†åŒ–ï¼ˆæ¨ªæˆªé¢ï¼‰
        normalized_factors = []
        for factor_name in factor_names:
            if factor_name not in features:
                raise ValueError(f"ç‰¹å¾ {factor_name} ä¸å­˜åœ¨")

            factor = features[factor_name]
            # æ¨ªæˆªé¢æ’åï¼ˆæ¯å¤©ç‹¬ç«‹ï¼‰
            factor_rank = factor.rank(axis=1, pct=True)
            normalized_factors.append(factor_rank)

        # åŠ æƒç»„åˆ
        combined_signal = pd.DataFrame(0, index=features['MOM20'].index, columns=features['MOM20'].columns)
        for factor, weight in zip(normalized_factors, weights):
            combined_signal += factor * weight

        return combined_signal


def run_strategy_backtest(
    strategy_name: str,
    signals: pd.DataFrame,
    prices: pd.DataFrame,
    top_n: int = 30,
    rebalance_freq: str = 'W'
) -> Dict:
    """
    è¿è¡Œç­–ç•¥å›æµ‹å¹¶è¿”å›ç»“æœ

    å‚æ•°:
        strategy_name: ç­–ç•¥åç§°
        signals: ä¿¡å·æ•°æ®
        prices: ä»·æ ¼æ•°æ®
        top_n: é€‰è‚¡æ•°é‡
        rebalance_freq: è°ƒä»“é¢‘ç‡

    è¿”å›:
        å›æµ‹ç»“æœå­—å…¸
    """
    logger.info(f"\nå›æµ‹ç­–ç•¥: {strategy_name}")

    engine = BacktestEngine(
        initial_capital=1000000,
        commission_rate=0.0003,
        stamp_tax_rate=0.001,
        slippage=0.001,
        verbose=False
    )

    results = engine.backtest_long_only(
        signals=signals,
        prices=prices,
        top_n=top_n,
        holding_period=5,
        rebalance_freq=rebalance_freq
    )

    analyzer = PerformanceAnalyzer(
        returns=results['daily_returns'],
        risk_free_rate=0.03
    )
    metrics = analyzer.calculate_all_metrics(verbose=False)
    cost_metrics = results['cost_analysis']

    logger.info(f"  å¹´åŒ–æ”¶ç›Š: {metrics['annualized_return']*100:.2f}%")
    logger.info(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.3f}")
    logger.info(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']*100:.2f}%")

    return {
        'name': strategy_name,
        'results': results,
        'metrics': metrics,
        'cost_metrics': cost_metrics
    }


def comparison1_momentum_vs_reversal():
    """
    å¯¹æ¯”1: åŠ¨é‡ç­–ç•¥ vs åè½¬ç­–ç•¥

    ç»å…¸å¯¹æ¯”ï¼šè¶‹åŠ¿è·Ÿéš vs å‡å€¼å›å½’
    """
    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”1: åŠ¨é‡ç­–ç•¥ vs åè½¬ç­–ç•¥")
    logger.info("="*80)

    logger.info("\nç­–ç•¥è¯´æ˜:")
    logger.info("  åŠ¨é‡ç­–ç•¥: ä¹°å…¥è¿‡å»è¡¨ç°å¥½çš„è‚¡ç¥¨ï¼ˆè¶‹åŠ¿è·Ÿéšï¼‰")
    logger.info("  åè½¬ç­–ç•¥: ä¹°å…¥è¿‡å»è¡¨ç°å·®çš„è‚¡ç¥¨ï¼ˆå‡å€¼å›å½’ï¼‰")

    # å‡†å¤‡æ•°æ®
    prices, features = create_sample_data(n_days=504, n_stocks=100)

    # åˆ›å»ºç­–ç•¥
    factory = StrategyFactory()

    strategies = [
        ('MOM20ï¼ˆ20æ—¥åŠ¨é‡ï¼‰', factory.momentum_strategy(features, lookback=20)),
        ('MOM60ï¼ˆ60æ—¥åŠ¨é‡ï¼‰', factory.momentum_strategy(features, lookback=60)),
        ('REV5ï¼ˆ5æ—¥åè½¬ï¼‰', factory.reversal_strategy(features, lookback=5)),
        ('REV10ï¼ˆ10æ—¥åè½¬ï¼‰', factory.reversal_strategy(features, lookback=10)),
    ]

    # å›æµ‹æ‰€æœ‰ç­–ç•¥
    backtest_results = []
    for name, signals in strategies:
        result = run_strategy_backtest(name, signals, prices, top_n=30, rebalance_freq='W')
        backtest_results.append(result)

    # å¯¹æ¯”ç»“æœ
    comparison = []
    for result in backtest_results:
        metrics = result['metrics']
        cost = result['cost_metrics']

        comparison.append({
            'ç­–ç•¥': result['name'],
            'å¹´åŒ–æ”¶ç›Š(%)': f"{metrics['annualized_return']*100:.2f}",
            'å¤æ™®æ¯”ç‡': f"{metrics['sharpe_ratio']:.3f}",
            'æœ€å¤§å›æ’¤(%)': f"{metrics['max_drawdown']*100:.2f}",
            'èƒœç‡(%)': f"{metrics['win_rate']*100:.1f}",
            'ç›ˆäºæ¯”': f"{metrics['profit_factor']:.2f}",
            'æˆæœ¬æ‹–ç´¯(%)': f"{cost['cost_drag']*100:.2f}"
        })

    comparison_df = pd.DataFrame(comparison)

    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”ç»“æœ:")
    logger.info("="*80)
    logger.info("\n" + comparison_df.to_string(index=False))

    logger.info("\nåˆ†æ:")
    logger.info("  åŠ¨é‡ç­–ç•¥ç‰¹ç‚¹:")
    logger.info("    - åœ¨è¶‹åŠ¿è¡Œæƒ…ä¸­è¡¨ç°å¥½")
    logger.info("    - å®¹æ˜“åœ¨éœ‡è¡å¸‚ä¸­é¢‘ç¹æ­¢æŸ")
    logger.info("    - é•¿å‘¨æœŸåŠ¨é‡ï¼ˆ60æ—¥ï¼‰æ›´ç¨³å®š")
    logger.info("  åè½¬ç­–ç•¥ç‰¹ç‚¹:")
    logger.info("    - åœ¨éœ‡è¡å¸‚ä¸­è¡¨ç°å¥½")
    logger.info("    - åœ¨å¼ºè¶‹åŠ¿ä¸­å®¹æ˜“é€†åŠ¿äºæŸ")
    logger.info("    - çŸ­å‘¨æœŸåè½¬ï¼ˆ5æ—¥ï¼‰æ³¢åŠ¨å¤§")

    logger.success("\nâœ“ å¯¹æ¯”1å®Œæˆ\n")

    return comparison_df


def comparison2_single_vs_multi_factor():
    """
    å¯¹æ¯”2: å•å› å­ç­–ç•¥ vs å¤šå› å­ç­–ç•¥

    æµ‹è¯•å› å­ç»„åˆçš„ä»·å€¼
    """
    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”2: å•å› å­ç­–ç•¥ vs å¤šå› å­ç­–ç•¥")
    logger.info("="*80)

    logger.info("\nç­–ç•¥è¯´æ˜:")
    logger.info("  å•å› å­: åªä½¿ç”¨ä¸€ä¸ªå› å­é€‰è‚¡")
    logger.info("  å¤šå› å­: ç»„åˆå¤šä¸ªå› å­ï¼Œåˆ†æ•£é£é™©")

    # å‡†å¤‡æ•°æ®
    prices, features = create_sample_data(n_days=504, n_stocks=100)

    factory = StrategyFactory()

    # å•å› å­ç­–ç•¥
    single_factor_strategies = [
        ('å•å› å­-åŠ¨é‡', factory.momentum_strategy(features, 20)),
        ('å•å› å­-åè½¬', factory.reversal_strategy(features, 5)),
        ('å•å› å­-ä½æ³¢', factory.low_volatility_strategy(features)),
    ]

    # å¤šå› å­ç­–ç•¥
    multi_factor_strategies = [
        ('å¤šå› å­-ç­‰æƒ', factory.multi_factor_strategy(
            features,
            ['MOM20', 'REV5', 'VOL20'],
            weights=[0.33, 0.33, 0.34]
        )),
        ('å¤šå› å­-åŠ¨é‡ä¸ºä¸»', factory.multi_factor_strategy(
            features,
            ['MOM20', 'MOM60', 'VOL20'],
            weights=[0.5, 0.3, 0.2]
        )),
        ('å¤šå› å­-ç»¼åˆ', factory.multi_factor_strategy(
            features,
            ['MOM20', 'MOM60', 'REV5', 'VOL20'],
            weights=[0.4, 0.3, 0.2, 0.1]
        )),
    ]

    # åˆå¹¶æ‰€æœ‰ç­–ç•¥
    all_strategies = single_factor_strategies + multi_factor_strategies

    # å›æµ‹
    backtest_results = []
    for name, signals in all_strategies:
        result = run_strategy_backtest(name, signals, prices, top_n=30, rebalance_freq='W')
        backtest_results.append(result)

    # å¯¹æ¯”ç»“æœ
    comparison = []
    for result in backtest_results:
        metrics = result['metrics']

        comparison.append({
            'ç­–ç•¥': result['name'],
            'ç±»å‹': 'å•å› å­' if 'å•å› å­' in result['name'] else 'å¤šå› å­',
            'å¹´åŒ–æ”¶ç›Š(%)': f"{metrics['annualized_return']*100:.2f}",
            'å¤æ™®æ¯”ç‡': f"{metrics['sharpe_ratio']:.3f}",
            'æœ€å¤§å›æ’¤(%)': f"{metrics['max_drawdown']*100:.2f}",
            'å¡ç›æ¯”ç‡': f"{metrics['calmar_ratio']:.3f}",
        })

    comparison_df = pd.DataFrame(comparison)

    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”ç»“æœ:")
    logger.info("="*80)
    logger.info("\n" + comparison_df.to_string(index=False))

    # åˆ†ç»„ç»Ÿè®¡
    logger.info("\nåˆ†ç»„ç»Ÿè®¡:")
    for strategy_type in ['å•å› å­', 'å¤šå› å­']:
        subset = comparison_df[comparison_df['ç±»å‹'] == strategy_type]
        sharpe_values = subset['å¤æ™®æ¯”ç‡'].astype(float)
        logger.info(f"  {strategy_type}:")
        logger.info(f"    å¹³å‡å¤æ™®: {sharpe_values.mean():.3f}")
        logger.info(f"    æœ€é«˜å¤æ™®: {sharpe_values.max():.3f}")

    logger.info("\nåˆ†æ:")
    logger.info("  å¤šå› å­ä¼˜åŠ¿:")
    logger.info("    âœ“ åˆ†æ•£å•å› å­å¤±æ•ˆé£é™©")
    logger.info("    âœ“ å¤æ™®æ¯”ç‡é€šå¸¸æ›´é«˜")
    logger.info("    âœ“ æœ€å¤§å›æ’¤æ§åˆ¶æ›´å¥½")
    logger.info("  å•å› å­ä¼˜åŠ¿:")
    logger.info("    âœ“ é€»è¾‘æ¸…æ™°ï¼Œæ˜“äºç†è§£")
    logger.info("    âœ“ åœ¨å› å­æœ‰æ•ˆæ—¶æ”¶ç›Šå¯èƒ½æ›´é«˜")
    logger.info("    âœ“ äº¤æ˜“æˆæœ¬å¯èƒ½æ›´ä½")

    logger.success("\nâœ“ å¯¹æ¯”2å®Œæˆ\n")

    return comparison_df


def comparison3_different_rebalance_freq():
    """
    å¯¹æ¯”3: ä¸åŒè°ƒä»“é¢‘ç‡ä¸‹çš„ç­–ç•¥è¡¨ç°

    åŒä¸€ç­–ç•¥ï¼Œä¸åŒæ‰§è¡Œé¢‘ç‡
    """
    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”3: ä¸åŒè°ƒä»“é¢‘ç‡çš„å½±å“")
    logger.info("="*80)

    logger.info("\nç›®æ ‡: æ‰¾åˆ°æœ€é€‚åˆç­–ç•¥çš„è°ƒä»“é¢‘ç‡")

    # å‡†å¤‡æ•°æ®
    prices, features = create_sample_data(n_days=504, n_stocks=100)

    factory = StrategyFactory()

    # é€‰æ‹©ä¸€ä¸ªå¤šå› å­ç­–ç•¥
    signals = factory.multi_factor_strategy(
        features,
        ['MOM20', 'REV5', 'VOL20'],
        weights=[0.5, 0.3, 0.2]
    )

    # æµ‹è¯•ä¸åŒé¢‘ç‡
    frequencies = {
        'D': 'æ¯æ—¥',
        'W': 'æ¯å‘¨',
        'M': 'æ¯æœˆ'
    }

    backtest_results = []
    for freq_code, freq_name in frequencies.items():
        logger.info(f"\næµ‹è¯• {freq_name}è°ƒä»“...")

        result = run_strategy_backtest(
            f"å¤šå› å­ç­–ç•¥-{freq_name}è°ƒä»“",
            signals,
            prices,
            top_n=30,
            rebalance_freq=freq_code
        )
        backtest_results.append(result)

    # å¯¹æ¯”ç»“æœ
    comparison = []
    for result in backtest_results:
        metrics = result['metrics']
        cost = result['cost_metrics']

        comparison.append({
            'è°ƒä»“é¢‘ç‡': result['name'].split('-')[1],
            'å¹´åŒ–æ”¶ç›Š(%)': f"{metrics['annualized_return']*100:.2f}",
            'å¤æ™®æ¯”ç‡': f"{metrics['sharpe_ratio']:.3f}",
            'æœ€å¤§å›æ’¤(%)': f"{metrics['max_drawdown']*100:.2f}",
            'äº¤æ˜“æˆæœ¬(å…ƒ)': f"{cost['total_cost']:,.0f}",
            'å¹´åŒ–æ¢æ‰‹': f"{cost['annual_turnover_rate']:.2f}",
            'æˆæœ¬æ‹–ç´¯(%)': f"{cost['cost_drag']*100:.2f}"
        })

    comparison_df = pd.DataFrame(comparison)

    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”ç»“æœ:")
    logger.info("="*80)
    logger.info("\n" + comparison_df.to_string(index=False))

    logger.info("\nç»“è®º:")
    logger.info("  é¢‘ç‡é€‰æ‹©å–å†³äº:")
    logger.info("    1. ä¿¡å·ç¨³å®šæ€§ï¼ˆç¨³å®šâ†’å¯é«˜é¢‘ï¼‰")
    logger.info("    2. æˆæœ¬æ‰¿å—åŠ›ï¼ˆä½ä½£é‡‘â†’å¯é«˜é¢‘ï¼‰")
    logger.info("    3. èµ„é‡‘å®¹é‡ï¼ˆå¤§èµ„é‡‘â†’ä½é¢‘ï¼‰")

    logger.success("\nâœ“ å¯¹æ¯”3å®Œæˆ\n")

    return comparison_df


def comparison4_portfolio_optimization():
    """
    å¯¹æ¯”4: ç­–ç•¥ç»„åˆä¼˜åŒ–

    ç»„åˆå¤šä¸ªç­–ç•¥ï¼Œé™ä½ç›¸å…³æ€§
    """
    logger.info("\n" + "="*80)
    logger.info("å¯¹æ¯”4: ç­–ç•¥ç»„åˆä¼˜åŒ–")
    logger.info("="*80)

    logger.info("\nç›®æ ‡: é€šè¿‡ç»„åˆä¸ç›¸å…³ç­–ç•¥ï¼Œæå‡æ•´ä½“è¡¨ç°")

    # å‡†å¤‡æ•°æ®
    prices, features = create_sample_data(n_days=504, n_stocks=100)

    factory = StrategyFactory()

    # åˆ›å»º3ä¸ªä½ç›¸å…³æ€§ç­–ç•¥
    strategies = [
        ('åŠ¨é‡ç­–ç•¥', factory.momentum_strategy(features, 20)),
        ('åè½¬ç­–ç•¥', factory.reversal_strategy(features, 5)),
        ('ä½æ³¢ç­–ç•¥', factory.low_volatility_strategy(features)),
    ]

    # å•ç‹¬å›æµ‹æ¯ä¸ªç­–ç•¥
    individual_results = []
    strategy_returns = {}

    for name, signals in strategies:
        result = run_strategy_backtest(name, signals, prices, top_n=20, rebalance_freq='W')
        individual_results.append(result)
        strategy_returns[name] = result['results']['daily_returns']

    # è®¡ç®—ç­–ç•¥ç›¸å…³æ€§
    logger.info("\nç­–ç•¥æ”¶ç›Šç‡ç›¸å…³æ€§:")
    returns_df = pd.DataFrame(strategy_returns)
    correlation = returns_df.corr()
    logger.info("\n" + correlation.to_string())

    # ç»„åˆç­–ç•¥ï¼ˆç­‰æƒé‡ç»„åˆæ”¶ç›Šï¼‰
    logger.info("\nåˆ›å»ºç»„åˆç­–ç•¥ï¼ˆç­‰æƒï¼‰...")
    combined_returns = returns_df.mean(axis=1)

    # åˆ†æç»„åˆç­–ç•¥
    combined_analyzer = PerformanceAnalyzer(
        returns=combined_returns,
        risk_free_rate=0.03
    )
    combined_metrics = combined_analyzer.calculate_all_metrics(verbose=False)

    # å¯¹æ¯”
    comparison = []

    # æ·»åŠ å•ç­–ç•¥
    for result in individual_results:
        metrics = result['metrics']
        comparison.append({
            'ç­–ç•¥': result['name'],
            'ç±»å‹': 'å•ç­–ç•¥',
            'å¹´åŒ–æ”¶ç›Š(%)': f"{metrics['annualized_return']*100:.2f}",
            'å¤æ™®æ¯”ç‡': f"{metrics['sharpe_ratio']:.3f}",
            'æœ€å¤§å›æ’¤(%)': f"{metrics['max_drawdown']*100:.2f}",
            'ç´¢æè¯ºæ¯”ç‡': f"{metrics['sortino_ratio']:.3f}"
        })

    # æ·»åŠ ç»„åˆç­–ç•¥
    comparison.append({
        'ç­–ç•¥': 'ç»„åˆç­–ç•¥ï¼ˆç­‰æƒï¼‰',
        'ç±»å‹': 'ç»„åˆ',
        'å¹´åŒ–æ”¶ç›Š(%)': f"{combined_metrics['annualized_return']*100:.2f}",
        'å¤æ™®æ¯”ç‡': f"{combined_metrics['sharpe_ratio']:.3f}",
        'æœ€å¤§å›æ’¤(%)': f"{combined_metrics['max_drawdown']*100:.2f}",
        'ç´¢æè¯ºæ¯”ç‡': f"{combined_metrics['sortino_ratio']:.3f}"
    })

    comparison_df = pd.DataFrame(comparison)

    logger.info("\n" + "="*80)
    logger.info("å•ç­–ç•¥ vs ç»„åˆç­–ç•¥:")
    logger.info("="*80)
    logger.info("\n" + comparison_df.to_string(index=False))

    logger.info("\nåˆ†æ:")
    logger.info("  ç»„åˆç­–ç•¥ä¼˜åŠ¿:")

    # æ£€æŸ¥ç»„åˆæ˜¯å¦ä¼˜äºå•ç­–ç•¥
    single_sharpes = [r['metrics']['sharpe_ratio'] for r in individual_results]
    avg_single_sharpe = np.mean(single_sharpes)
    combined_sharpe = combined_metrics['sharpe_ratio']

    if combined_sharpe > avg_single_sharpe:
        logger.info(f"    âœ“ å¤æ™®æ¯”ç‡ {combined_sharpe:.3f} > å•ç­–ç•¥å¹³å‡ {avg_single_sharpe:.3f}")
        logger.info("    âœ“ é€šè¿‡åˆ†æ•£åŒ–æå‡é£é™©è°ƒæ•´æ”¶ç›Š")
    else:
        logger.info(f"    âœ— å¤æ™®æ¯”ç‡æœªæå‡ï¼ˆå¯èƒ½ç­–ç•¥ç›¸å…³æ€§é«˜ï¼‰")

    logger.info("\nå»ºè®®:")
    logger.info("  1. é€‰æ‹©ç›¸å…³æ€§ < 0.5 çš„ç­–ç•¥ç»„åˆ")
    logger.info("  2. å¯ä»¥ä½¿ç”¨ä¼˜åŒ–æ–¹æ³•ç¡®å®šæƒé‡ï¼ˆéç­‰æƒï¼‰")
    logger.info("  3. å®šæœŸé‡æ–°è¯„ä¼°ç­–ç•¥ç›¸å…³æ€§")

    logger.success("\nâœ“ å¯¹æ¯”4å®Œæˆ\n")

    return comparison_df, correlation


def main():
    """è¿è¡Œæ‰€æœ‰å¯¹æ¯”åˆ†æ"""
    logger.info("\n" + "ğŸ“Š"*40)
    logger.info("å¤šç­–ç•¥å›æµ‹å¯¹æ¯”ç¤ºä¾‹")
    logger.info("ğŸ“Š"*40)

    try:
        # å¯¹æ¯”1: åŠ¨é‡ vs åè½¬
        comparison1 = comparison1_momentum_vs_reversal()

        # å¯¹æ¯”2: å•å› å­ vs å¤šå› å­
        comparison2 = comparison2_single_vs_multi_factor()

        # å¯¹æ¯”3: è°ƒä»“é¢‘ç‡å½±å“
        comparison3 = comparison3_different_rebalance_freq()

        # å¯¹æ¯”4: ç­–ç•¥ç»„åˆ
        comparison4, correlation = comparison4_portfolio_optimization()

        # æ€»ç»“
        logger.info("\n" + "="*80)
        logger.info("æ‰€æœ‰å¯¹æ¯”åˆ†æå®Œæˆï¼")
        logger.info("="*80)

        logger.info("\næ ¸å¿ƒå‘ç°:")
        logger.info("  1. åŠ¨é‡å’Œåè½¬ç­–ç•¥åœ¨ä¸åŒå¸‚åœºç¯å¢ƒä¸‹è¡¨ç°ä¸åŒ")
        logger.info("  2. å¤šå› å­ç­–ç•¥é€šå¸¸æ¯”å•å› å­æ›´ç¨³å®š")
        logger.info("  3. è°ƒä»“é¢‘ç‡å¯¹æˆæœ¬å’Œæ”¶ç›Šå½±å“æ˜¾è‘—")
        logger.info("  4. ä½ç›¸å…³æ€§ç­–ç•¥ç»„åˆå¯æå‡å¤æ™®æ¯”ç‡")

        logger.info("\nç­–ç•¥é€‰æ‹©å»ºè®®:")
        logger.info("  è¶‹åŠ¿å¸‚åœº â†’ åŠ¨é‡ç­–ç•¥ï¼ˆé•¿å‘¨æœŸï¼‰")
        logger.info("  éœ‡è¡å¸‚åœº â†’ åè½¬ç­–ç•¥æˆ–ä½æ³¢ç­–ç•¥")
        logger.info("  ä¸ç¡®å®šæ—¶ â†’ å¤šå› å­ç»„åˆç­–ç•¥")

        logger.info("\nå®æˆ˜æŠ€å·§:")
        logger.info("  âœ“ å§‹ç»ˆè¿›è¡Œå¤šç­–ç•¥å¯¹æ¯”")
        logger.info("  âœ“ å…³æ³¨é£é™©è°ƒæ•´æ”¶ç›Šï¼ˆå¤æ™®ï¼‰è€Œéç»å¯¹æ”¶ç›Š")
        logger.info("  âœ“ è€ƒè™‘äº¤æ˜“æˆæœ¬å¯¹é«˜é¢‘ç­–ç•¥çš„ä¾µèš€")
        logger.info("  âœ“ åˆ©ç”¨ç­–ç•¥ç»„åˆé™ä½å•ä¸€ç­–ç•¥é£é™©")

        logger.info("\nä¸‹ä¸€æ­¥:")
        logger.info("  1. åœ¨çœŸå®æ•°æ®ä¸ŠéªŒè¯ç­–ç•¥")
        logger.info("  2. ç»“åˆå¸‚åœºç¯å¢ƒåŠ¨æ€é€‰æ‹©ç­–ç•¥")
        logger.info("  3. æŒç»­ç›‘æ§ç­–ç•¥æœ‰æ•ˆæ€§")

        logger.success("\nâœ… ç­–ç•¥å¯¹æ¯”ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼\n")

        return 0

    except Exception as e:
        logger.error(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
