"""
LightGBMæ¨¡å‹ï¼ˆåŸºçº¿æ¨¡å‹ï¼‰
ç”¨äºè‚¡ç¥¨æ”¶ç›Šç‡é¢„æµ‹å’Œæ’å
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from typing import Optional, Dict, List, Tuple
import warnings
import pickle
from pathlib import Path
from loguru import logger

warnings.filterwarnings('ignore')


class LightGBMStockModel:
    """LightGBMè‚¡ç¥¨é¢„æµ‹æ¨¡å‹"""

    def __init__(
        self,
        objective: str = 'regression',
        metric: str = 'rmse',
        num_leaves: int = 15,
        learning_rate: float = 0.05,
        n_estimators: int = 500,
        max_depth: int = 4,
        min_child_samples: int = 30,
        subsample: float = 0.8,
        colsample_bytree: float = 0.6,
        reg_alpha: float = 0.1,
        reg_lambda: float = 0.1,
        random_state: int = 42,
        verbose: int = -1,
        use_gpu: bool = True,
        gpu_platform_id: int = 0,
        gpu_device_id: int = 0
    ):
        """
        åˆå§‹åŒ–LightGBMæ¨¡å‹ï¼ˆæ”¯æŒGPUåŠ é€Ÿï¼‰

        å‚æ•°:
            objective: ç›®æ ‡å‡½æ•° ('regression', 'lambdarank')
            metric: è¯„ä¼°æŒ‡æ ‡
            num_leaves: å¶å­èŠ‚ç‚¹æ•°
            learning_rate: å­¦ä¹ ç‡
            n_estimators: æ ‘çš„æ•°é‡
            max_depth: æœ€å¤§æ·±åº¦ (-1è¡¨ç¤ºä¸é™åˆ¶)
            min_child_samples: å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
            subsample: è¡Œé‡‡æ ·æ¯”ä¾‹
            colsample_bytree: åˆ—é‡‡æ ·æ¯”ä¾‹
            reg_alpha: L1æ­£åˆ™åŒ–ç³»æ•°
            reg_lambda: L2æ­£åˆ™åŒ–ç³»æ•°
            random_state: éšæœºç§å­
            verbose: è®­ç»ƒè¾“å‡ºè¯¦ç»†ç¨‹åº¦
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿï¼ˆé»˜è®¤Trueï¼‰
            gpu_platform_id: GPUå¹³å°IDï¼ˆé»˜è®¤0ï¼‰
            gpu_device_id: GPUè®¾å¤‡IDï¼ˆé»˜è®¤0ï¼‰
        """
        # å°è¯•å¯¼å…¥GPUç®¡ç†å™¨
        try:
            from src.utils.gpu_utils import gpu_manager
            gpu_available = gpu_manager.cuda_available
        except ImportError:
            gpu_available = False
            logger.warning("GPUç®¡ç†å™¨æœªå®‰è£…ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")

        # åŸºç¡€å‚æ•°
        self.params = {
            'objective': objective,
            'metric': metric,
            'num_leaves': num_leaves,
            'learning_rate': learning_rate,
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'min_child_samples': min_child_samples,
            'min_gain_to_split': 0.01,  # æ·»åŠ åˆ†è£‚å¢ç›Šé˜ˆå€¼ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            'subsample': subsample,
            'colsample_bytree': colsample_bytree,
            'reg_alpha': reg_alpha,
            'reg_lambda': reg_lambda,
            'random_state': random_state,
            'verbose': verbose,
        }

        # GPUé…ç½®
        self.use_gpu = use_gpu and gpu_available
        if self.use_gpu:
            try:
                # æ£€æŸ¥LightGBM GPUæ”¯æŒ
                from src.utils.gpu_utils import gpu_manager
                if gpu_manager.check_lightgbm_gpu():
                    self.params.update({
                        'device': 'gpu',
                        'gpu_platform_id': gpu_platform_id,
                        'gpu_device_id': gpu_device_id,
                        'gpu_use_dp': False,  # ä½¿ç”¨å•ç²¾åº¦
                    })
                    logger.info("ğŸš€ LightGBMå°†ä½¿ç”¨GPUè®­ç»ƒ")
                else:
                    self.use_gpu = False
                    self.params['force_col_wise'] = True
                    logger.warning("âš ï¸  LightGBM GPUä¸å¯ç”¨ï¼Œé™çº§ä¸ºCPUæ¨¡å¼")
            except Exception as e:
                logger.warning(f"GPUåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                self.use_gpu = False
                self.params['force_col_wise'] = True
        else:
            self.params['force_col_wise'] = True

        self.model = None
        self.feature_names = None
        self.feature_importance = None

    def train(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_valid: Optional[pd.DataFrame] = None,
        y_valid: Optional[pd.Series] = None,
        early_stopping_rounds: int = 50,
        verbose_eval: int = 50
    ) -> Dict:
        """
        è®­ç»ƒæ¨¡å‹

        å‚æ•°:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            X_valid: éªŒè¯ç‰¹å¾
            y_valid: éªŒè¯æ ‡ç­¾
            early_stopping_rounds: æ—©åœè½®æ•°
            verbose_eval: è®­ç»ƒè¾“å‡ºé—´éš”

        è¿”å›:
            è®­ç»ƒå†å²å­—å…¸
        """
        logger.info(f"\nå¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹...")
        logger.info(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ Ã— {len(X_train.columns)} ç‰¹å¾")

        # ä¿å­˜ç‰¹å¾å
        self.feature_names = list(X_train.columns)

        # åˆ›å»ºæ•°æ®é›†
        train_data = lgb.Dataset(X_train, label=y_train)

        # éªŒè¯é›†
        valid_sets = [train_data]
        valid_names = ['train']

        if X_valid is not None and y_valid is not None:
            valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)
            valid_sets.append(valid_data)
            valid_names.append('valid')
            logger.info(f"éªŒè¯é›†: {len(X_valid)} æ ·æœ¬")

        # è®­ç»ƒæ¨¡å‹
        callbacks = []
        if verbose_eval > 0:
            callbacks.append(lgb.log_evaluation(period=verbose_eval))
        if early_stopping_rounds > 0 and X_valid is not None:
            callbacks.append(lgb.early_stopping(stopping_rounds=early_stopping_rounds))

        self.model = lgb.train(
            self.params,
            train_data,
            valid_sets=valid_sets,
            valid_names=valid_names,
            callbacks=callbacks
        )

        # è®¡ç®—ç‰¹å¾é‡è¦æ€§
        self._compute_feature_importance()

        logger.success(f"âœ“ è®­ç»ƒå®Œæˆï¼Œæœ€ä½³è¿­ä»£: {self.model.best_iteration}")

        # è¿”å›è®­ç»ƒå†å²
        history = {
            'best_iteration': self.model.best_iteration,
            'best_score': self.model.best_score
        }

        return history

    def predict(
        self,
        X: pd.DataFrame,
        num_iteration: int = None
    ) -> np.ndarray:
        """
        é¢„æµ‹

        å‚æ•°:
            X: ç‰¹å¾DataFrame
            num_iteration: ä½¿ç”¨çš„è¿­ä»£æ¬¡æ•°ï¼ˆNoneè¡¨ç¤ºæœ€ä½³è¿­ä»£ï¼‰

        è¿”å›:
            é¢„æµ‹å€¼æ•°ç»„
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train()æ–¹æ³•")

        # æ£€æŸ¥ç‰¹å¾åæ˜¯å¦åŒ¹é…
        if list(X.columns) != self.feature_names:
            logger.warning("è­¦å‘Š: ç‰¹å¾åä¸åŒ¹é…ï¼Œå°è¯•é‡æ–°æ’åº...")
            X = X[self.feature_names]

        predictions = self.model.predict(
            X,
            num_iteration=num_iteration
        )

        return predictions

    def predict_rank(
        self,
        X: pd.DataFrame,
        num_iteration: int = None,
        ascending: bool = False
    ) -> np.ndarray:
        """
        é¢„æµ‹å¹¶è¿”å›æ’åï¼ˆç”¨äºé€‰è‚¡ï¼‰

        å‚æ•°:
            X: ç‰¹å¾DataFrame
            num_iteration: ä½¿ç”¨çš„è¿­ä»£æ¬¡æ•°
            ascending: æ˜¯å¦å‡åºæ’å

        è¿”å›:
            æ’åæ•°ç»„ï¼ˆ1è¡¨ç¤ºæœ€é«˜/æœ€ä½ï¼‰
        """
        predictions = self.predict(X, num_iteration)
        ranks = pd.Series(predictions).rank(ascending=ascending).values
        return ranks

    def _compute_feature_importance(self):
        """è®¡ç®—ç‰¹å¾é‡è¦æ€§"""
        if self.model is None:
            return

        importance_gain = self.model.feature_importance(importance_type='gain')
        importance_split = self.model.feature_importance(importance_type='split')

        self.feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'gain': importance_gain,
            'split': importance_split
        }).sort_values('gain', ascending=False)

    def get_feature_importance(
        self,
        importance_type: str = 'gain',
        top_n: int = None
    ) -> pd.DataFrame:
        """
        è·å–ç‰¹å¾é‡è¦æ€§

        å‚æ•°:
            importance_type: é‡è¦æ€§ç±»å‹ ('gain', 'split')
            top_n: è¿”å›å‰Nä¸ªé‡è¦ç‰¹å¾

        è¿”å›:
            ç‰¹å¾é‡è¦æ€§DataFrame
        """
        if self.feature_importance is None:
            raise ValueError("ç‰¹å¾é‡è¦æ€§æœªè®¡ç®—")

        df = self.feature_importance.copy()
        df = df.sort_values(importance_type, ascending=False)

        if top_n is not None:
            df = df.head(top_n)

        return df

    def plot_feature_importance(
        self,
        importance_type: str = 'gain',
        top_n: int = 20,
        figsize: tuple = (10, 8)
    ):
        """
        ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾

        å‚æ•°:
            importance_type: é‡è¦æ€§ç±»å‹
            top_n: æ˜¾ç¤ºå‰Nä¸ªç‰¹å¾
            figsize: å›¾ç‰‡å¤§å°
        """
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            logger.info("éœ€è¦å®‰è£…matplotlib: pip install matplotlib")
            return

        importance_df = self.get_feature_importance(importance_type, top_n)

        plt.figure(figsize=figsize)
        plt.barh(range(len(importance_df)), importance_df[importance_type])
        plt.yticks(range(len(importance_df)), importance_df['feature'])
        plt.xlabel(f'Feature Importance ({importance_type})')
        plt.title(f'Top {top_n} Important Features')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()

    def save_model(
        self,
        model_path: str,
        save_importance: bool = True
    ):
        """
        ä¿å­˜æ¨¡å‹

        å‚æ•°:
            model_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            save_importance: æ˜¯å¦ä¿å­˜ç‰¹å¾é‡è¦æ€§
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")

        model_path = Path(model_path)
        model_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æ¨¡å‹
        self.model.save_model(str(model_path))

        # ä¿å­˜ç‰¹å¾åå’Œå‚æ•°
        meta_path = model_path.with_suffix('.meta.pkl')
        meta_data = {
            'params': self.params,
            'feature_names': self.feature_names,
            'feature_importance': self.feature_importance if save_importance else None
        }

        with open(meta_path, 'wb') as f:
            pickle.dump(meta_data, f)

        logger.success(f"âœ“ æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
        logger.success(f"âœ“ å…ƒæ•°æ®å·²ä¿å­˜è‡³: {meta_path}")

    def load_model(
        self,
        model_path: str
    ):
        """
        åŠ è½½æ¨¡å‹

        å‚æ•°:
            model_path: æ¨¡å‹è·¯å¾„
        """
        model_path = Path(model_path)

        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        # åŠ è½½æ¨¡å‹
        self.model = lgb.Booster(model_file=str(model_path))

        # åŠ è½½å…ƒæ•°æ®
        meta_path = model_path.with_suffix('.meta.pkl')
        if meta_path.exists():
            with open(meta_path, 'rb') as f:
                meta_data = pickle.load(f)

            self.params = meta_data.get('params', self.params)
            self.feature_names = meta_data.get('feature_names')
            self.feature_importance = meta_data.get('feature_importance')

        logger.success(f"âœ“ æ¨¡å‹å·²åŠ è½½: {model_path}")

    def get_params(self) -> dict:
        """è·å–æ¨¡å‹å‚æ•°"""
        return self.params.copy()

    def auto_tune(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_valid: pd.DataFrame,
        y_valid: pd.Series,
        param_grid: Optional[Dict] = None,
        metric: str = 'ic',
        n_trials: int = 20,
        method: str = 'grid'
    ) -> Tuple['LightGBMStockModel', Dict]:
        """
        è‡ªåŠ¨è°ƒä¼˜è¶…å‚æ•°

        å‚æ•°:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            X_valid: éªŒè¯ç‰¹å¾
            y_valid: éªŒè¯æ ‡ç­¾
            param_grid: å‚æ•°æœç´¢ç©ºé—´ï¼ˆNone=ä½¿ç”¨é»˜è®¤ï¼‰
            metric: ä¼˜åŒ–æŒ‡æ ‡ ('ic', 'rank_ic', 'mse')
            n_trials: æœç´¢æ¬¡æ•°
            method: æœç´¢æ–¹æ³• ('grid', 'random')

        è¿”å›:
            (best_model, results): æœ€ä½³æ¨¡å‹å’Œè°ƒä¼˜ç»“æœ
        """
        from itertools import product
        import random

        logger.info(f"å¼€å§‹è‡ªåŠ¨è°ƒä¼˜ (æ–¹æ³•={method}, æŒ‡æ ‡={metric})...")

        # é»˜è®¤æœç´¢ç©ºé—´
        if param_grid is None:
            param_grid = {
                'learning_rate': [0.03, 0.05, 0.1],
                'num_leaves': [15, 31, 63],
                'max_depth': [3, 5, 7],
                'n_estimators': [100, 200],
                'min_child_samples': [20, 30]
            }

        # ç”Ÿæˆå‚æ•°ç»„åˆ
        keys = list(param_grid.keys())
        values = list(param_grid.values())

        if method == 'grid':
            # ç½‘æ ¼æœç´¢ï¼šæ‰€æœ‰ç»„åˆ
            param_combinations = [dict(zip(keys, v)) for v in product(*values)]
            logger.info(f"ç½‘æ ¼æœç´¢: {len(param_combinations)} ç§ç»„åˆ")
        else:
            # éšæœºæœç´¢ï¼šéšæœºé‡‡æ ·
            all_combinations = [dict(zip(keys, v)) for v in product(*values)]
            param_combinations = random.sample(
                all_combinations,
                min(n_trials, len(all_combinations))
            )
            logger.info(f"éšæœºæœç´¢: {len(param_combinations)} ç§ç»„åˆ")

        best_score = -float('inf') if metric != 'mse' else float('inf')
        best_params = None
        best_model = None
        all_results = []

        for i, params in enumerate(param_combinations, 1):
            # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
            model = LightGBMStockModel(**params, random_state=42, verbose=-1)
            model.train(X_train, y_train, X_valid, y_valid, verbose_eval=0)

            # è¯„ä¼°
            y_pred = model.predict(X_valid)
            score = self._calculate_metric(y_valid, y_pred, metric)

            all_results.append({'params': params, 'score': score})

            # æ›´æ–°æœ€ä½³
            is_better = (score > best_score) if metric != 'mse' else (score < best_score)
            if is_better:
                best_score = score
                best_params = params
                best_model = model

            if i % 5 == 0:
                logger.info(f"è¿›åº¦: {i}/{len(param_combinations)}, æœ€ä½³{metric}={best_score:.6f}")

        logger.info(f"âœ“ è°ƒä¼˜å®Œæˆï¼æœ€ä½³{metric}={best_score:.6f}")
        logger.info(f"æœ€ä½³å‚æ•°: {best_params}")

        return best_model, {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }

    def _calculate_metric(self, y_true: pd.Series, y_pred: np.ndarray, metric: str) -> float:
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        if metric == 'ic':
            return np.corrcoef(y_true, y_pred)[0, 1]
        elif metric == 'rank_ic':
            return pd.Series(y_true.values).corr(pd.Series(y_pred), method='spearman')
        elif metric == 'mse':
            return np.mean((y_true - y_pred) ** 2)
        else:
            raise ValueError(f"æœªçŸ¥æŒ‡æ ‡: {metric}")


# ==================== ä¾¿æ·å‡½æ•° ====================

def train_lightgbm_model(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    X_valid: pd.DataFrame = None,
    y_valid: pd.Series = None,
    params: dict = None,
    early_stopping_rounds: int = 50
) -> LightGBMStockModel:
    """
    ä¾¿æ·å‡½æ•°ï¼šè®­ç»ƒLightGBMæ¨¡å‹

    å‚æ•°:
        X_train: è®­ç»ƒç‰¹å¾
        y_train: è®­ç»ƒæ ‡ç­¾
        X_valid: éªŒè¯ç‰¹å¾
        y_valid: éªŒè¯æ ‡ç­¾
        params: æ¨¡å‹å‚æ•°å­—å…¸
        early_stopping_rounds: æ—©åœè½®æ•°

    è¿”å›:
        è®­ç»ƒå¥½çš„æ¨¡å‹
    """
    # é»˜è®¤å‚æ•°
    default_params = {
        'objective': 'regression',
        'metric': 'rmse',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'n_estimators': 500,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42
    }

    if params:
        default_params.update(params)

    # åˆ›å»ºæ¨¡å‹
    model = LightGBMStockModel(**default_params)

    # è®­ç»ƒæ¨¡å‹
    model.train(
        X_train, y_train,
        X_valid, y_valid,
        early_stopping_rounds=early_stopping_rounds
    )

    return model


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    logger.info("LightGBMæ¨¡å‹æµ‹è¯•\n")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    n_samples = 1000
    n_features = 20

    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )

    # æ¨¡æ‹Ÿè‚¡ç¥¨æ”¶ç›Šç‡ï¼ˆå¸¦å™ªå£°ï¼‰
    y = (
        X['feature_0'] * 0.5 +
        X['feature_1'] * 0.3 +
        X['feature_2'] * -0.2 +
        np.random.randn(n_samples) * 0.1
    )

    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    split_idx = int(n_samples * 0.8)
    X_train, X_valid = X[:split_idx], X[split_idx:]
    y_train, y_valid = y[:split_idx], y[split_idx:]

    logger.info("æ•°æ®å‡†å¤‡:")
    logger.info(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    logger.info(f"  éªŒè¯é›†: {len(X_valid)} æ ·æœ¬")
    logger.info(f"  ç‰¹å¾æ•°: {len(X.columns)}")

    # è®­ç»ƒæ¨¡å‹
    logger.info("\nè®­ç»ƒLightGBMæ¨¡å‹:")
    model = LightGBMStockModel(
        objective='regression',
        learning_rate=0.1,
        n_estimators=100,
        num_leaves=31,
        verbose=-1
    )

    history = model.train(
        X_train, y_train,
        X_valid, y_valid,
        early_stopping_rounds=10,
        verbose_eval=20
    )

    # é¢„æµ‹
    logger.info("\né¢„æµ‹:")
    y_pred_train = model.predict(X_train)
    y_pred_valid = model.predict(X_valid)

    # è®¡ç®—æŒ‡æ ‡
    from sklearn.metrics import mean_squared_error, r2_score

    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
    valid_rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))
    train_r2 = r2_score(y_train, y_pred_train)
    valid_r2 = r2_score(y_valid, y_pred_valid)

    logger.info(f"\nè®­ç»ƒé›† RMSE: {train_rmse:.4f}, RÂ²: {train_r2:.4f}")
    logger.info(f"éªŒè¯é›† RMSE: {valid_rmse:.4f}, RÂ²: {valid_r2:.4f}")

    # ç‰¹å¾é‡è¦æ€§
    logger.info("\nç‰¹å¾é‡è¦æ€§ (Top 10):")
    importance_df = model.get_feature_importance('gain', top_n=10)
    logger.info(f"{importance_df}")

    # ä¿å­˜å’ŒåŠ è½½æ¨¡å‹
    logger.info("\nä¿å­˜æ¨¡å‹:")
    model.save_model('test_lgb_model.txt')

    logger.info("\nåŠ è½½æ¨¡å‹:")
    new_model = LightGBMStockModel()
    new_model.load_model('test_lgb_model.txt')

    y_pred_new = new_model.predict(X_valid)
    logger.info(f"åŠ è½½åé¢„æµ‹ä¸€è‡´æ€§: {np.allclose(y_pred_valid, y_pred_new)}")

    logger.success("\nâœ“ LightGBMæ¨¡å‹æµ‹è¯•å®Œæˆ")
