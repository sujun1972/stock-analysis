# å¸¸è§é—®é¢˜

**Frequently Asked Questions for Stock-Analysis Core**

**ç‰ˆæœ¬**: v3.0.0
**æœ€åæ›´æ–°**: 2026-02-01

---

## ğŸ“‹ ç›®å½•

- [å®‰è£…ä¸é…ç½®](#å®‰è£…ä¸é…ç½®)
- [æ•°æ®è·å–](#æ•°æ®è·å–)
- [ç‰¹å¾è®¡ç®—](#ç‰¹å¾è®¡ç®—)
- [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
- [ç­–ç•¥å›æµ‹](#ç­–ç•¥å›æµ‹)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [é”™è¯¯æ’æŸ¥](#é”™è¯¯æ’æŸ¥)
- [è¿›é˜¶ä½¿ç”¨](#è¿›é˜¶ä½¿ç”¨)

---

## å®‰è£…ä¸é…ç½®

### Q1: æ”¯æŒå“ªäº›Pythonç‰ˆæœ¬ï¼Ÿ

**A**: æ¨èä½¿ç”¨ **Python 3.9 æˆ– 3.10**ã€‚

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # åº”æ˜¾ç¤º Python 3.9.x æˆ– 3.10.x

# å¦‚æœç‰ˆæœ¬ä¸ç¬¦ï¼Œå»ºè®®ä½¿ç”¨pyenvå®‰è£…
pyenv install 3.10.13
pyenv global 3.10.13
```

**ä¸æ”¯æŒ**:
- Python 3.8åŠä»¥ä¸‹ï¼ˆpandas 2.0éœ€è¦3.9+ï¼‰
- Python 3.11+ï¼ˆéƒ¨åˆ†ä¾èµ–åŒ…å¯èƒ½ä¸å…¼å®¹ï¼‰

---

### Q2: pip installå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: å¸¸è§è§£å†³æ–¹æ¡ˆï¼š

```bash
# æ–¹æ¡ˆ1: å‡çº§pip
pip install --upgrade pip setuptools wheel

# æ–¹æ¡ˆ2: ä½¿ç”¨å›½å†…é•œåƒï¼ˆæ¨èï¼‰
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# æ–¹æ¡ˆ3: æ¸…é™¤ç¼“å­˜é‡è£…
pip install --no-cache-dir -r requirements.txt

# æ–¹æ¡ˆ4: å•ç‹¬å®‰è£…é—®é¢˜åŒ…
pip install pandas==2.0.0 --no-cache-dir
```

**å¸¸è§é—®é¢˜åŒ…**:
- **TA-Lib**: éœ€è¦å…ˆå®‰è£…Cåº“ï¼ˆè§Q3ï¼‰
- **PyTorch**: é€‰æ‹©æ­£ç¡®çš„CUDAç‰ˆæœ¬ï¼ˆè§Q4ï¼‰
- **psycopg2**: ä½¿ç”¨ `psycopg2-binary` æ›¿ä»£

---

### Q3: TA-Libå®‰è£…å¤±è´¥ï¼Ÿ

**A**: TA-Libéœ€è¦å…ˆå®‰è£…Cè¯­è¨€åº“ï¼š

**macOS**:
```bash
brew install ta-lib
pip install ta-lib
```

**Linux (Ubuntu/Debian)**:
```bash
# ä¸‹è½½å¹¶ç¼–è¯‘
wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz
tar -xzf ta-lib-0.4.0-src.tar.gz
cd ta-lib/
./configure --prefix=/usr
make
sudo make install

# å®‰è£…PythonåŒ…
pip install ta-lib
```

**Windows**:
```bash
# ä¸‹è½½é¢„ç¼–è¯‘åŒ…
# è®¿é—®: https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib

# å®‰è£…ï¼ˆæ›¿æ¢ä¸ºå®é™…æ–‡ä»¶åï¼‰
pip install TA_Libâ€‘0.4.28â€‘cp310â€‘cp310â€‘win_amd64.whl
```

---

### Q4: å¦‚ä½•å®‰è£…GPUç‰ˆæœ¬çš„PyTorchï¼Ÿ

**A**: æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©ï¼š

```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi  # æŸ¥çœ‹CUDA Version

# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPUç‰ˆæœ¬ï¼ˆæ— GPUï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# éªŒè¯GPUå¯ç”¨æ€§
python -c "import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}')"
```

---

### Q5: æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Ÿ

**A**: é€æ­¥æ’æŸ¥ï¼š

**1. æ£€æŸ¥PostgreSQLæ˜¯å¦å¯åŠ¨**:
```bash
# macOS
brew services list | grep postgresql

# Linux
sudo systemctl status postgresql

# å¯åŠ¨æœåŠ¡
brew services start postgresql  # macOS
sudo systemctl start postgresql  # Linux
```

**2. æ£€æŸ¥ç«¯å£**:
```bash
netstat -an | grep 5432
# åº”æ˜¾ç¤º LISTEN çŠ¶æ€
```

**3. æ£€æŸ¥é…ç½®æ–‡ä»¶**:
```yaml
# config/database.yaml
database:
  timescaledb:
    host: localhost  # â† æ£€æŸ¥æ˜¯å¦æ­£ç¡®
    port: 5432
    database: stock_analysis
    user: postgres
    password: yourpassword  # â† æ£€æŸ¥å¯†ç 
```

**4. æµ‹è¯•è¿æ¥**:
```bash
# å‘½ä»¤è¡Œè¿æ¥æµ‹è¯•
psql -h localhost -U postgres -d stock_analysis

# Pythonæµ‹è¯•
python -c "from src.data.database_manager import DatabaseManager; db = DatabaseManager(); print(db.test_connection())"
```

**5. å¸¸è§é”™è¯¯**:
- `connection refused`: PostgreSQLæœªå¯åŠ¨
- `authentication failed`: å¯†ç é”™è¯¯
- `database does not exist`: éœ€å…ˆåˆ›å»ºæ•°æ®åº“
  ```bash
  createdb stock_analysis
  ```

---

## æ•°æ®è·å–

### Q6: å¦‚ä½•è·å–å…è´¹çš„Aè‚¡æ•°æ®ï¼Ÿ

**A**: æ¨èä½¿ç”¨ **AkShare**ï¼ˆå®Œå…¨å…è´¹ï¼‰:

```python
from src.providers import DataProviderFactory

# åˆ›å»ºAkShareæä¾›è€…
provider = DataProviderFactory.create_provider('akshare')

# è·å–æ—¥çº¿æ•°æ®
data = provider.get_daily_data(
    stock_code='000001.SZ',
    start_date='2023-01-01',
    end_date='2023-12-31'
)

print(f"è·å–äº† {len(data)} æ¡æ•°æ®")
```

**ä¼˜ç‚¹**:
- âœ… å®Œå…¨å…è´¹ï¼Œæ— éœ€æ³¨å†Œ
- âœ… è¦†ç›–Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡
- âœ… æ•°æ®æ›´æ–°åŠæ—¶

**æ³¨æ„äº‹é¡¹**:
- æœ‰é¢‘ç‡é™åˆ¶ï¼ˆçº¦10æ¬¡/ç§’ï¼‰
- å†å²æ•°æ®å¯èƒ½æœ‰å»¶è¿Ÿ

---

### Q7: Tushareæ•°æ®è·å–å¤±è´¥ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š

**1. ç¡®è®¤Tokenæœ‰æ•ˆ**:
```python
# è®¿é—® https://tushare.pro æ³¨å†Œå¹¶è·å–Token

# è®¾ç½®Token
import tushare as ts
ts.set_token('YOUR_TOKEN_HERE')

# æµ‹è¯•
pro = ts.pro_api()
df = pro.daily(ts_code='000001.SZ', start_date='20230101', end_date='20231231')
print(len(df))
```

**2. æ£€æŸ¥ç§¯åˆ†é™åˆ¶**:
- Tushareæ ¹æ®ç§¯åˆ†é™åˆ¶æ¥å£è°ƒç”¨é¢‘ç‡
- è®¿é—® [ä¸ªäººä¸­å¿ƒ](https://tushare.pro/user/token) æŸ¥çœ‹ç§¯åˆ†

**3. é…ç½®æ–‡ä»¶**:
```yaml
# config/data_sources.yaml
data_sources:
  tushare:
    enabled: true
    token: "YOUR_TOKEN"  # â† æ›¿æ¢ä¸ºçœŸå®Token
    rate_limit: 200
```

---

### Q8: å¦‚ä½•ä¸‹è½½æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®ï¼Ÿ

**A**: ä½¿ç”¨å†…ç½®å·¥å…·ï¼š

```python
from src.utils.stock_utils import get_index_components
from src.providers import DataProviderFactory

# è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨
hs300_codes = get_index_components('000300.SH')
print(f"æ²ªæ·±300æˆåˆ†è‚¡æ•°é‡: {len(hs300_codes)}")

# æ‰¹é‡ä¸‹è½½
provider = DataProviderFactory.create_provider('akshare')

for code in hs300_codes:
    try:
        data = provider.get_daily_data(code, '2023-01-01', '2023-12-31')
        print(f"âœ… {code}: {len(data)} æ¡æ•°æ®")
    except Exception as e:
        print(f"âŒ {code}: {e}")
```

**å…¶ä»–æŒ‡æ•°**:
- ä¸Šè¯50: `'000016.SH'`
- ä¸­è¯500: `'000905.SH'`
- åˆ›ä¸šæ¿æŒ‡: `'399006.SZ'`

---

### Q9: æ•°æ®æœ‰ç¼ºå¤±å€¼æ€ä¹ˆåŠï¼Ÿ

**A**: ä½¿ç”¨æ•°æ®æ¸…æ´—å·¥å…·ï¼š

```python
from src.data.data_cleaner import DataCleaner

cleaner = DataCleaner()

# æ–¹æ³•1: å‰å‘å¡«å……ï¼ˆæ¨èï¼‰
data_filled = cleaner.forward_fill(data)

# æ–¹æ³•2: çº¿æ€§æ’å€¼
data_interpolated = cleaner.interpolate(data, method='linear')

# æ–¹æ³•3: åˆ é™¤ç¼ºå¤±å€¼ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
data_dropped = cleaner.drop_missing(data, threshold=0.1)  # ç¼ºå¤±>10%åˆ é™¤

# æ–¹æ³•4: ä½¿ç”¨å‡å€¼å¡«å……
data_mean = cleaner.fill_with_mean(data)
```

---

## ç‰¹å¾è®¡ç®—

### Q10: å¦‚ä½•åŠ é€Ÿç‰¹å¾è®¡ç®—ï¼Ÿ

**A**: å¤šç§ä¼˜åŒ–æ–¹æ³•ï¼š

**æ–¹æ³•1: ä½¿ç”¨å‘é‡åŒ–**:
```python
# âŒ æ…¢é€Ÿï¼ˆå¾ªç¯ï¼‰
momentum = []
for i in range(len(prices)):
    if i >= 20:
        momentum.append(prices[i] / prices[i-20] - 1)
    else:
        momentum.append(np.nan)

# âœ… å¿«é€Ÿï¼ˆå‘é‡åŒ–ï¼‰
momentum = prices / prices.shift(20) - 1  # 11å€åŠ é€Ÿ
```

**æ–¹æ³•2: å¹¶è¡Œè®¡ç®—**:
```python
from src.features import AlphaFactors

# ä½¿ç”¨å¤šæ ¸
alpha = AlphaFactors(data, n_jobs=4)  # ä½¿ç”¨4ä¸ªCPUæ ¸å¿ƒ
features = alpha.calculate_all_alpha_factors()
```

**æ–¹æ³•3: ç¼“å­˜ç»“æœ**:
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_features(stock_code, start_date):
    return calculate_features(stock_code, start_date)

# ç¬¬äºŒæ¬¡è°ƒç”¨ç›´æ¥ä»ç¼“å­˜è¯»å–
features = cached_features('000001.SZ', '2023-01-01')
```

**æ–¹æ³•4: ä½¿ç”¨Parquetæ ¼å¼**:
```python
# ä¿å­˜
features.to_parquet('features.parquet')  # æ¯”CSVå¿«5-10å€

# è¯»å–
features = pd.read_parquet('features.parquet')
```

---

### Q11: ç‰¹å¾è®¡ç®—å‡ºç°NaNï¼Ÿ

**A**: è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œè§£å†³æ–¹æ³•ï¼š

**åŸå› **: æ»šåŠ¨çª—å£è®¡ç®—å‰æœŸä¸è¶³

```python
# ä¾‹å¦‚ï¼š20æ—¥åŠ¨é‡å› å­
momentum_20 = prices / prices.shift(20) - 1
# å‰20è¡Œä¸ºNaNï¼ˆæ•°æ®ä¸è¶³ï¼‰

# è§£å†³æ–¹æ¡ˆ1: åˆ é™¤NaNè¡Œ
features = features.dropna()

# è§£å†³æ–¹æ¡ˆ2: å‰å‘å¡«å……
features = features.fillna(method='ffill')

# è§£å†³æ–¹æ¡ˆ3: è®¾ç½®min_periods
momentum_20 = prices.pct_change(periods=20, fill_method=None)
```

**å»ºè®®**:
- è®­ç»ƒæ¨¡å‹æ—¶åˆ é™¤NaN
- å®ç›˜ä½¿ç”¨æ—¶å‰å‘å¡«å……

---

### Q12: å¦‚ä½•é€‰æ‹©æœ€æœ‰æ•ˆçš„å› å­ï¼Ÿ

**A**: ä½¿ç”¨å› å­åˆ†æå·¥å…·ï¼š

```python
from src.analysis import ICCalculator, FactorAnalyzer

# 1. è®¡ç®—ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰
ic_calc = ICCalculator()
ic_results = ic_calc.calculate_ic(factors, returns)

# æŸ¥çœ‹ICå€¼
print(ic_results.sort_values('mean_ic', ascending=False))

# 2. é€‰æ‹©é«˜ICå› å­
good_factors = ic_results[ic_results['mean_ic'] > 0.05]
print(f"æœ‰æ•ˆå› å­: {len(good_factors)}/{len(ic_results)}")

# 3. å› å­ä¼˜åŒ–
analyzer = FactorAnalyzer()
best_factors = analyzer.select_best_factors(
    factors,
    returns,
    method='forward',  # å‰å‘é€æ­¥é€‰æ‹©
    max_factors=20
)
```

**ICå€¼å‚è€ƒ**:
- IC > 0.05: è¾ƒå¥½
- IC > 0.08: ä¼˜ç§€
- IC > 0.10: éå¸¸ä¼˜ç§€

---

## æ¨¡å‹è®­ç»ƒ

### Q13: æ¨¡å‹è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: ä¼˜åŒ–å»ºè®®ï¼š

**1. ä½¿ç”¨GPU**:
```python
config = TrainingConfig(
    model_type='gru',
    use_gpu=True  # å¯ç”¨GPUï¼ˆ20å€åŠ é€Ÿï¼‰
)
```

**2. å‡å°‘ç‰¹å¾æ•°é‡**:
```python
# ä½¿ç”¨ç‰¹å¾é€‰æ‹©
from sklearn.feature_selection import SelectKBest, f_regression

selector = SelectKBest(f_regression, k=50)  # é€‰æ‹©å‰50ä¸ªç‰¹å¾
X_selected = selector.fit_transform(X, y)
```

**3. å‡å°‘æ ·æœ¬æ•°é‡**:
```python
# é‡‡æ ·è®­ç»ƒ
X_sample = X.sample(frac=0.5, random_state=42)  # ä½¿ç”¨50%æ ·æœ¬
```

**4. è°ƒæ•´è¶…å‚æ•°**:
```python
config = TrainingConfig(
    model_type='lightgbm',
    hyperparameters={
        'n_estimators': 50,  # å‡å°‘æ ‘çš„æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        'max_depth': 3       # å‡å°æ ‘æ·±åº¦ï¼ˆé»˜è®¤5ï¼‰
    }
)
```

---

### Q14: æ¨¡å‹è¿‡æ‹Ÿåˆæ€ä¹ˆåŠï¼Ÿ

**A**: é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼š

**1. äº¤å‰éªŒè¯**:
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"äº¤å‰éªŒè¯RÂ²: {scores.mean():.4f} Â± {scores.std():.4f}")
```

**2. æ­£åˆ™åŒ–**:
```python
config = TrainingConfig(
    model_type='lightgbm',
    hyperparameters={
        'reg_alpha': 0.1,  # L1æ­£åˆ™åŒ–
        'reg_lambda': 0.1  # L2æ­£åˆ™åŒ–
    }
)
```

**3. Early Stopping**:
```python
config = TrainingConfig(
    model_type='lightgbm',
    hyperparameters={
        'early_stopping_rounds': 50  # 50è½®æ— æå‡åˆ™åœæ­¢
    }
)
```

**4. ç‰¹å¾å·¥ç¨‹**:
```python
# åˆ é™¤é«˜ç›¸å…³ç‰¹å¾
corr_matrix = features.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]
features = features.drop(columns=to_drop)
```

---

### Q15: å¦‚ä½•è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Ÿ

**A**: å¤šç»´åº¦è¯„ä¼°ï¼š

```python
from src.models.model_trainer import ModelTrainer

trainer = ModelTrainer(config)
# ... è®­ç»ƒæ¨¡å‹ ...

# è¯„ä¼°
eval_response = trainer.evaluate(X_test, y_test)
metrics = eval_response.data

print(f"RÂ²: {metrics['r2']:.4f}")      # æ‹Ÿåˆä¼˜åº¦
print(f"MSE: {metrics['mse']:.6f}")    # å‡æ–¹è¯¯å·®
print(f"MAE: {metrics['mae']:.6f}")    # å¹³å‡ç»å¯¹è¯¯å·®
print(f"IC: {metrics['ic']:.4f}")      # ä¿¡æ¯ç³»æ•°
```

**æŒ‡æ ‡å‚è€ƒ**:
- **RÂ²**: >0.05ï¼ˆé‡‘èæ•°æ®ï¼‰
- **IC**: >0.05ï¼ˆæœ‰é¢„æµ‹èƒ½åŠ›ï¼‰
- **MSE**: è¶Šå°è¶Šå¥½

**é‡è¦**: é‡‘èæ•°æ®RÂ²æ™®éè¾ƒä½ï¼ˆ0.05-0.15ï¼‰ï¼Œä¸è¦æœŸæœ›è¾¾åˆ°0.9+

---

## ç­–ç•¥å›æµ‹

### Q16: å›æµ‹ç»“æœå¤ªå¥½ï¼Œæ˜¯å¦è¿‡æ‹Ÿåˆï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š

**1. æœªæ¥æ•°æ®æ³„æ¼**:
```python
# âŒ é”™è¯¯ï¼šä½¿ç”¨äº†æœªæ¥æ•°æ®
signals = data['close'].shift(-1) > data['close']  # ä½¿ç”¨äº†æ˜å¤©çš„æ•°æ®

# âœ… æ­£ç¡®ï¼šåªä½¿ç”¨å†å²æ•°æ®
signals = data['close'].shift(1) > data['close'].shift(2)
```

**2. äº¤æ˜“æˆæœ¬**:
```python
# âœ… ç¡®ä¿åŒ…å«çœŸå®æˆæœ¬
engine = BacktestEngine(
    commission_rate=0.0003,  # ä¸‡3ä½£é‡‘
    slippage_rate=0.001,     # 0.1%æ»‘ç‚¹
    stamp_tax_rate=0.001     # 0.1%å°èŠ±ç¨ï¼ˆå–å‡ºï¼‰
)
```

**3. æ ·æœ¬å¤–æµ‹è¯•**:
```python
# è®­ç»ƒé›†ï¼š2020-2022
# æµ‹è¯•é›†ï¼š2023ï¼ˆæ ·æœ¬å¤–ï¼‰
train_data = data[data['date'] < '2023-01-01']
test_data = data[data['date'] >= '2023-01-01']
```

**4. æ»šåŠ¨å›æµ‹**:
```python
from src.analysis import RollingBacktest

roller = RollingBacktest(window_size=252, step_size=63)
results = roller.run(strategy, data)
```

---

### Q17: å¦‚ä½•è®¾ç½®åˆç†çš„äº¤æ˜“æˆæœ¬ï¼Ÿ

**A**: Aè‚¡å¸‚åœºå‚è€ƒï¼š

```python
engine = BacktestEngine(
    # ä½£é‡‘ï¼ˆåŒå‘ï¼‰
    commission_rate=0.0003,  # ä¸‡3ï¼ˆæ•£æˆ·æ™®éæ°´å¹³ï¼‰
                             # ä¸‡2.5ï¼ˆæ´»è·ƒè´¦æˆ·ï¼‰
                             # ä¸‡1ï¼ˆæœºæ„æˆ–å¤§èµ„é‡‘ï¼‰

    # å°èŠ±ç¨ï¼ˆä»…å–å‡ºï¼‰
    stamp_tax_rate=0.001,    # åƒ1ï¼ˆå›ºå®šï¼‰

    # æ»‘ç‚¹
    slippage_rate=0.001,     # 0.1%ï¼ˆæµåŠ¨æ€§å¥½çš„å¤§ç›˜è‚¡ï¼‰
                             # 0.2-0.5%ï¼ˆå°ç›˜è‚¡æˆ–ç§‘åˆ›æ¿ï¼‰

    # å…¶ä»–è´¹ç”¨
    min_commission=5         # æœ€ä½ä½£é‡‘5å…ƒ
)
```

**æ€»æˆæœ¬ä¼°ç®—**:
- ä¹°å…¥ï¼š0.03% + 0.1% = 0.13%
- å–å‡ºï¼š0.03% + 0.1% + 0.1% = 0.23%
- **å•æ¬¡å¾€è¿”**: ~0.36%

---

### Q18: å¦‚ä½•è¯„ä¼°ç­–ç•¥çš„ç¨³å®šæ€§ï¼Ÿ

**A**: å¤šè§’åº¦è¯„ä¼°ï¼š

**1. æ»šåŠ¨å›æµ‹**:
```python
from src.analysis import RollingBacktest

roller = RollingBacktest(
    window_size=252,  # 1å¹´çª—å£
    step_size=63      # æ¯å­£åº¦æ»šåŠ¨
)

results = roller.run(strategy, data)
roller.plot_rolling_sharpe(results)  # æŸ¥çœ‹å¤æ™®æ¯”ç‡å˜åŒ–
```

**2. åˆ†æ—¶æ®µåˆ†æ**:
```python
# ç‰›å¸‚ã€ç†Šå¸‚ã€éœ‡è¡å¸‚è¡¨ç°
bull_market = data[data['date'].between('2019-01-01', '2021-02-01')]
bear_market = data[data['date'].between('2021-02-01', '2022-10-01')]

bull_results = engine.backtest_long_only(signals, bull_market)
bear_results = engine.backtest_long_only(signals, bear_market)

print(f"ç‰›å¸‚å¹´åŒ–æ”¶ç›Š: {bull_results.annualized_return:.2%}")
print(f"ç†Šå¸‚å¹´åŒ–æ”¶ç›Š: {bear_results.annualized_return:.2%}")
```

**3. è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ**:
```python
from src.analysis import MonteCarloSimulator

simulator = MonteCarloSimulator()
simulated_paths = simulator.run(strategy, data, n_simulations=1000)

# åˆ†ææœ€åæƒ…å†µ
worst_case = simulated_paths.min(axis=0)
```

---

## æ€§èƒ½ä¼˜åŒ–

### Q19: å¦‚ä½•æå‡å›æµ‹é€Ÿåº¦ï¼Ÿ

**A**: æ€§èƒ½ä¼˜åŒ–æŠ€å·§ï¼š

**1. å‘é‡åŒ–è®¡ç®—**:
```python
# âŒ æ…¢é€Ÿï¼ˆå¾ªç¯ï¼‰
for i in range(len(data)):
    if signals[i] == 1:
        positions[i] = 1

# âœ… å¿«é€Ÿï¼ˆå‘é‡åŒ–ï¼‰
positions = np.where(signals == 1, 1, 0)  # å¿«100å€
```

**2. å¹¶è¡Œå›æµ‹**:
```python
from src.backtest import ParallelBacktester

backtester = ParallelBacktester(n_workers=4)
results = backtester.run(strategies, data)  # 4å€åŠ é€Ÿ
```

**3. ä½¿ç”¨Numba JIT**:
```python
from numba import jit

@jit(nopython=True)
def fast_backtest(prices, signals):
    # JITç¼–è¯‘çš„å›æµ‹é€»è¾‘
    pass
```

---

### Q20: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A**: å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆï¼š

**1. å‡å°‘æ•°æ®ç²¾åº¦**:
```python
# å°†float64é™ä¸ºfloat32
data = data.astype({
    'open': 'float32',
    'high': 'float32',
    'low': 'float32',
    'close': 'float32'
})  # å†…å­˜å‡å°‘50%
```

**2. åˆ†æ‰¹å¤„ç†**:
```python
# æŒ‰è‚¡ç¥¨åˆ†æ‰¹
for stock_batch in chunks(stock_codes, batch_size=100):
    process_batch(stock_batch)
```

**3. ä½¿ç”¨ç”Ÿæˆå™¨**:
```python
def data_generator(stock_codes):
    for code in stock_codes:
        yield load_data(code)

for data in data_generator(stock_codes):
    process(data)  # é€ä¸ªå¤„ç†ï¼Œä¸å ç”¨å¤§é‡å†…å­˜
```

---

## é”™è¯¯æ’æŸ¥

### Q21: ModuleNotFoundError: No module named 'src'

**A**: Pythonè·¯å¾„é—®é¢˜ï¼š

```bash
# æ–¹æ¡ˆ1: æ·»åŠ PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/path/to/stock-analysis/core"

# æ–¹æ¡ˆ2: åœ¨è„šæœ¬å¼€å¤´æ·»åŠ 
import sys
sys.path.append('/path/to/stock-analysis/core')

# æ–¹æ¡ˆ3: å®‰è£…ä¸ºåŒ…ï¼ˆæ¨èï¼‰
pip install -e .
```

---

### Q22: è¿è¡Œæ—¶è­¦å‘Šå¤ªå¤šï¼Ÿ

**A**: é…ç½®è­¦å‘Šè¿‡æ»¤ï¼š

```python
import warnings

# å¿½ç•¥æ‰€æœ‰è­¦å‘Šï¼ˆä¸æ¨èï¼‰
warnings.filterwarnings('ignore')

# åªå¿½ç•¥ç‰¹å®šè­¦å‘Šï¼ˆæ¨èï¼‰
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', message='.*DataFrame.*')

# åœ¨pandasä¸­
import pandas as pd
pd.options.mode.chained_assignment = None  # å…³é—­SettingWithCopyWarning
```

---

### Q23: å¦‚ä½•æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼Ÿ

**A**: è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼š

```python
from loguru import logger

# æ–¹æ³•1: ä»£ç ä¸­è®¾ç½®
logger.remove()  # ç§»é™¤é»˜è®¤handler
logger.add(
    "logs/debug.log",
    level="DEBUG",  # æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—
    rotation="100 MB"
)

# æ–¹æ³•2: é…ç½®æ–‡ä»¶
# config/logging.yaml
logging:
  level: DEBUG  # INFO, WARNING, ERROR
```

```bash
# æ–¹æ³•3: ç¯å¢ƒå˜é‡
export LOG_LEVEL=DEBUG
python script.py
```

---

## è¿›é˜¶ä½¿ç”¨

### Q24: å¦‚ä½•å®ç°è‡ªå®šä¹‰ç­–ç•¥ï¼Ÿ

**A**: ç»§æ‰¿BaseStrategyï¼š

```python
from src.strategies.base_strategy import BaseStrategy
import pandas as pd

class MyCustomStrategy(BaseStrategy):
    """è‡ªå®šä¹‰ç­–ç•¥"""

    def generate_signals(
        self,
        data: pd.DataFrame,
        features: pd.DataFrame
    ) -> pd.Series:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·

        Returns:
            pd.Series: 1=ä¹°å…¥, -1=å–å‡º, 0=æŒæœ‰
        """
        # ä½ çš„ç­–ç•¥é€»è¾‘
        signals = pd.Series(0, index=data.index)

        # ç¤ºä¾‹ï¼šåŒå‡çº¿ç­–ç•¥
        ma5 = data['close'].rolling(5).mean()
        ma20 = data['close'].rolling(20).mean()

        signals[ma5 > ma20] = 1   # é‡‘å‰ä¹°å…¥
        signals[ma5 < ma20] = -1  # æ­»å‰å–å‡º

        return signals

# ä½¿ç”¨
strategy = MyCustomStrategy(name='MyStrategy', params={})
signals = strategy.generate_signals(data, features)
```

---

### Q25: å¦‚ä½•éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ

**A**: ç”Ÿäº§éƒ¨ç½²æµç¨‹ï¼š

**1. ä½¿ç”¨Docker**:
```bash
# æ„å»ºé•œåƒ
docker build -t stock-analysis:v3.0.0 .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name stock-analysis \
  -v /data:/app/data \
  -e DATABASE_URL=postgresql://... \
  stock-analysis:v3.0.0
```

**2. å®šæ—¶ä»»åŠ¡**:
```bash
# crontab
# æ¯å¤©15:30è¿è¡Œï¼ˆæ”¶ç›˜åï¼‰
30 15 * * 1-5 cd /path/to/project && python scripts/daily_update.py
```

**3. ç›‘æ§å‘Šè­¦**:
```python
from src.utils.monitor import Monitor

monitor = Monitor()

@monitor.alert_on_error(email='admin@example.com')
def daily_task():
    # ä½ çš„ä»»åŠ¡
    pass
```

---

## ğŸ“š æ›´å¤šèµ„æº

### ç›¸å…³æ–‡æ¡£

- ğŸ“– [å¿«é€Ÿå¼€å§‹](quick_start.md)
- ğŸ”§ [å®‰è£…æŒ‡å—](installation.md)
- ğŸ“Š [CLIæŒ‡å—](CLI_GUIDE.md)
- ğŸ¤– [æ¨¡å‹ä½¿ç”¨æŒ‡å—](MODEL_USAGE_GUIDE.md)

### è·å–å¸®åŠ©

- ğŸ“§ [GitHub Issues](https://github.com/your-org/stock-analysis/issues) - æŠ¥å‘ŠBug
- ğŸ’¬ [Discussions](https://github.com/your-org/stock-analysis/discussions) - æŠ€æœ¯è®¨è®º
- ğŸ“š [å®Œæ•´æ–‡æ¡£](../README.md) - æ–‡æ¡£ä¸­å¿ƒ

---

## ğŸ¤ è´¡çŒ®FAQ

å‘ç°æ–‡æ¡£ä¸­æœªè§£ç­”çš„é—®é¢˜ï¼Ÿæ¬¢è¿è´¡çŒ®ï¼

1. åœ¨ [Issues](https://github.com/your-org/stock-analysis/issues) ä¸­æå‡ºé—®é¢˜
2. ç­‰å¾…ç¡®è®¤åï¼Œæäº¤PRæ·»åŠ åˆ°æœ¬FAQ
3. PRæ ¼å¼ï¼š
   ```markdown
   ### Q26: ä½ çš„é—®é¢˜ï¼Ÿ

   **A**: è¯¦ç»†è§£ç­”...
   ```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v3.0.0
**ç»´æŠ¤å›¢é˜Ÿ**: Quant Team
**æœ€åæ›´æ–°**: 2026-02-01
