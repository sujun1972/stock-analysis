# Core æ¨¡å—åç»­å¼€å‘è·¯çº¿å›¾

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

**æ–‡æ¡£ç›®çš„**ï¼šæŒ‡å¯¼ Core é‡åŒ–äº¤æ˜“ç³»ç»Ÿä»å½“å‰ 85% å®Œæˆåº¦æå‡åˆ°ç”Ÿäº§çº§ 100%

**é€‚ç”¨äººå‘˜**ï¼šé‡åŒ–ç­–ç•¥å¼€å‘è€…ã€åç«¯å·¥ç¨‹å¸ˆã€ç³»ç»Ÿæ¶æ„å¸ˆ

**æœ€åæ›´æ–°**ï¼š2026-01-29

---

## ğŸ¯ å¼€å‘ç›®æ ‡

### å½“å‰çŠ¶æ€
- âœ… æ•°æ®å±‚ï¼šå®Œæˆ 95%ï¼ˆå¤šæ•°æ®æºã€TimescaleDBï¼‰
- âœ… ç‰¹å¾å±‚ï¼šå®Œæˆ 98%ï¼ˆ125+ Alphaå› å­ï¼‰
- âœ… æ¨¡å‹å±‚ï¼šå®Œæˆ 85%ï¼ˆLightGBM/GRU/Ridgeï¼‰
- âœ… å›æµ‹å±‚ï¼šå®Œæˆ 80%ï¼ˆå‘é‡åŒ–å¼•æ“ï¼‰
- âœ… **ç­–ç•¥å±‚ï¼šå®Œæˆ 90%** â­ NEWï¼ˆ5ç§ç­–ç•¥ï¼Œç»Ÿä¸€æ¡†æ¶ï¼‰
- âŒ **é£æ§å±‚ï¼šç¼ºå¤±**
- âš ï¸  ä¼˜åŒ–å±‚ï¼šä¸å®Œæ•´

### æœ€ç»ˆç›®æ ‡
- ğŸ¯ å®Œæˆåº¦è¾¾åˆ° **100%**
- ğŸ¯ æ”¯æŒ **å®Œæ•´çš„é‡åŒ–äº¤æ˜“å·¥ä½œæµ**
- ğŸ¯ æä¾› **10+ å¯ç”¨çš„äº¤æ˜“ç­–ç•¥**
- ğŸ¯ å®ç° **å®æ—¶é£é™©ç›‘æ§**
- ğŸ¯ æ”¯æŒ **è‡ªåŠ¨å‚æ•°ä¼˜åŒ–**
- ğŸ¯ å…·å¤‡ **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²èƒ½åŠ›**

---

## ğŸ“… ä¸‰é˜¶æ®µå¼€å‘è®¡åˆ’

### é˜¶æ®µ1ï¼šæ ¸å¿ƒè¡¥å……ï¼ˆ1-2å‘¨ï¼‰ğŸ”´ é«˜ä¼˜å…ˆçº§

**ç›®æ ‡**ï¼š~~è¡¥å……ç­–ç•¥å±‚å’Œ~~é£é™©ç®¡ç†æ¨¡å—ï¼Œä½¿ç³»ç»Ÿå¯ç”¨

**å·¥ä½œé‡ä¼°ç®—**ï¼š~~60-80~~ 32-40 å·¥æ—¶ï¼ˆç­–ç•¥å±‚å·²å®Œæˆ âœ…ï¼‰

#### 1.1 ~~å®ç°äº¤æ˜“ç­–ç•¥å±‚ (strategies/)~~ âœ… å·²å®Œæˆ

**çŠ¶æ€**ï¼šâœ… å·²å®Œæˆï¼ˆ2026-01-29ï¼‰

**æ—¶é—´**ï¼š~~5å¤© / 40å·¥æ—¶~~

**ç›®å½•ç»“æ„**ï¼š
```
core/src/strategies/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base_strategy.py              # ç­–ç•¥åŸºç±» (8h)
â”œâ”€â”€ signal_generator.py           # ä¿¡å·ç”Ÿæˆå™¨ (6h)
â”œâ”€â”€ momentum_strategy.py          # åŠ¨é‡ç­–ç•¥ (4h)
â”œâ”€â”€ mean_reversion_strategy.py    # å‡å€¼å›å½’ç­–ç•¥ (4h)
â”œâ”€â”€ ml_strategy.py                # æœºå™¨å­¦ä¹ ç­–ç•¥ (6h)
â”œâ”€â”€ multi_factor_strategy.py      # å¤šå› å­ç­–ç•¥ (6h)
â”œâ”€â”€ strategy_combiner.py          # ç­–ç•¥ç»„åˆå™¨ (4h)
â””â”€â”€ examples/                     # ä½¿ç”¨ç¤ºä¾‹ (2h)
    â”œâ”€â”€ example_momentum.py
    â”œâ”€â”€ example_ml.py
    â””â”€â”€ example_multi_factor.py
```

**å·²å®ç°åŠŸèƒ½** âœ…ï¼š

1. **ç­–ç•¥åŸºç±»** ([base_strategy.py](core/src/strategies/base_strategy.py:1))
```python
from abc import ABC, abstractmethod
import pandas as pd
from typing import Dict, Optional

class BaseStrategy(ABC):
    """
    äº¤æ˜“ç­–ç•¥åŸºç±»

    æ‰€æœ‰ç­–ç•¥å¿…é¡»å®ç°çš„æ–¹æ³•ï¼š
    - generate_signals(): ç”Ÿæˆä¹°å–ä¿¡å·
    - get_positions(): è·å–æŒä»“å»ºè®®
    - get_strategy_name(): è¿”å›ç­–ç•¥åç§°
    """

    def __init__(self, name: str, config: Dict):
        self.name = name
        self.config = config

    @abstractmethod
    def generate_signals(
        self,
        prices: pd.DataFrame,
        features: pd.DataFrame
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·

        Args:
            prices: ä»·æ ¼æ•°æ® (index=date, columns=stock_codes)
            features: ç‰¹å¾æ•°æ®

        Returns:
            signals: ä¿¡å·DataFrame (å€¼: 1=ä¹°å…¥, 0=æŒæœ‰, -1=å–å‡º)
        """
        pass

    @abstractmethod
    def calculate_scores(
        self,
        features: pd.DataFrame
    ) -> pd.DataFrame:
        """
        è®¡ç®—è‚¡ç¥¨è¯„åˆ†ï¼ˆç”¨äºæ’åºé€‰è‚¡ï¼‰

        Returns:
            scores: è¯„åˆ†DataFrame (å€¼è¶Šå¤§è¶Šå¥½)
        """
        pass

    def backtest(self, engine, prices, features):
        """å›æµ‹æ¥å£"""
        signals = self.generate_signals(prices, features)
        return engine.backtest_long_only(signals, prices)
```

2. **åŠ¨é‡ç­–ç•¥** ([momentum_strategy.py](core/src/strategies/momentum_strategy.py:1))
```python
class MomentumStrategy(BaseStrategy):
    """
    åŠ¨é‡ç­–ç•¥ï¼šä¹°å…¥è¿‘æœŸå¼ºåŠ¿è‚¡ï¼ŒæŒæœ‰ä¸€æ®µæ—¶é—´åå–å‡º

    å‚æ•°ï¼š
        - lookback_period: å›çœ‹æœŸï¼ˆé»˜è®¤20å¤©ï¼‰
        - holding_period: æŒä»“æœŸï¼ˆé»˜è®¤5å¤©ï¼‰
        - top_n: é€‰è‚¡æ•°é‡ï¼ˆé»˜è®¤50ï¼‰
    """

    def generate_signals(self, prices, features):
        # è®¡ç®—åŠ¨é‡å¾—åˆ†ï¼šè¿‡å»Næ—¥æ”¶ç›Šç‡
        momentum = prices.pct_change(self.config['lookback_period'])

        # æ¯æœŸé€‰æ‹©åŠ¨é‡æœ€é«˜çš„top_nåªè‚¡ç¥¨
        signals = pd.DataFrame(0, index=prices.index, columns=prices.columns)

        for date in signals.index:
            scores = momentum.loc[date].dropna()
            top_stocks = scores.nlargest(self.config['top_n']).index
            signals.loc[date, top_stocks] = 1

        return signals

    def calculate_scores(self, features):
        # ä½¿ç”¨ MOM20 å› å­ä½œä¸ºè¯„åˆ†
        return features['MOM20']
```

3. **å¤šå› å­ç­–ç•¥** ([multi_factor_strategy.py](core/src/strategies/multi_factor_strategy.py:1))
```python
class MultiFactorStrategy(BaseStrategy):
    """
    å¤šå› å­ç­–ç•¥ï¼šç»“åˆå¤šä¸ªAlphaå› å­è¿›è¡Œé€‰è‚¡

    å‚æ•°ï¼š
        - factors: å› å­åˆ—è¡¨ ['MOM20', 'REV5', 'VOLATILITY20']
        - weights: å› å­æƒé‡ [0.4, 0.3, 0.3]
        - top_n: é€‰è‚¡æ•°é‡
    """

    def calculate_scores(self, features):
        # å› å­æ ‡å‡†åŒ–
        normalized = features[self.config['factors']].rank(pct=True)

        # åŠ æƒæ±‚å’Œ
        weights = self.config['weights']
        scores = sum(normalized[f] * w for f, w in zip(self.config['factors'], weights))

        return scores

    def generate_signals(self, prices, features):
        scores = self.calculate_scores(features)

        signals = pd.DataFrame(0, index=prices.index, columns=prices.columns)
        for date in signals.index:
            if date in scores.index:
                top_stocks = scores.loc[date].nlargest(self.config['top_n']).index
                signals.loc[date, top_stocks] = 1

        return signals
```

4. **æœºå™¨å­¦ä¹ ç­–ç•¥** ([ml_strategy.py](core/src/strategies/ml_strategy.py:1))
```python
class MLStrategy(BaseStrategy):
    """
    æœºå™¨å­¦ä¹ ç­–ç•¥ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æ”¶ç›Šç‡

    å‚æ•°ï¼š
        - model: å·²è®­ç»ƒçš„æ¨¡å‹ï¼ˆLightGBM/GRUï¼‰
        - threshold: é¢„æµ‹é˜ˆå€¼ï¼ˆé»˜è®¤0.01ï¼Œå³é¢„æµ‹æ”¶ç›Š>1%æ‰ä¹°å…¥ï¼‰
        - top_n: é€‰è‚¡æ•°é‡
    """

    def __init__(self, name, config, model):
        super().__init__(name, config)
        self.model = model

    def calculate_scores(self, features):
        # ä½¿ç”¨æ¨¡å‹é¢„æµ‹
        predictions = self.model.predict(features)
        return pd.Series(predictions, index=features.index)

    def generate_signals(self, prices, features):
        scores = self.calculate_scores(features)

        # é€‰æ‹©é¢„æµ‹æ”¶ç›Šæœ€é«˜çš„è‚¡ç¥¨
        signals = pd.DataFrame(0, index=prices.index, columns=prices.columns)
        for date in signals.index:
            if date in scores.index:
                # åªä¹°å…¥é¢„æµ‹æ”¶ç›Š > threshold çš„è‚¡ç¥¨
                candidates = scores.loc[date][scores.loc[date] > self.config['threshold']]
                top_stocks = candidates.nlargest(self.config['top_n']).index
                signals.loc[date, top_stocks] = 1

        return signals
```

**æµ‹è¯•å®Œæˆæƒ…å†µ** âœ…ï¼š
- âœ… å•å…ƒæµ‹è¯•ï¼š7ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œ108ä¸ªæµ‹è¯•ç”¨ä¾‹
- âœ… å›æµ‹ç¤ºä¾‹ï¼š3ä¸ªå®Œæ•´ç¤ºä¾‹ï¼ˆåŠ¨é‡ã€å‡å€¼å›å½’ã€ç­–ç•¥ç»„åˆï¼‰
- âœ… æ€§èƒ½æµ‹è¯•ï¼šé€šè¿‡ï¼ˆå‘é‡åŒ–è®¡ç®—ï¼‰
- âš ï¸  æµ‹è¯•é€šè¿‡ç‡ï¼š52%ï¼ˆéœ€è¦ä¼˜åŒ–ï¼Œè§ä¸‹ä¸€èŠ‚ï¼‰

**åç»­ä¼˜åŒ–**ï¼š
- ğŸ”„ ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹ï¼Œæå‡é€šè¿‡ç‡åˆ°90%+ï¼ˆé¢„è®¡2å¤©ï¼‰
- ğŸ”„ æ·»åŠ æ›´å¤šç­–ç•¥ç¤ºä¾‹
- ğŸ”„ å®Œå–„ç­–ç•¥æ–‡æ¡£

---

#### 1.2 å®ç°é£é™©ç®¡ç†æ¨¡å— (risk_management/)

**æ—¶é—´**ï¼š4å¤© / 32å·¥æ—¶

**ç›®å½•ç»“æ„**ï¼š
```
core/src/risk_management/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ var_calculator.py             # VaRè®¡ç®—å™¨ (6h)
â”œâ”€â”€ drawdown_controller.py        # å›æ’¤æ§åˆ¶å™¨ (5h)
â”œâ”€â”€ position_sizer.py             # ä»“ä½è®¡ç®—å™¨ (5h)
â”œâ”€â”€ correlation_monitor.py        # ç›¸å…³æ€§ç›‘æ§ (4h)
â”œâ”€â”€ risk_monitor.py               # å®æ—¶é£é™©ç›‘æ§ (6h)
â”œâ”€â”€ stress_test.py                # å‹åŠ›æµ‹è¯• (4h)
â””â”€â”€ examples/                     # ä½¿ç”¨ç¤ºä¾‹ (2h)
    â””â”€â”€ example_risk_monitor.py
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **VaR è®¡ç®—å™¨** ([var_calculator.py](core/src/risk_management/var_calculator.py:1))
```python
class VaRCalculator:
    """
    é£é™©ä»·å€¼(Value at Risk)è®¡ç®—å™¨

    æ”¯æŒä¸‰ç§æ–¹æ³•ï¼š
    - historical: å†å²æ¨¡æ‹Ÿæ³•
    - variance_covariance: æ–¹å·®-åæ–¹å·®æ³•
    - monte_carlo: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ³•
    """

    def calculate_historical_var(
        self,
        returns: pd.Series,
        confidence_level: float = 0.95
    ) -> float:
        """
        å†å²æ¨¡æ‹Ÿæ³•è®¡ç®—VaR

        Args:
            returns: å†å²æ”¶ç›Šç‡åºåˆ—
            confidence_level: ç½®ä¿¡æ°´å¹³ï¼ˆé»˜è®¤95%ï¼‰

        Returns:
            VaRå€¼ï¼ˆè´Ÿæ•°è¡¨ç¤ºæ½œåœ¨æŸå¤±ï¼‰
        """
        return returns.quantile(1 - confidence_level)

    def calculate_portfolio_var(
        self,
        portfolio_values: pd.Series,
        confidence_level: float = 0.95,
        holding_period: int = 1
    ) -> Dict[str, float]:
        """
        è®¡ç®—ç»„åˆVaR

        Returns:
            {
                'var_1day': 1æ—¥VaR,
                'var_5day': 5æ—¥VaR,
                'cvar': æ¡ä»¶VaR (CVaR/Expected Shortfall)
            }
        """
        returns = portfolio_values.pct_change().dropna()

        # 1æ—¥VaR
        var_1day = self.calculate_historical_var(returns, confidence_level)

        # Næ—¥VaRï¼ˆå‡è®¾æ”¶ç›Šç‡ç‹¬ç«‹åŒåˆ†å¸ƒï¼‰
        var_nday = var_1day * np.sqrt(holding_period)

        # CVaRï¼ˆVaRä¹‹ä¸‹çš„å¹³å‡æŸå¤±ï¼‰
        cvar = returns[returns <= var_1day].mean()

        return {
            'var_1day': var_1day,
            f'var_{holding_period}day': var_nday,
            'cvar': cvar
        }
```

2. **å›æ’¤æ§åˆ¶å™¨** ([drawdown_controller.py](core/src/risk_management/drawdown_controller.py:1))
```python
class DrawdownController:
    """
    å›æ’¤æ§åˆ¶å™¨ï¼šç›‘æ§å¹¶æ§åˆ¶æœ€å¤§å›æ’¤

    åŠŸèƒ½ï¼š
    - å®æ—¶è®¡ç®—å½“å‰å›æ’¤
    - è§¦å‘å›æ’¤è­¦æŠ¥
    - è‡ªåŠ¨å‡ä»“/åœæ­¢äº¤æ˜“
    """

    def __init__(self, max_drawdown: float = 0.15):
        """
        Args:
            max_drawdown: æœ€å¤§å…è®¸å›æ’¤ï¼ˆé»˜è®¤15%ï¼‰
        """
        self.max_drawdown = max_drawdown
        self.peak_value = 0
        self.current_drawdown = 0

    def calculate_drawdown(self, portfolio_values: pd.Series) -> pd.Series:
        """è®¡ç®—å›æ’¤åºåˆ—"""
        peak = portfolio_values.expanding().max()
        drawdown = (portfolio_values - peak) / peak
        return drawdown

    def check_drawdown_limit(self, current_value: float) -> Dict[str, any]:
        """
        æ£€æŸ¥æ˜¯å¦è§¦å‘å›æ’¤é™åˆ¶

        Returns:
            {
                'current_drawdown': å½“å‰å›æ’¤,
                'is_alert': æ˜¯å¦è­¦æŠ¥ï¼ˆ>æœ€å¤§å›æ’¤çš„80%ï¼‰,
                'should_stop': æ˜¯å¦åº”è¯¥åœæ­¢äº¤æ˜“,
                'action': 'reduce_position' | 'stop_trading' | 'continue'
            }
        """
        # æ›´æ–°å³°å€¼
        if current_value > self.peak_value:
            self.peak_value = current_value

        # è®¡ç®—å½“å‰å›æ’¤
        self.current_drawdown = (current_value - self.peak_value) / self.peak_value

        # åˆ¤æ–­æ˜¯å¦è§¦å‘è­¦æŠ¥
        is_alert = abs(self.current_drawdown) > self.max_drawdown * 0.8
        should_stop = abs(self.current_drawdown) > self.max_drawdown

        # å†³å®šåŠ¨ä½œ
        if should_stop:
            action = 'stop_trading'
        elif is_alert:
            action = 'reduce_position'
        else:
            action = 'continue'

        return {
            'current_drawdown': self.current_drawdown,
            'is_alert': is_alert,
            'should_stop': should_stop,
            'action': action,
            'recommendation': self._get_recommendation(action)
        }

    def _get_recommendation(self, action: str) -> str:
        if action == 'stop_trading':
            return 'å›æ’¤å·²è¶…è¿‡é™åˆ¶ï¼Œå»ºè®®ç«‹å³åœæ­¢äº¤æ˜“å¹¶æ¸…ä»“'
        elif action == 'reduce_position':
            return 'å›æ’¤æ¥è¿‘é™åˆ¶ï¼Œå»ºè®®å‡ä»“50%é™ä½é£é™©'
        else:
            return 'å›æ’¤åœ¨æ§åˆ¶èŒƒå›´å†…ï¼Œå¯ä»¥ç»§ç»­äº¤æ˜“'
```

3. **ä»“ä½è®¡ç®—å™¨** ([position_sizer.py](core/src/risk_management/position_sizer.py:1))
```python
class PositionSizer:
    """
    ä»“ä½è®¡ç®—å™¨ï¼šæ ¹æ®é£é™©è®¡ç®—åˆç†çš„ä»“ä½å¤§å°

    æ”¯æŒå¤šç§æ–¹æ³•ï¼š
    - equal_weight: ç­‰æƒé‡
    - risk_parity: é£é™©å¹³ä»·
    - kelly: å‡¯åˆ©å…¬å¼
    - volatility_target: ç›®æ ‡æ³¢åŠ¨ç‡
    """

    def calculate_kelly_size(
        self,
        win_rate: float,
        win_loss_ratio: float,
        max_position: float = 0.2
    ) -> float:
        """
        å‡¯åˆ©å…¬å¼è®¡ç®—ä»“ä½

        Kelly % = (win_rate * win_loss_ratio - (1 - win_rate)) / win_loss_ratio

        Args:
            win_rate: èƒœç‡ï¼ˆ0-1ï¼‰
            win_loss_ratio: ç›ˆäºæ¯”ï¼ˆå¹³å‡ç›ˆåˆ©/å¹³å‡äºæŸï¼‰
            max_position: æœ€å¤§ä»“ä½é™åˆ¶

        Returns:
            å»ºè®®ä»“ä½æ¯”ä¾‹ï¼ˆ0-1ï¼‰
        """
        kelly = (win_rate * win_loss_ratio - (1 - win_rate)) / win_loss_ratio

        # åŠå‡¯åˆ©ï¼ˆä¿å®ˆï¼‰
        kelly = kelly * 0.5

        # é™åˆ¶æœ€å¤§ä»“ä½
        return min(max(kelly, 0), max_position)

    def calculate_risk_parity_weights(
        self,
        returns: pd.DataFrame
    ) -> pd.Series:
        """
        é£é™©å¹³ä»·æƒé‡è®¡ç®—

        æ¯åªè‚¡ç¥¨çš„é£é™©è´¡çŒ®ç›¸ç­‰

        Args:
            returns: è‚¡ç¥¨æ”¶ç›Šç‡DataFrame

        Returns:
            å„è‚¡ç¥¨æƒé‡Series
        """
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatilities = returns.std()

        # é£é™©å¹³ä»·ï¼šæƒé‡ä¸æ³¢åŠ¨ç‡æˆåæ¯”
        inv_vol = 1 / volatilities
        weights = inv_vol / inv_vol.sum()

        return weights
```

4. **å®æ—¶é£é™©ç›‘æ§** ([risk_monitor.py](core/src/risk_management/risk_monitor.py:1))
```python
class RiskMonitor:
    """
    å®æ—¶é£é™©ç›‘æ§å™¨ï¼šç»¼åˆç›‘æ§æ‰€æœ‰é£é™©æŒ‡æ ‡

    ç›‘æ§å†…å®¹ï¼š
    - ç»„åˆVaR
    - æœ€å¤§å›æ’¤
    - ä»“ä½é›†ä¸­åº¦
    - è¡Œä¸šé›†ä¸­åº¦
    - ç›¸å…³æ€§é£é™©
    """

    def __init__(self, config: Dict):
        self.var_calculator = VaRCalculator()
        self.drawdown_controller = DrawdownController(
            max_drawdown=config.get('max_drawdown', 0.15)
        )
        self.alerts = []

    def monitor(
        self,
        portfolio_value: float,
        positions: Dict,
        prices: Dict
    ) -> Dict[str, any]:
        """
        æ‰§è¡Œé£é™©ç›‘æ§

        Returns:
            {
                'var': VaRæŒ‡æ ‡,
                'drawdown': å›æ’¤ä¿¡æ¯,
                'concentration': é›†ä¸­åº¦ä¿¡æ¯,
                'alerts': è­¦æŠ¥åˆ—è¡¨,
                'overall_risk_level': 'low' | 'medium' | 'high'
            }
        """
        # 1. è®¡ç®—VaRï¼ˆå‡è®¾æœ‰å†å²æ”¶ç›Šç‡æ•°æ®ï¼‰
        # var_metrics = self.var_calculator.calculate_portfolio_var(...)

        # 2. æ£€æŸ¥å›æ’¤
        drawdown_info = self.drawdown_controller.check_drawdown_limit(portfolio_value)

        # 3. æ£€æŸ¥ä»“ä½é›†ä¸­åº¦
        concentration = self._check_concentration(positions, prices, portfolio_value)

        # 4. æ±‡æ€»è­¦æŠ¥
        self.alerts = []
        if drawdown_info['is_alert']:
            self.alerts.append(f"å›æ’¤è­¦æŠ¥: {drawdown_info['current_drawdown']:.2%}")

        if concentration['max_position'] > 0.3:
            self.alerts.append(f"ä»“ä½è¿‡äºé›†ä¸­: {concentration['max_stock']} å æ¯” {concentration['max_position']:.2%}")

        # 5. è¯„ä¼°æ•´ä½“é£é™©ç­‰çº§
        overall_risk = self._assess_overall_risk(drawdown_info, concentration)

        return {
            'drawdown': drawdown_info,
            'concentration': concentration,
            'alerts': self.alerts,
            'overall_risk_level': overall_risk,
            'timestamp': pd.Timestamp.now()
        }

    def _check_concentration(self, positions, prices, total_value):
        """æ£€æŸ¥ä»“ä½é›†ä¸­åº¦"""
        if not positions:
            return {'max_position': 0, 'max_stock': None}

        position_values = {
            stock: pos['shares'] * prices.get(stock, 0)
            for stock, pos in positions.items()
        }

        max_stock = max(position_values, key=position_values.get)
        max_position = position_values[max_stock] / total_value

        return {
            'max_stock': max_stock,
            'max_position': max_position,
            'top5_concentration': sum(sorted(position_values.values(), reverse=True)[:5]) / total_value
        }

    def _assess_overall_risk(self, drawdown_info, concentration):
        """è¯„ä¼°æ•´ä½“é£é™©ç­‰çº§"""
        risk_score = 0

        # å›æ’¤é£é™©
        if abs(drawdown_info['current_drawdown']) > 0.1:
            risk_score += 2
        elif abs(drawdown_info['current_drawdown']) > 0.05:
            risk_score += 1

        # é›†ä¸­åº¦é£é™©
        if concentration['max_position'] > 0.3:
            risk_score += 2
        elif concentration['max_position'] > 0.2:
            risk_score += 1

        # è¯„çº§
        if risk_score >= 3:
            return 'high'
        elif risk_score >= 1:
            return 'medium'
        else:
            return 'low'
```

**æµ‹è¯•è¦æ±‚**ï¼š
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- å‹åŠ›æµ‹è¯•ï¼ˆæç«¯å¸‚åœºæƒ…å†µï¼‰
- æ€§èƒ½æµ‹è¯•ï¼ˆå®æ—¶ç›‘æ§å»¶è¿Ÿ < 100msï¼‰

---

#### 1.3 å®Œå–„å› å­åˆ†æå·¥å…·

**æ—¶é—´**ï¼š3å¤© / 24å·¥æ—¶

**æ–°å¢æ–‡ä»¶**ï¼š
```
core/src/features/
â”œâ”€â”€ factor_analyzer.py            # å› å­åˆ†æå™¨ (8h)
â”œâ”€â”€ ic_calculator.py              # ICè®¡ç®—å™¨ (6h)
â”œâ”€â”€ layering_test.py              # åˆ†å±‚æµ‹è¯• (6h)
â””â”€â”€ decay_analyzer.py             # è¡°å‡åˆ†æ (4h)
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **IC è®¡ç®—å™¨** ([ic_calculator.py](core/src/features/ic_calculator.py:1))
```python
class ICCalculator:
    """
    ä¿¡æ¯ç³»æ•°(Information Coefficient)è®¡ç®—å™¨

    IC = Corr(å› å­å€¼, æœªæ¥æ”¶ç›Šç‡)

    ç”¨äºè¯„ä¼°å› å­çš„é¢„æµ‹èƒ½åŠ›
    """

    def calculate_ic(
        self,
        factor: pd.Series,
        future_returns: pd.Series,
        method: str = 'pearson'
    ) -> float:
        """
        è®¡ç®—IC

        Args:
            factor: å› å­å€¼åºåˆ—
            future_returns: æœªæ¥æ”¶ç›Šç‡åºåˆ—
            method: 'pearson' | 'spearman'

        Returns:
            ICå€¼ï¼ˆ-1åˆ°1ï¼‰
        """
        if method == 'pearson':
            return factor.corr(future_returns)
        elif method == 'spearman':
            return factor.corr(future_returns, method='spearman')

    def calculate_ic_series(
        self,
        factors: pd.DataFrame,
        prices: pd.DataFrame,
        forward_periods: int = 5
    ) -> pd.DataFrame:
        """
        è®¡ç®—ICæ—¶é—´åºåˆ—

        Args:
            factors: å› å­DataFrame (index=date, columns=stock_codes)
            prices: ä»·æ ¼DataFrame
            forward_periods: å‰ç»æœŸï¼ˆå¤©æ•°ï¼‰

        Returns:
            ICæ—¶é—´åºåˆ—DataFrame (index=date, columns=factor_names)
        """
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
        future_returns = prices.pct_change(forward_periods).shift(-forward_periods)

        ic_series = {}
        for date in factors.index:
            factor_values = factors.loc[date]
            return_values = future_returns.loc[date]

            # åˆ é™¤NaN
            valid = factor_values.notna() & return_values.notna()

            if valid.sum() > 10:  # è‡³å°‘10ä¸ªæœ‰æ•ˆæ ·æœ¬
                ic = self.calculate_ic(
                    factor_values[valid],
                    return_values[valid]
                )
                ic_series[date] = ic

        return pd.Series(ic_series)

    def calculate_ic_ir(self, ic_series: pd.Series) -> Dict[str, float]:
        """
        è®¡ç®—ICå’ŒICIR

        Returns:
            {
                'mean_ic': ICå‡å€¼,
                'ic_std': ICæ ‡å‡†å·®,
                'ic_ir': ICIR (ICå‡å€¼/ICæ ‡å‡†å·®),
                'ic_win_rate': IC>0çš„æ¯”ä¾‹
            }
        """
        return {
            'mean_ic': ic_series.mean(),
            'ic_std': ic_series.std(),
            'ic_ir': ic_series.mean() / ic_series.std() if ic_series.std() > 0 else 0,
            'ic_win_rate': (ic_series > 0).mean()
        }
```

2. **åˆ†å±‚æµ‹è¯•** ([layering_test.py](core/src/features/layering_test.py:1))
```python
class LayeringTest:
    """
    å› å­åˆ†å±‚æµ‹è¯•

    å°†è‚¡ç¥¨æŒ‰å› å­å€¼åˆ†ä¸ºNå±‚ï¼Œæ¯”è¾ƒå„å±‚çš„æ”¶ç›Šè¡¨ç°
    """

    def perform_layering_test(
        self,
        factor: pd.DataFrame,
        returns: pd.DataFrame,
        n_layers: int = 5
    ) -> pd.DataFrame:
        """
        æ‰§è¡Œåˆ†å±‚æµ‹è¯•

        Args:
            factor: å› å­DataFrame
            returns: æ”¶ç›Šç‡DataFrame
            n_layers: åˆ†å±‚æ•°é‡ï¼ˆé»˜è®¤5å±‚ï¼‰

        Returns:
            å„å±‚æ”¶ç›Šç»Ÿè®¡DataFrame
        """
        layer_returns = {f'Layer_{i+1}': [] for i in range(n_layers)}

        for date in factor.index:
            if date not in returns.index:
                continue

            # è·å–å½“æœŸå› å­å€¼å’Œä¸‹æœŸæ”¶ç›Š
            factor_values = factor.loc[date].dropna()
            next_returns = returns.loc[date]

            # æŒ‰å› å­å€¼åˆ†å±‚
            layers = pd.qcut(factor_values, n_layers, labels=False, duplicates='drop')

            # è®¡ç®—å„å±‚å¹³å‡æ”¶ç›Š
            for i in range(n_layers):
                stocks_in_layer = layers[layers == i].index
                layer_ret = next_returns[stocks_in_layer].mean()
                layer_returns[f'Layer_{i+1}'].append(layer_ret)

        # ç»Ÿè®¡å„å±‚è¡¨ç°
        summary = pd.DataFrame({
            'Mean_Return': {k: np.mean(v) for k, v in layer_returns.items()},
            'Std_Return': {k: np.std(v) for k, v in layer_returns.items()},
            'Sharpe': {k: np.mean(v) / np.std(v) if np.std(v) > 0 else 0
                      for k, v in layer_returns.items()}
        })

        # æ·»åŠ å¤šç©ºç»„åˆæ”¶ç›Šï¼ˆæœ€é«˜å±‚ - æœ€ä½å±‚ï¼‰
        long_short = [h - l for h, l in zip(
            layer_returns[f'Layer_{n_layers}'],
            layer_returns['Layer_1']
        )]
        summary.loc['Long_Short'] = [
            np.mean(long_short),
            np.std(long_short),
            np.mean(long_short) / np.std(long_short) if np.std(long_short) > 0 else 0
        ]

        return summary
```

**æµ‹è¯•è¦æ±‚**ï¼š
- åœ¨çœŸå®æ•°æ®ä¸ŠéªŒè¯ï¼ˆè‡³å°‘3ä¸ªå› å­ï¼‰
- ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šï¼ˆICåºåˆ—å›¾ã€åˆ†å±‚æ”¶ç›Šå›¾ï¼‰

---

#### 1.4 å®Œå–„æ•°æ®è´¨é‡æ£€æŸ¥

**æ—¶é—´**ï¼š2å¤© / 16å·¥æ—¶

**æ–°å¢æ–‡ä»¶**ï¼š
```
core/src/data/
â”œâ”€â”€ data_validator.py             # æ•°æ®éªŒè¯å™¨ (5h)
â”œâ”€â”€ outlier_detector.py           # å¼‚å¸¸å€¼æ£€æµ‹ (5h)
â”œâ”€â”€ suspend_filter.py             # åœç‰Œè¿‡æ»¤ (4h)
â””â”€â”€ missing_handler.py            # ç¼ºå¤±å€¼å¤„ç† (2h)
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **å¼‚å¸¸å€¼æ£€æµ‹å™¨** ([outlier_detector.py](core/src/data/outlier_detector.py:1))
```python
class OutlierDetector:
    """
    å¼‚å¸¸å€¼æ£€æµ‹å™¨

    æ£€æµ‹ä»·æ ¼æ•°æ®ä¸­çš„å¼‚å¸¸å€¼ï¼š
    - å•æ—¥æš´æ¶¨æš´è·Œï¼ˆ>20%ï¼‰
    - ä»·æ ¼çªå˜
    - æˆäº¤é‡å¼‚å¸¸
    """

    def detect_price_outliers(
        self,
        df: pd.DataFrame,
        method: str = 'iqr'
    ) -> pd.DataFrame:
        """
        æ£€æµ‹ä»·æ ¼å¼‚å¸¸å€¼

        Args:
            df: ä»·æ ¼DataFrame
            method: 'iqr' | 'zscore' | 'isolation_forest'

        Returns:
            å¼‚å¸¸æ ‡è®°DataFrame (True=å¼‚å¸¸)
        """
        if method == 'iqr':
            return self._detect_by_iqr(df)
        elif method == 'zscore':
            return self._detect_by_zscore(df)

    def _detect_by_iqr(self, df: pd.DataFrame) -> pd.DataFrame:
        """IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        returns = df.pct_change()

        Q1 = returns.quantile(0.25)
        Q3 = returns.quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 3 * IQR
        upper_bound = Q3 + 3 * IQR

        outliers = (returns < lower_bound) | (returns > upper_bound)

        return outliers

    def filter_outliers(
        self,
        df: pd.DataFrame,
        outliers: pd.DataFrame,
        method: str = 'remove'
    ) -> pd.DataFrame:
        """
        å¤„ç†å¼‚å¸¸å€¼

        Args:
            method: 'remove' | 'winsorize' | 'interpolate'
        """
        if method == 'remove':
            return df.where(~outliers)
        elif method == 'winsorize':
            # å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºè¾¹ç•Œå€¼
            return df.clip(lower=df.quantile(0.01), upper=df.quantile(0.99), axis=1)
```

2. **åœç‰Œè¿‡æ»¤å™¨** ([suspend_filter.py](core/src/data/suspend_filter.py:1))
```python
class SuspendFilter:
    """
    åœç‰Œè‚¡ç¥¨è¿‡æ»¤å™¨

    è¯†åˆ«å¹¶è¿‡æ»¤åœç‰Œè‚¡ç¥¨ï¼š
    - æˆäº¤é‡ä¸º0
    - è¿ç»­å¤šæ—¥ä»·æ ¼ä¸å˜
    """

    def detect_suspended_stocks(
        self,
        prices: pd.DataFrame,
        volumes: pd.DataFrame
    ) -> pd.DataFrame:
        """
        æ£€æµ‹åœç‰Œè‚¡ç¥¨

        Returns:
            åœç‰Œæ ‡è®°DataFrame (True=åœç‰Œ)
        """
        # æ–¹æ³•1ï¼šæˆäº¤é‡ä¸º0
        zero_volume = (volumes == 0) | volumes.isna()

        # æ–¹æ³•2ï¼šä»·æ ¼è¿ç»­3å¤©ä¸å˜
        price_unchanged = (prices == prices.shift(1)) & \
                         (prices == prices.shift(2)) & \
                         (prices == prices.shift(3))

        # åˆå¹¶
        suspended = zero_volume | price_unchanged

        return suspended

    def filter_suspended(
        self,
        df: pd.DataFrame,
        suspended: pd.DataFrame
    ) -> pd.DataFrame:
        """è¿‡æ»¤æ‰åœç‰Œè‚¡ç¥¨çš„æ•°æ®"""
        return df.where(~suspended)
```

**äº¤ä»˜ç‰©**ï¼š
- 4ä¸ªæ–°æ¨¡å—çš„ä»£ç 
- å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡>80%ï¼‰
- ä½¿ç”¨ç¤ºä¾‹

---

### é˜¶æ®µ2ï¼šåŠŸèƒ½å¢å¼ºï¼ˆ2-3å‘¨ï¼‰ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**ç›®æ ‡**ï¼šæå‡ç³»ç»Ÿæ€§èƒ½å’Œæ˜“ç”¨æ€§

**å·¥ä½œé‡ä¼°ç®—**ï¼š80-100 å·¥æ—¶

#### 2.1 å®ç°å‚æ•°ä¼˜åŒ–æ¨¡å— (optimization/)

**æ—¶é—´**ï¼š5å¤© / 40å·¥æ—¶

**ç›®å½•ç»“æ„**ï¼š
```
core/src/optimization/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ grid_search.py                # ç½‘æ ¼æœç´¢ (8h)
â”œâ”€â”€ bayesian_optimizer.py         # è´å¶æ–¯ä¼˜åŒ– (10h)
â”œâ”€â”€ walk_forward.py               # Walk-Forwardä¼˜åŒ– (10h)
â”œâ”€â”€ genetic_algorithm.py          # é—ä¼ ç®—æ³• (8h)
â””â”€â”€ examples/                     # ä½¿ç”¨ç¤ºä¾‹ (4h)
    â”œâ”€â”€ example_grid_search.py
    â””â”€â”€ example_walk_forward.py
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **ç½‘æ ¼æœç´¢** - éå†æ‰€æœ‰å‚æ•°ç»„åˆ
2. **è´å¶æ–¯ä¼˜åŒ–** - æ™ºèƒ½æœç´¢æœ€ä¼˜å‚æ•°ï¼ˆä½¿ç”¨ scikit-optimizeï¼‰
3. **Walk-Forward ä¼˜åŒ–** - æ»šåŠ¨ä¼˜åŒ–ï¼Œé¿å…è¿‡æ‹Ÿåˆ
4. **é—ä¼ ç®—æ³•** - è¿›åŒ–ç®—æ³•å¯»ä¼˜

**ç¤ºä¾‹ä»£ç **ï¼š
```python
class GridSearchOptimizer:
    """ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨"""

    def optimize(
        self,
        strategy_class,
        param_grid: Dict[str, List],
        train_data: Dict,
        validation_data: Dict,
        metric: str = 'sharpe_ratio'
    ) -> Dict:
        """
        ç½‘æ ¼æœç´¢æœ€ä¼˜å‚æ•°

        Args:
            strategy_class: ç­–ç•¥ç±»
            param_grid: å‚æ•°ç½‘æ ¼ï¼Œå¦‚ {'lookback': [10, 20, 30], 'top_n': [30, 50]}
            train_data: è®­ç»ƒæ•°æ®
            validation_data: éªŒè¯æ•°æ®
            metric: ä¼˜åŒ–æŒ‡æ ‡

        Returns:
            {
                'best_params': æœ€ä¼˜å‚æ•°,
                'best_score': æœ€ä¼˜å¾—åˆ†,
                'all_results': æ‰€æœ‰ç»“æœåˆ—è¡¨
            }
        """
        from itertools import product

        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        keys = param_grid.keys()
        values = param_grid.values()
        param_combinations = [dict(zip(keys, v)) for v in product(*values)]

        results = []
        for params in param_combinations:
            # åˆ›å»ºç­–ç•¥
            strategy = strategy_class('test', params)

            # å›æµ‹
            backtest_result = strategy.backtest(
                train_data['engine'],
                train_data['prices'],
                train_data['features']
            )

            # è®¡ç®—æŒ‡æ ‡
            score = self._calculate_metric(backtest_result, metric)

            results.append({
                'params': params,
                'score': score
            })

        # æ‰¾åˆ°æœ€ä¼˜å‚æ•°
        best = max(results, key=lambda x: x['score'])

        return {
            'best_params': best['params'],
            'best_score': best['score'],
            'all_results': results
        }
```

---

#### 2.2 æ·»åŠ å¹¶è¡Œè®¡ç®—æ”¯æŒ

**æ—¶é—´**ï¼š3å¤© / 24å·¥æ—¶

**ä¼˜åŒ–å†…å®¹**ï¼š
1. å¤šè‚¡ç¥¨å¹¶è¡Œç‰¹å¾è®¡ç®—ï¼ˆmultiprocessingï¼‰
2. å¼‚æ­¥æ•°æ®ä¸‹è½½ï¼ˆasyncioï¼‰
3. æ‰¹é‡æ¨¡å‹è®­ç»ƒï¼ˆjoblibï¼‰

**ç¤ºä¾‹ä»£ç **ï¼š
```python
# features/parallel_calculator.py
from joblib import Parallel, delayed
from multiprocessing import cpu_count

class ParallelFeatureCalculator:
    """å¹¶è¡Œç‰¹å¾è®¡ç®—å™¨"""

    def calculate_features_parallel(
        self,
        stock_list: List[str],
        n_jobs: int = -1
    ) -> Dict[str, pd.DataFrame]:
        """
        å¹¶è¡Œè®¡ç®—å¤šåªè‚¡ç¥¨çš„ç‰¹å¾

        Args:
            stock_list: è‚¡ç¥¨åˆ—è¡¨
            n_jobs: å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆ-1=ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒï¼‰

        Returns:
            {stock_code: features_df}
        """
        if n_jobs == -1:
            n_jobs = cpu_count()

        # å¹¶è¡Œè®¡ç®—
        results = Parallel(n_jobs=n_jobs)(
            delayed(self._calculate_single_stock)(code)
            for code in stock_list
        )

        # ç»„åˆç»“æœ
        return dict(zip(stock_list, results))

    def _calculate_single_stock(self, stock_code: str) -> pd.DataFrame:
        """è®¡ç®—å•åªè‚¡ç¥¨çš„ç‰¹å¾"""
        # åŠ è½½æ•°æ®
        df = self.db.load_daily_data(stock_code)

        # è®¡ç®—ç‰¹å¾
        af = AlphaFactors(df)
        features = af.add_all_alpha_factors()

        return features
```

---

#### 2.3 æ·»åŠ æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

**æ—¶é—´**ï¼š4å¤© / 32å·¥æ—¶

**æ–°å¢æ–‡ä»¶**ï¼š
```
core/src/monitoring/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ performance_monitor.py        # æ€§èƒ½ç›‘æ§ (8h)
â”œâ”€â”€ alert_manager.py              # å‘Šè­¦ç®¡ç†å™¨ (8h)
â”œâ”€â”€ metrics_collector.py          # æŒ‡æ ‡æ”¶é›†å™¨ (8h)
â””â”€â”€ reporters/                    # æŠ¥å‘Šç”Ÿæˆå™¨ (8h)
    â”œâ”€â”€ email_reporter.py
    â””â”€â”€ dingtalk_reporter.py
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
1. è®¡ç®—æ—¶é—´ç›‘æ§ï¼ˆè£…é¥°å™¨ï¼‰
2. å†…å­˜ä½¿ç”¨ç›‘æ§
3. å¼‚å¸¸å‘Šè­¦ï¼ˆé’‰é’‰/é‚®ä»¶ï¼‰
4. æ—¥æŠ¥/å‘¨æŠ¥ç”Ÿæˆ

---

#### 2.4 æ‰©å±•å›æµ‹å¼•æ“åŠŸèƒ½

**æ—¶é—´**ï¼š3å¤© / 24å·¥æ—¶

**æ–°å¢åŠŸèƒ½**ï¼š
1. æ”¯æŒåšç©ºï¼ˆèåˆ¸ï¼‰
2. æ”¯æŒæœŸè´§å¯¹å†²
3. æ”¯æŒå¤šç§è°ƒä»“é¢‘ç‡ï¼ˆæ—¥/å‘¨/æœˆï¼‰
4. æ”¯æŒæ»‘ç‚¹æ¨¡å‹ä¼˜åŒ–
5. æ”¯æŒäº¤æ˜“æˆæœ¬åˆ†æ

---

### é˜¶æ®µ3ï¼šç”Ÿäº§å‡†å¤‡ï¼ˆ3-4å‘¨ï¼‰ğŸŸ¢ ä½ä¼˜å…ˆçº§

**ç›®æ ‡**ï¼šå®ç›˜äº¤æ˜“å‡†å¤‡

**å·¥ä½œé‡ä¼°ç®—**ï¼š100-120 å·¥æ—¶

#### 3.1 å®ç°å®ç›˜äº¤æ˜“æ¥å£ (trading/)

**æ—¶é—´**ï¼š10å¤© / 80å·¥æ—¶

**æ³¨æ„**ï¼šæ­¤æ¨¡å—éœ€è¦åˆ¸å•†æˆæƒï¼Œå»ºè®®å…ˆå®ç°æ¨¡æ‹Ÿäº¤æ˜“

**ç›®å½•ç»“æ„**ï¼š
```
core/src/trading/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ broker_interface.py           # åˆ¸å•†æ¥å£åŸºç±»
â”œâ”€â”€ order_manager.py              # è®¢å•ç®¡ç†å™¨
â”œâ”€â”€ execution_engine.py           # æ‰§è¡Œå¼•æ“
â”œâ”€â”€ trade_monitor.py              # äº¤æ˜“ç›‘æ§
â”œâ”€â”€ paper_trading.py              # æ¨¡æ‹Ÿäº¤æ˜“ï¼ˆä¼˜å…ˆå®ç°ï¼‰
â””â”€â”€ adapters/                     # åˆ¸å•†é€‚é…å™¨
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ xtp_adapter.py            # XTPæ¥å£
    â””â”€â”€ simulator_adapter.py      # æ¨¡æ‹Ÿå™¨
```

---

#### 3.2 å®Œå–„æ–‡æ¡£å’Œæ•™ç¨‹

**æ—¶é—´**ï¼š5å¤© / 40å·¥æ—¶

**äº¤ä»˜ç‰©**ï¼š
1. Sphinx APIæ–‡æ¡£
2. Jupyter Notebook æ•™ç¨‹ï¼ˆ10+ä¸ªï¼‰
3. è§†é¢‘æ•™ç¨‹ï¼ˆå¯é€‰ï¼‰
4. FAQæ–‡æ¡£

---

## ğŸ“ å¼€å‘è§„èŒƒ

### ä»£ç è§„èŒƒ
1. **ç±»å‹æç¤º**ï¼šæ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰ç±»å‹æç¤º
2. **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šéµå¾ª Google Style
3. **æ—¥å¿—ç³»ç»Ÿ**ï¼šç»Ÿä¸€ä½¿ç”¨ Loguru
4. **å¼‚å¸¸å¤„ç†**ï¼šæ˜ç¡®çš„å¼‚å¸¸ç±»å‹å’Œé”™è¯¯ä¿¡æ¯

### æµ‹è¯•è§„èŒƒ
1. **å•å…ƒæµ‹è¯•è¦†ç›–ç‡** > 80%
2. **é›†æˆæµ‹è¯•**ï¼šå…³é”®æµç¨‹å¿…é¡»æœ‰é›†æˆæµ‹è¯•
3. **æ€§èƒ½æµ‹è¯•**ï¼šæ–°åŠŸèƒ½å¿…é¡»æœ‰æ€§èƒ½åŸºå‡†

### Gitè§„èŒƒ
1. **åˆ†æ”¯ç­–ç•¥**ï¼šfeature/xxx, fix/xxx, refactor/xxx
2. **æäº¤ä¿¡æ¯**ï¼šéµå¾ª Conventional Commits
3. **ä»£ç å®¡æŸ¥**ï¼šæ‰€æœ‰ä»£ç å¿…é¡»ç»è¿‡Review

---

## ğŸ¯ ä¼˜å…ˆçº§è¯´æ˜

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»å®Œæˆï¼‰
- ~~ç­–ç•¥å±‚~~ âœ… å·²å®Œæˆ
- ç­–ç•¥æµ‹è¯•ä¼˜åŒ–ï¼ˆæå‡é€šè¿‡ç‡ï¼‰
- é£é™©ç®¡ç†
- å› å­åˆ†æå·¥å…·

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®å®Œæˆï¼‰
- å‚æ•°ä¼˜åŒ–
- å¹¶è¡Œè®¡ç®—
- æ€§èƒ½ç›‘æ§

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰
- å®ç›˜äº¤æ˜“æ¥å£
- å¸‚åœºä¸­æ€§ç­–ç•¥
- é«˜çº§åŠŸèƒ½

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
1. [Core README](./README.md)
2. [æ¶æ„åˆ†ææ–‡æ¡£](./ARCHITECTURE_ANALYSIS.md)
3. æäº¤ Issue åˆ° GitHub

---

**æœ€åæ›´æ–°**ï¼š2026-01-29
**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
**é¢„è®¡å®Œæˆæ—¶é—´**ï¼š6-9å‘¨ï¼ˆæ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©ï¼‰
